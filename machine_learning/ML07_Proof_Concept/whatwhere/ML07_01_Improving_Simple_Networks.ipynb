{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML07_01_Improving_Simple_Networks.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"10143c7b8f244cf1864ee86925fb238e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d84d6e7f76a2482198a26c4424cb8ebd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6da24aeee76d4b85b3b93e9a07616094","IPY_MODEL_cfe07a21dcd340bdb19a65f8401a90f9"]}},"d84d6e7f76a2482198a26c4424cb8ebd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6da24aeee76d4b85b3b93e9a07616094":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6ed5c00ca3694905b2b2bc29ba5b8940","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":553433881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":553433881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8caca4a95da94cba92d66b7e42709459"}},"cfe07a21dcd340bdb19a65f8401a90f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c5f04a04e2834917829e34b57039f266","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528M/528M [00:54&lt;00:00, 10.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4d03977cd553460f91c208490c73c647"}},"6ed5c00ca3694905b2b2bc29ba5b8940":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8caca4a95da94cba92d66b7e42709459":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c5f04a04e2834917829e34b57039f266":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4d03977cd553460f91c208490c73c647":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"1IuDnV7wBCdC"},"source":["<font size=6>Développer une preuve de concept</font>  \n","<font size=5>Classification d'image avec le papier Learning What and Where to Transfer  \n","Partie 1 : Améliorer les performances de mon CNN et de VGG16 grâce à EfficientNetB4</font>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"u_rEOyNPBCdD"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"GF2mrZJkBCdE"},"source":["**Vérification de l'environnement**"]},{"cell_type":"code","metadata":{"id":"tUgNLOrZ5zyy"},"source":["import sys\n","IN_COLAB = \"google.colab\" in sys.modules\n","# PATH_DRIVE : to change according to your Google Drive folders\n","PATH_DRIVE = \"/content/drive/My Drive/MachineLearning/ML07\"\n","# IMAGES_DRIVE : to get access to previously loaded images\n","IMAGES_DRIVE = \"/content/drive/My Drive/MachineLearning/ML06/Images\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ay0Ybm0I500n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605860161129,"user_tz":-60,"elapsed":823,"user":{"displayName":"CBS Power","photoUrl":"","userId":"13126957910862042425"}},"outputId":"4d14f604-2250-429f-8fcd-287a363e8359"},"source":["if IN_COLAB:\n","    print(\"Le notebook est exécuté sur Google Colab\")\n","else:\n","    print(\"Le notebook est exécuté en local\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Le notebook est exécuté sur Google Colab\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CCi_1tXv505N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605860183891,"user_tz":-60,"elapsed":23571,"user":{"displayName":"CBS Power","photoUrl":"","userId":"13126957910862042425"}},"outputId":"16226db8-27cc-4b45-d0b0-f23792280f16"},"source":["if IN_COLAB:\n","    from google.colab import drive, files\n","    drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6ay6qcCIBCdQ"},"source":["---\n","## <font color=blue>Notebook set-up</font>"]},{"cell_type":"markdown","metadata":{"id":"uSAAMADMBCdR"},"source":["**Importation des librairies**"]},{"cell_type":"code","metadata":{"id":"Sqiejm5glRVD"},"source":["import os\n","#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"79hrYgCN5y49"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import re\n","import datetime\n","import random as python_random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqmb_7nXmC2M"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQuRhGr6TYB2"},"source":["import csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z1ZnXqIM6feY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605860192351,"user_tz":-60,"elapsed":31987,"user":{"displayName":"CBS Power","photoUrl":"","userId":"13126957910862042425"}},"outputId":"f66b6ef6-d644-4aae-f945-a1fd3ee4c783"},"source":["if IN_COLAB:\n","    sys.path.append(PATH_DRIVE)\n","    os.chdir(PATH_DRIVE)\n","    import sf_graphiques as sfg\n","    import sf_small_cnn as sf_target\n","    import sf_efficientnet_b4 as sf_source\n","    import sf_vgg16 as sf_vgg\n","    import sf_pytorch_loaders as sf_load\n","    import sf_meta_optimizers as sf_optim\n","    import sf_l2t_ww as sf_l2t\n","else:\n","    import modules_perso.sf_graphiques as sfg\n","    import modules_perso.sf_small_cnn as sf_target\n","    import modules_perso.sf_efficientnet_b4 as sf_source\n","    import modules_perso.sf_vgg16 as sf_vgg\n","    import modules_perso.sf_pytorch_loaders as sf_load\n","    import modules_perso.sf_meta_optimizers as sf_optim\n","    import modules_perso.sf_l2t_ww as sf_l2t"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"viCeZ9D2BCde"},"source":["**Notebook set-up**"]},{"cell_type":"code","metadata":{"id":"5wZeyN8chxvE"},"source":["def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n","    path = fig_id + \".\" + fig_extension\n","    if IN_COLAB:\n","        path = PATH_DRIVE + \"/\" + path\n","    #print(\"Saving figure\", fig_id)\n","    if tight_layout:\n","        plt.tight_layout()\n","    plt.savefig(path, dpi=resolution)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0g-vuB7KQdJt"},"source":["RANDOM_SEED = 42\n","BATCH_SIZE = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HS2qTQ43S93Z"},"source":["def reset_random_seeds():\n","    np.random.seed(RANDOM_SEED)\n","    python_random.seed(RANDOM_SEED)\n","    torch.manual_seed(40)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGbHCe6mWd_8"},"source":["reset_random_seeds()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k7ekka88FQSp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605860192365,"user_tz":-60,"elapsed":31959,"user":{"displayName":"CBS Power","photoUrl":"","userId":"13126957910862042425"}},"outputId":"2e2b1d0d-1a89-441e-f7f5-4aaae96c3056"},"source":["if torch.cuda.device_count() >= 1:\n","    print(torch.cuda.get_device_name(0))\n","else:\n","    print(\"No Cuda Device\")\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LchSd56l7iph"},"source":["**Personal Methods**"]},{"cell_type":"code","metadata":{"id":"r6gbizCTLhHj"},"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNE6rZ1bLi80"},"source":["def accuracy_topk(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(1.0 / batch_size))\n","    return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oPmX-QbVqg_S"},"source":["def accuracy_top1(outputs_data, labels):\n","    _, pred = torch.max(outputs_data, 1)\n","    correct = (pred == labels).sum().item()\n","    return correct / labels.size(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLSBB1tCNx7m"},"source":["def get_validation(model, loader):\n","    acc = AverageMeter()\n","    loss = AverageMeter()\n","    model.eval()\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(device), y.to(device)\n","            y_pred = model.forward(x)\n","            loss.update(F.cross_entropy(y_pred, y))\n","            acc.update(accuracy_top1(y_pred.data, y))\n","    return loss.avg, acc.avg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZgebVWTfJaNU"},"source":["def transferlearning_on_targettask(mymodel, mycriterion, myoptimizer, myloaders,\n","                                   mysave_name, nb_epochs=50, patience=0):\n","    csv_filename = os.path.join(PATH_DRIVE, \"logs/{}.csv\".format(mysave_name))\n","    csv_memory = open(csv_filename, \"w\")  # Write the headers to the file\n","    writer = csv.writer(csv_memory)\n","    writer.writerow([\"epoch\", \"validation_loss\", \"training_loss\",\n","                      \"validation_accuracy\", \"training_accuracy\"])\n","    csv_memory.close()\n","\n","    best_acc = 0.0\n","    lag_best = 0\n","    for epoch in range(nb_epochs):\n","        mymodel.train()\n","        epoch_acc = AverageMeter()\n","        epoch_loss = AverageMeter()\n","        for x, y in myloaders[0]:\n","            x, y = x.to(device), y.to(device)\n","            myoptimizer.zero_grad()\n","            y_pred = mymodel.forward(x)\n","            loss = mycriterion(y_pred, y)\n","            loss.backward()\n","            myoptimizer.step()\n","            epoch_loss.update(loss.item())\n","            epoch_acc.update(accuracy_top1(y_pred.data, y))\n","        training_loss = epoch_loss.avg\n","        training_accuracy = epoch_acc.avg\n","        \n","        validation_loss, validation_accuracy = get_validation(mymodel, myloaders[2])\n","        if validation_accuracy > best_acc:\n","            best_acc = validation_accuracy\n","            lag_best = 0\n","            torch.save(mymodel.state_dict(), \"models/{}.pth\".format(mysave_name))\n","        else:\n","            lag_best += 1\n","\n","        print(\"[Epoch : {}]  [Training accuracy = {:.2%}] [Validation accuracy = {:.2%}] [Best = {:.2%}]  [Training loss = {:.3f}] [Validation loss = {:.3f}]\"\\\n","              .format(epoch, training_accuracy, validation_accuracy, best_acc, training_loss, validation_loss))\n","        csv_memory = open(csv_filename, \"a\")  # Write the results to the file\n","        writer = csv.writer(csv_memory)\n","        writer.writerow([epoch, validation_loss, training_loss,\n","                        validation_accuracy, training_accuracy])\n","        csv_memory.close()\n","\n","        if (patience > 0) & (lag_best > patience):\n","            print(\"Learning ended by early-stop\")\n","            break\n","        # next epoch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tHBFWuX4Hi0B"},"source":["---\n","## 1\\. Performance du modèle Baseline"]},{"cell_type":"markdown","metadata":{"id":"aWsPkjWmDhIG"},"source":["Je calcule la performance du modèle CNN très simple que j'ai créé lors du traitement initial de ce problème.  \n","J'ajoute une couche de Batch Normalization après chaque couche de convolution pour résoudre un problème d'explosion du gradient rencontré lors de mon premier essai de la méthode l2t-ww avec ce modèle comme cible."]},{"cell_type":"code","metadata":{"id":"HwZyu06IWsO2"},"source":["model = sf_target.mycnn3(num_classes=120)\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), eps=1e-7)\n","# note : eps=1e-7 to get the same epsilon than Tensorflow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vunpq_GDWsO-"},"source":["loaders = sf_load.get_dataset(IMAGES_DRIVE, model, mini_data=0.1, stratify=True,\n","                              batch_size=128, with_data_augmentation=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"osWteTv8WsPJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605230327746,"user_tz":-60,"elapsed":8176872,"user":{"displayName":"S FRIOT","photoUrl":"","userId":"08174580811350672782"}},"outputId":"c65cc3d6-58da-4210-ee87-ceb5de3c5b9a"},"source":["transferlearning_on_targettask(model, criterion, optimizer, loaders,\n","                               mysave_name=\"baseline_model\",\n","                               nb_epochs=1000, patience=50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Epoch : 0]  [Training accuracy = 0.64%] [Validation accuracy = 1.54%] [Best = 1.54%]  [Training loss = 4.951] [Validation loss = 4.796]\n","[Epoch : 1]  [Training accuracy = 1.19%] [Validation accuracy = 0.93%] [Best = 1.54%]  [Training loss = 4.786] [Validation loss = 4.786]\n","[Epoch : 2]  [Training accuracy = 1.19%] [Validation accuracy = 1.05%] [Best = 1.54%]  [Training loss = 4.788] [Validation loss = 4.778]\n","[Epoch : 3]  [Training accuracy = 0.21%] [Validation accuracy = 1.11%] [Best = 1.54%]  [Training loss = 4.772] [Validation loss = 4.770]\n","[Epoch : 4]  [Training accuracy = 1.83%] [Validation accuracy = 1.53%] [Best = 1.54%]  [Training loss = 4.759] [Validation loss = 4.764]\n","[Epoch : 5]  [Training accuracy = 2.07%] [Validation accuracy = 1.80%] [Best = 1.80%]  [Training loss = 4.737] [Validation loss = 4.758]\n","[Epoch : 6]  [Training accuracy = 1.57%] [Validation accuracy = 1.47%] [Best = 1.80%]  [Training loss = 4.727] [Validation loss = 4.754]\n","[Epoch : 7]  [Training accuracy = 2.33%] [Validation accuracy = 1.65%] [Best = 1.80%]  [Training loss = 4.698] [Validation loss = 4.747]\n","[Epoch : 8]  [Training accuracy = 2.87%] [Validation accuracy = 1.86%] [Best = 1.86%]  [Training loss = 4.678] [Validation loss = 4.743]\n","[Epoch : 9]  [Training accuracy = 3.04%] [Validation accuracy = 1.56%] [Best = 1.86%]  [Training loss = 4.674] [Validation loss = 4.737]\n","[Epoch : 10]  [Training accuracy = 2.87%] [Validation accuracy = 1.83%] [Best = 1.86%]  [Training loss = 4.656] [Validation loss = 4.729]\n","[Epoch : 11]  [Training accuracy = 2.37%] [Validation accuracy = 1.74%] [Best = 1.86%]  [Training loss = 4.633] [Validation loss = 4.723]\n","[Epoch : 12]  [Training accuracy = 3.54%] [Validation accuracy = 2.16%] [Best = 2.16%]  [Training loss = 4.622] [Validation loss = 4.716]\n","[Epoch : 13]  [Training accuracy = 4.83%] [Validation accuracy = 2.21%] [Best = 2.21%]  [Training loss = 4.587] [Validation loss = 4.711]\n","[Epoch : 14]  [Training accuracy = 4.30%] [Validation accuracy = 2.53%] [Best = 2.53%]  [Training loss = 4.573] [Validation loss = 4.708]\n","[Epoch : 15]  [Training accuracy = 4.59%] [Validation accuracy = 2.39%] [Best = 2.53%]  [Training loss = 4.540] [Validation loss = 4.696]\n","[Epoch : 16]  [Training accuracy = 4.87%] [Validation accuracy = 2.70%] [Best = 2.70%]  [Training loss = 4.533] [Validation loss = 4.689]\n","[Epoch : 17]  [Training accuracy = 6.35%] [Validation accuracy = 2.61%] [Best = 2.70%]  [Training loss = 4.503] [Validation loss = 4.685]\n","[Epoch : 18]  [Training accuracy = 6.09%] [Validation accuracy = 2.82%] [Best = 2.82%]  [Training loss = 4.490] [Validation loss = 4.675]\n","[Epoch : 19]  [Training accuracy = 5.92%] [Validation accuracy = 3.12%] [Best = 3.12%]  [Training loss = 4.440] [Validation loss = 4.669]\n","[Epoch : 20]  [Training accuracy = 6.47%] [Validation accuracy = 3.16%] [Best = 3.16%]  [Training loss = 4.426] [Validation loss = 4.661]\n","[Epoch : 21]  [Training accuracy = 7.29%] [Validation accuracy = 3.25%] [Best = 3.25%]  [Training loss = 4.390] [Validation loss = 4.659]\n","[Epoch : 22]  [Training accuracy = 8.11%] [Validation accuracy = 3.35%] [Best = 3.35%]  [Training loss = 4.369] [Validation loss = 4.656]\n","[Epoch : 23]  [Training accuracy = 7.15%] [Validation accuracy = 3.31%] [Best = 3.35%]  [Training loss = 4.359] [Validation loss = 4.651]\n","[Epoch : 24]  [Training accuracy = 6.63%] [Validation accuracy = 3.41%] [Best = 3.41%]  [Training loss = 4.333] [Validation loss = 4.644]\n","[Epoch : 25]  [Training accuracy = 7.58%] [Validation accuracy = 3.49%] [Best = 3.49%]  [Training loss = 4.302] [Validation loss = 4.642]\n","[Epoch : 26]  [Training accuracy = 8.68%] [Validation accuracy = 3.82%] [Best = 3.82%]  [Training loss = 4.239] [Validation loss = 4.642]\n","[Epoch : 27]  [Training accuracy = 7.82%] [Validation accuracy = 3.33%] [Best = 3.82%]  [Training loss = 4.238] [Validation loss = 4.640]\n","[Epoch : 28]  [Training accuracy = 9.58%] [Validation accuracy = 3.64%] [Best = 3.82%]  [Training loss = 4.201] [Validation loss = 4.638]\n","[Epoch : 29]  [Training accuracy = 8.41%] [Validation accuracy = 3.54%] [Best = 3.82%]  [Training loss = 4.207] [Validation loss = 4.634]\n","[Epoch : 30]  [Training accuracy = 11.18%] [Validation accuracy = 3.68%] [Best = 3.82%]  [Training loss = 4.178] [Validation loss = 4.630]\n","[Epoch : 31]  [Training accuracy = 10.56%] [Validation accuracy = 3.93%] [Best = 3.93%]  [Training loss = 4.150] [Validation loss = 4.627]\n","[Epoch : 32]  [Training accuracy = 10.41%] [Validation accuracy = 3.77%] [Best = 3.93%]  [Training loss = 4.133] [Validation loss = 4.628]\n","[Epoch : 33]  [Training accuracy = 10.19%] [Validation accuracy = 3.75%] [Best = 3.93%]  [Training loss = 4.106] [Validation loss = 4.627]\n","[Epoch : 34]  [Training accuracy = 11.51%] [Validation accuracy = 3.75%] [Best = 3.93%]  [Training loss = 4.065] [Validation loss = 4.633]\n","[Epoch : 35]  [Training accuracy = 13.39%] [Validation accuracy = 4.19%] [Best = 4.19%]  [Training loss = 4.048] [Validation loss = 4.629]\n","[Epoch : 36]  [Training accuracy = 12.78%] [Validation accuracy = 3.89%] [Best = 4.19%]  [Training loss = 4.041] [Validation loss = 4.628]\n","[Epoch : 37]  [Training accuracy = 11.78%] [Validation accuracy = 3.94%] [Best = 4.19%]  [Training loss = 4.015] [Validation loss = 4.623]\n","[Epoch : 38]  [Training accuracy = 12.09%] [Validation accuracy = 4.22%] [Best = 4.22%]  [Training loss = 3.959] [Validation loss = 4.632]\n","[Epoch : 39]  [Training accuracy = 13.82%] [Validation accuracy = 4.07%] [Best = 4.22%]  [Training loss = 3.967] [Validation loss = 4.632]\n","[Epoch : 40]  [Training accuracy = 13.73%] [Validation accuracy = 3.94%] [Best = 4.22%]  [Training loss = 3.944] [Validation loss = 4.621]\n","[Epoch : 41]  [Training accuracy = 13.08%] [Validation accuracy = 3.87%] [Best = 4.22%]  [Training loss = 3.897] [Validation loss = 4.622]\n","[Epoch : 42]  [Training accuracy = 13.04%] [Validation accuracy = 4.00%] [Best = 4.22%]  [Training loss = 3.925] [Validation loss = 4.622]\n","[Epoch : 43]  [Training accuracy = 13.52%] [Validation accuracy = 3.67%] [Best = 4.22%]  [Training loss = 3.897] [Validation loss = 4.627]\n","[Epoch : 44]  [Training accuracy = 14.74%] [Validation accuracy = 3.95%] [Best = 4.22%]  [Training loss = 3.877] [Validation loss = 4.620]\n","[Epoch : 45]  [Training accuracy = 13.76%] [Validation accuracy = 4.04%] [Best = 4.22%]  [Training loss = 3.845] [Validation loss = 4.630]\n","[Epoch : 46]  [Training accuracy = 14.37%] [Validation accuracy = 3.86%] [Best = 4.22%]  [Training loss = 3.840] [Validation loss = 4.628]\n","[Epoch : 47]  [Training accuracy = 15.20%] [Validation accuracy = 4.15%] [Best = 4.22%]  [Training loss = 3.826] [Validation loss = 4.628]\n","[Epoch : 48]  [Training accuracy = 16.23%] [Validation accuracy = 3.95%] [Best = 4.22%]  [Training loss = 3.777] [Validation loss = 4.628]\n","[Epoch : 49]  [Training accuracy = 15.15%] [Validation accuracy = 4.22%] [Best = 4.22%]  [Training loss = 3.774] [Validation loss = 4.634]\n","[Epoch : 50]  [Training accuracy = 16.44%] [Validation accuracy = 3.69%] [Best = 4.22%]  [Training loss = 3.721] [Validation loss = 4.634]\n","[Epoch : 51]  [Training accuracy = 15.16%] [Validation accuracy = 4.54%] [Best = 4.54%]  [Training loss = 3.710] [Validation loss = 4.637]\n","[Epoch : 52]  [Training accuracy = 16.32%] [Validation accuracy = 4.24%] [Best = 4.54%]  [Training loss = 3.716] [Validation loss = 4.633]\n","[Epoch : 53]  [Training accuracy = 17.86%] [Validation accuracy = 4.42%] [Best = 4.54%]  [Training loss = 3.641] [Validation loss = 4.641]\n","[Epoch : 54]  [Training accuracy = 18.25%] [Validation accuracy = 4.27%] [Best = 4.54%]  [Training loss = 3.645] [Validation loss = 4.646]\n","[Epoch : 55]  [Training accuracy = 16.84%] [Validation accuracy = 4.37%] [Best = 4.54%]  [Training loss = 3.624] [Validation loss = 4.643]\n","[Epoch : 56]  [Training accuracy = 16.56%] [Validation accuracy = 4.59%] [Best = 4.59%]  [Training loss = 3.661] [Validation loss = 4.637]\n","[Epoch : 57]  [Training accuracy = 18.85%] [Validation accuracy = 4.25%] [Best = 4.59%]  [Training loss = 3.591] [Validation loss = 4.630]\n","[Epoch : 58]  [Training accuracy = 18.29%] [Validation accuracy = 4.58%] [Best = 4.59%]  [Training loss = 3.590] [Validation loss = 4.648]\n","[Epoch : 59]  [Training accuracy = 18.11%] [Validation accuracy = 4.37%] [Best = 4.59%]  [Training loss = 3.569] [Validation loss = 4.648]\n","[Epoch : 60]  [Training accuracy = 19.45%] [Validation accuracy = 4.46%] [Best = 4.59%]  [Training loss = 3.561] [Validation loss = 4.661]\n","[Epoch : 61]  [Training accuracy = 18.39%] [Validation accuracy = 4.38%] [Best = 4.59%]  [Training loss = 3.525] [Validation loss = 4.658]\n","[Epoch : 62]  [Training accuracy = 19.69%] [Validation accuracy = 4.49%] [Best = 4.59%]  [Training loss = 3.511] [Validation loss = 4.657]\n","[Epoch : 63]  [Training accuracy = 19.79%] [Validation accuracy = 4.38%] [Best = 4.59%]  [Training loss = 3.502] [Validation loss = 4.657]\n","[Epoch : 64]  [Training accuracy = 18.91%] [Validation accuracy = 4.58%] [Best = 4.59%]  [Training loss = 3.486] [Validation loss = 4.651]\n","[Epoch : 65]  [Training accuracy = 21.90%] [Validation accuracy = 4.83%] [Best = 4.83%]  [Training loss = 3.445] [Validation loss = 4.667]\n","[Epoch : 66]  [Training accuracy = 20.93%] [Validation accuracy = 4.45%] [Best = 4.83%]  [Training loss = 3.429] [Validation loss = 4.659]\n","[Epoch : 67]  [Training accuracy = 21.02%] [Validation accuracy = 4.22%] [Best = 4.83%]  [Training loss = 3.439] [Validation loss = 4.669]\n","[Epoch : 68]  [Training accuracy = 21.88%] [Validation accuracy = 4.41%] [Best = 4.83%]  [Training loss = 3.412] [Validation loss = 4.677]\n","[Epoch : 69]  [Training accuracy = 20.73%] [Validation accuracy = 4.38%] [Best = 4.83%]  [Training loss = 3.408] [Validation loss = 4.673]\n","[Epoch : 70]  [Training accuracy = 23.53%] [Validation accuracy = 4.45%] [Best = 4.83%]  [Training loss = 3.304] [Validation loss = 4.684]\n","[Epoch : 71]  [Training accuracy = 20.66%] [Validation accuracy = 4.58%] [Best = 4.83%]  [Training loss = 3.363] [Validation loss = 4.684]\n","[Epoch : 72]  [Training accuracy = 20.21%] [Validation accuracy = 4.70%] [Best = 4.83%]  [Training loss = 3.373] [Validation loss = 4.697]\n","[Epoch : 73]  [Training accuracy = 24.84%] [Validation accuracy = 4.44%] [Best = 4.83%]  [Training loss = 3.280] [Validation loss = 4.689]\n","[Epoch : 74]  [Training accuracy = 22.27%] [Validation accuracy = 4.44%] [Best = 4.83%]  [Training loss = 3.301] [Validation loss = 4.697]\n","[Epoch : 75]  [Training accuracy = 22.08%] [Validation accuracy = 4.53%] [Best = 4.83%]  [Training loss = 3.291] [Validation loss = 4.705]\n","[Epoch : 76]  [Training accuracy = 21.93%] [Validation accuracy = 4.68%] [Best = 4.83%]  [Training loss = 3.299] [Validation loss = 4.711]\n","[Epoch : 77]  [Training accuracy = 23.93%] [Validation accuracy = 4.39%] [Best = 4.83%]  [Training loss = 3.257] [Validation loss = 4.692]\n","[Epoch : 78]  [Training accuracy = 23.87%] [Validation accuracy = 4.47%] [Best = 4.83%]  [Training loss = 3.245] [Validation loss = 4.716]\n","[Epoch : 79]  [Training accuracy = 25.60%] [Validation accuracy = 4.99%] [Best = 4.99%]  [Training loss = 3.198] [Validation loss = 4.724]\n","[Epoch : 80]  [Training accuracy = 22.37%] [Validation accuracy = 4.79%] [Best = 4.99%]  [Training loss = 3.267] [Validation loss = 4.713]\n","[Epoch : 81]  [Training accuracy = 23.70%] [Validation accuracy = 4.85%] [Best = 4.99%]  [Training loss = 3.239] [Validation loss = 4.710]\n","[Epoch : 82]  [Training accuracy = 23.67%] [Validation accuracy = 4.20%] [Best = 4.99%]  [Training loss = 3.177] [Validation loss = 4.731]\n","[Epoch : 83]  [Training accuracy = 25.97%] [Validation accuracy = 4.79%] [Best = 4.99%]  [Training loss = 3.178] [Validation loss = 4.727]\n","[Epoch : 84]  [Training accuracy = 24.23%] [Validation accuracy = 4.64%] [Best = 4.99%]  [Training loss = 3.237] [Validation loss = 4.725]\n","[Epoch : 85]  [Training accuracy = 25.05%] [Validation accuracy = 4.37%] [Best = 4.99%]  [Training loss = 3.147] [Validation loss = 4.730]\n","[Epoch : 86]  [Training accuracy = 24.61%] [Validation accuracy = 4.66%] [Best = 4.99%]  [Training loss = 3.167] [Validation loss = 4.714]\n","[Epoch : 87]  [Training accuracy = 25.40%] [Validation accuracy = 4.51%] [Best = 4.99%]  [Training loss = 3.105] [Validation loss = 4.732]\n","[Epoch : 88]  [Training accuracy = 27.89%] [Validation accuracy = 4.93%] [Best = 4.99%]  [Training loss = 3.094] [Validation loss = 4.747]\n","[Epoch : 89]  [Training accuracy = 27.77%] [Validation accuracy = 4.66%] [Best = 4.99%]  [Training loss = 3.043] [Validation loss = 4.766]\n","[Epoch : 90]  [Training accuracy = 27.85%] [Validation accuracy = 4.89%] [Best = 4.99%]  [Training loss = 3.063] [Validation loss = 4.751]\n","[Epoch : 91]  [Training accuracy = 27.65%] [Validation accuracy = 4.70%] [Best = 4.99%]  [Training loss = 3.061] [Validation loss = 4.757]\n","[Epoch : 92]  [Training accuracy = 26.68%] [Validation accuracy = 4.57%] [Best = 4.99%]  [Training loss = 3.051] [Validation loss = 4.759]\n","[Epoch : 93]  [Training accuracy = 29.09%] [Validation accuracy = 4.79%] [Best = 4.99%]  [Training loss = 3.008] [Validation loss = 4.747]\n","[Epoch : 94]  [Training accuracy = 28.63%] [Validation accuracy = 4.96%] [Best = 4.99%]  [Training loss = 3.044] [Validation loss = 4.756]\n","[Epoch : 95]  [Training accuracy = 29.01%] [Validation accuracy = 4.89%] [Best = 4.99%]  [Training loss = 3.015] [Validation loss = 4.770]\n","[Epoch : 96]  [Training accuracy = 27.39%] [Validation accuracy = 5.07%] [Best = 5.07%]  [Training loss = 3.004] [Validation loss = 4.764]\n","[Epoch : 97]  [Training accuracy = 28.61%] [Validation accuracy = 4.94%] [Best = 5.07%]  [Training loss = 2.959] [Validation loss = 4.783]\n","[Epoch : 98]  [Training accuracy = 28.60%] [Validation accuracy = 4.69%] [Best = 5.07%]  [Training loss = 2.974] [Validation loss = 4.788]\n","[Epoch : 99]  [Training accuracy = 28.32%] [Validation accuracy = 4.73%] [Best = 5.07%]  [Training loss = 2.992] [Validation loss = 4.788]\n","[Epoch : 100]  [Training accuracy = 29.57%] [Validation accuracy = 4.55%] [Best = 5.07%]  [Training loss = 2.935] [Validation loss = 4.796]\n","[Epoch : 101]  [Training accuracy = 28.53%] [Validation accuracy = 4.74%] [Best = 5.07%]  [Training loss = 2.916] [Validation loss = 4.786]\n","[Epoch : 102]  [Training accuracy = 30.10%] [Validation accuracy = 5.30%] [Best = 5.30%]  [Training loss = 2.899] [Validation loss = 4.810]\n","[Epoch : 103]  [Training accuracy = 30.81%] [Validation accuracy = 4.78%] [Best = 5.30%]  [Training loss = 2.944] [Validation loss = 4.797]\n","[Epoch : 104]  [Training accuracy = 29.05%] [Validation accuracy = 4.76%] [Best = 5.30%]  [Training loss = 2.909] [Validation loss = 4.796]\n","[Epoch : 105]  [Training accuracy = 31.29%] [Validation accuracy = 4.73%] [Best = 5.30%]  [Training loss = 2.876] [Validation loss = 4.803]\n","[Epoch : 106]  [Training accuracy = 32.24%] [Validation accuracy = 5.03%] [Best = 5.30%]  [Training loss = 2.822] [Validation loss = 4.812]\n","[Epoch : 107]  [Training accuracy = 31.61%] [Validation accuracy = 5.27%] [Best = 5.30%]  [Training loss = 2.827] [Validation loss = 4.823]\n","[Epoch : 108]  [Training accuracy = 32.37%] [Validation accuracy = 5.01%] [Best = 5.30%]  [Training loss = 2.820] [Validation loss = 4.831]\n","[Epoch : 109]  [Training accuracy = 29.25%] [Validation accuracy = 4.78%] [Best = 5.30%]  [Training loss = 2.837] [Validation loss = 4.843]\n","[Epoch : 110]  [Training accuracy = 32.58%] [Validation accuracy = 4.84%] [Best = 5.30%]  [Training loss = 2.831] [Validation loss = 4.819]\n","[Epoch : 111]  [Training accuracy = 29.79%] [Validation accuracy = 5.17%] [Best = 5.30%]  [Training loss = 2.843] [Validation loss = 4.801]\n","[Epoch : 112]  [Training accuracy = 31.59%] [Validation accuracy = 5.55%] [Best = 5.55%]  [Training loss = 2.786] [Validation loss = 4.822]\n","[Epoch : 113]  [Training accuracy = 33.56%] [Validation accuracy = 5.12%] [Best = 5.55%]  [Training loss = 2.785] [Validation loss = 4.836]\n","[Epoch : 114]  [Training accuracy = 30.54%] [Validation accuracy = 4.94%] [Best = 5.55%]  [Training loss = 2.841] [Validation loss = 4.835]\n","[Epoch : 115]  [Training accuracy = 31.88%] [Validation accuracy = 5.59%] [Best = 5.59%]  [Training loss = 2.803] [Validation loss = 4.842]\n","[Epoch : 116]  [Training accuracy = 32.02%] [Validation accuracy = 5.53%] [Best = 5.59%]  [Training loss = 2.794] [Validation loss = 4.839]\n","[Epoch : 117]  [Training accuracy = 33.55%] [Validation accuracy = 4.66%] [Best = 5.59%]  [Training loss = 2.721] [Validation loss = 4.860]\n","[Epoch : 118]  [Training accuracy = 31.03%] [Validation accuracy = 5.40%] [Best = 5.59%]  [Training loss = 2.780] [Validation loss = 4.880]\n","[Epoch : 119]  [Training accuracy = 33.46%] [Validation accuracy = 5.53%] [Best = 5.59%]  [Training loss = 2.772] [Validation loss = 4.855]\n","[Epoch : 120]  [Training accuracy = 34.46%] [Validation accuracy = 5.18%] [Best = 5.59%]  [Training loss = 2.734] [Validation loss = 4.852]\n","[Epoch : 121]  [Training accuracy = 33.44%] [Validation accuracy = 5.14%] [Best = 5.59%]  [Training loss = 2.739] [Validation loss = 4.870]\n","[Epoch : 122]  [Training accuracy = 36.41%] [Validation accuracy = 5.32%] [Best = 5.59%]  [Training loss = 2.670] [Validation loss = 4.885]\n","[Epoch : 123]  [Training accuracy = 34.60%] [Validation accuracy = 5.33%] [Best = 5.59%]  [Training loss = 2.663] [Validation loss = 4.893]\n","[Epoch : 124]  [Training accuracy = 35.31%] [Validation accuracy = 4.91%] [Best = 5.59%]  [Training loss = 2.663] [Validation loss = 4.906]\n","[Epoch : 125]  [Training accuracy = 33.50%] [Validation accuracy = 5.12%] [Best = 5.59%]  [Training loss = 2.722] [Validation loss = 4.896]\n","[Epoch : 126]  [Training accuracy = 34.10%] [Validation accuracy = 5.18%] [Best = 5.59%]  [Training loss = 2.700] [Validation loss = 4.875]\n","[Epoch : 127]  [Training accuracy = 34.79%] [Validation accuracy = 4.83%] [Best = 5.59%]  [Training loss = 2.672] [Validation loss = 4.882]\n","[Epoch : 128]  [Training accuracy = 37.09%] [Validation accuracy = 5.17%] [Best = 5.59%]  [Training loss = 2.626] [Validation loss = 4.888]\n","[Epoch : 129]  [Training accuracy = 36.27%] [Validation accuracy = 4.77%] [Best = 5.59%]  [Training loss = 2.623] [Validation loss = 4.920]\n","[Epoch : 130]  [Training accuracy = 36.00%] [Validation accuracy = 5.15%] [Best = 5.59%]  [Training loss = 2.646] [Validation loss = 4.912]\n","[Epoch : 131]  [Training accuracy = 36.57%] [Validation accuracy = 5.08%] [Best = 5.59%]  [Training loss = 2.606] [Validation loss = 4.909]\n","[Epoch : 132]  [Training accuracy = 36.96%] [Validation accuracy = 5.12%] [Best = 5.59%]  [Training loss = 2.598] [Validation loss = 4.918]\n","[Epoch : 133]  [Training accuracy = 36.77%] [Validation accuracy = 5.26%] [Best = 5.59%]  [Training loss = 2.583] [Validation loss = 4.931]\n","[Epoch : 134]  [Training accuracy = 36.33%] [Validation accuracy = 5.46%] [Best = 5.59%]  [Training loss = 2.569] [Validation loss = 4.935]\n","[Epoch : 135]  [Training accuracy = 40.24%] [Validation accuracy = 5.16%] [Best = 5.59%]  [Training loss = 2.463] [Validation loss = 4.937]\n","[Epoch : 136]  [Training accuracy = 36.39%] [Validation accuracy = 5.13%] [Best = 5.59%]  [Training loss = 2.568] [Validation loss = 4.953]\n","[Epoch : 137]  [Training accuracy = 36.46%] [Validation accuracy = 5.21%] [Best = 5.59%]  [Training loss = 2.548] [Validation loss = 4.944]\n","[Epoch : 138]  [Training accuracy = 35.59%] [Validation accuracy = 5.35%] [Best = 5.59%]  [Training loss = 2.633] [Validation loss = 4.927]\n","[Epoch : 139]  [Training accuracy = 38.14%] [Validation accuracy = 5.08%] [Best = 5.59%]  [Training loss = 2.551] [Validation loss = 4.944]\n","[Epoch : 140]  [Training accuracy = 39.45%] [Validation accuracy = 5.21%] [Best = 5.59%]  [Training loss = 2.484] [Validation loss = 4.938]\n","[Epoch : 141]  [Training accuracy = 39.53%] [Validation accuracy = 4.79%] [Best = 5.59%]  [Training loss = 2.429] [Validation loss = 4.946]\n","[Epoch : 142]  [Training accuracy = 36.92%] [Validation accuracy = 5.16%] [Best = 5.59%]  [Training loss = 2.514] [Validation loss = 4.953]\n","[Epoch : 143]  [Training accuracy = 37.23%] [Validation accuracy = 4.99%] [Best = 5.59%]  [Training loss = 2.526] [Validation loss = 5.013]\n","[Epoch : 144]  [Training accuracy = 39.05%] [Validation accuracy = 5.05%] [Best = 5.59%]  [Training loss = 2.535] [Validation loss = 4.968]\n","[Epoch : 145]  [Training accuracy = 36.63%] [Validation accuracy = 5.04%] [Best = 5.59%]  [Training loss = 2.510] [Validation loss = 4.962]\n","[Epoch : 146]  [Training accuracy = 39.71%] [Validation accuracy = 5.47%] [Best = 5.59%]  [Training loss = 2.426] [Validation loss = 4.974]\n","[Epoch : 147]  [Training accuracy = 38.67%] [Validation accuracy = 5.30%] [Best = 5.59%]  [Training loss = 2.503] [Validation loss = 4.985]\n","[Epoch : 148]  [Training accuracy = 39.05%] [Validation accuracy = 5.17%] [Best = 5.59%]  [Training loss = 2.456] [Validation loss = 4.982]\n","[Epoch : 149]  [Training accuracy = 37.67%] [Validation accuracy = 4.84%] [Best = 5.59%]  [Training loss = 2.467] [Validation loss = 4.991]\n","[Epoch : 150]  [Training accuracy = 39.31%] [Validation accuracy = 5.04%] [Best = 5.59%]  [Training loss = 2.436] [Validation loss = 4.993]\n","[Epoch : 151]  [Training accuracy = 39.15%] [Validation accuracy = 5.24%] [Best = 5.59%]  [Training loss = 2.421] [Validation loss = 5.010]\n","[Epoch : 152]  [Training accuracy = 41.73%] [Validation accuracy = 5.06%] [Best = 5.59%]  [Training loss = 2.337] [Validation loss = 4.993]\n","[Epoch : 153]  [Training accuracy = 39.42%] [Validation accuracy = 5.19%] [Best = 5.59%]  [Training loss = 2.369] [Validation loss = 4.980]\n","[Epoch : 154]  [Training accuracy = 38.79%] [Validation accuracy = 4.98%] [Best = 5.59%]  [Training loss = 2.428] [Validation loss = 4.996]\n","[Epoch : 155]  [Training accuracy = 40.37%] [Validation accuracy = 5.12%] [Best = 5.59%]  [Training loss = 2.333] [Validation loss = 5.056]\n","[Epoch : 156]  [Training accuracy = 43.15%] [Validation accuracy = 5.17%] [Best = 5.59%]  [Training loss = 2.329] [Validation loss = 5.022]\n","[Epoch : 157]  [Training accuracy = 42.94%] [Validation accuracy = 5.12%] [Best = 5.59%]  [Training loss = 2.283] [Validation loss = 5.044]\n","[Epoch : 158]  [Training accuracy = 39.98%] [Validation accuracy = 5.09%] [Best = 5.59%]  [Training loss = 2.419] [Validation loss = 5.042]\n","[Epoch : 159]  [Training accuracy = 41.55%] [Validation accuracy = 4.99%] [Best = 5.59%]  [Training loss = 2.380] [Validation loss = 5.015]\n","[Epoch : 160]  [Training accuracy = 42.35%] [Validation accuracy = 4.88%] [Best = 5.59%]  [Training loss = 2.293] [Validation loss = 5.041]\n","[Epoch : 161]  [Training accuracy = 42.94%] [Validation accuracy = 4.98%] [Best = 5.59%]  [Training loss = 2.308] [Validation loss = 5.017]\n","[Epoch : 162]  [Training accuracy = 41.44%] [Validation accuracy = 4.77%] [Best = 5.59%]  [Training loss = 2.353] [Validation loss = 5.047]\n","[Epoch : 163]  [Training accuracy = 43.27%] [Validation accuracy = 4.94%] [Best = 5.59%]  [Training loss = 2.347] [Validation loss = 5.048]\n","[Epoch : 164]  [Training accuracy = 41.39%] [Validation accuracy = 5.17%] [Best = 5.59%]  [Training loss = 2.314] [Validation loss = 5.045]\n","[Epoch : 165]  [Training accuracy = 43.93%] [Validation accuracy = 4.93%] [Best = 5.59%]  [Training loss = 2.309] [Validation loss = 5.062]\n","Training stopped by early_stop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZLluQ8or14R9"},"source":["J'ai sauvegardé les meilleurs paramètres, car ils pourront constituer un bon point de départ pour les tests suivants."]},{"cell_type":"markdown","metadata":{"id":"Ieo1n8eg2Myq"},"source":["---\n","## 2\\. Transfert d'EfficientNetB4 vers le modèle Baseline"]},{"cell_type":"markdown","metadata":{"id":"odOBt1QsHR_Z"},"source":["### 2.1. Premier essai : le modèle cible n'est pas pré-entraîné"]},{"cell_type":"code","metadata":{"id":"wQaCO-yxbzC-"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xuGI5qqgmGSh"},"source":["source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_target.mycnn3(num_classes=120)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMG_lBVpnCtP"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z_latVBjo4i2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605306782589,"user_tz":-60,"elapsed":17858748,"user":{"displayName":"S FRIOT","photoUrl":"","userId":"08174580811350672782"}},"outputId":"de74bf2e-9ff9-4343-f048-b574f0287798"},"source":["l2t_model.train(IMAGES_DRIVE, epochs=50, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_mycnn_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-13 17:35:26,834] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-aae3090b-91c1-4814-b659-ecfe8712cb56.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-13 18:32:10,542] [main] Best model is saved\n","[2020-11-13 18:32:10,612] [main] Last model is saved\n","[2020-11-13 18:32:10,613] [main] [Epoch : 1]  [Training accuracy = 0.76%] [Validation accuracy = 0.76%] [Best = 0.76%]  [Training loss = 5.334] [Validation loss = 5.354]\n","[2020-11-13 18:39:57,163] [main] Last model is saved\n","[2020-11-13 18:39:57,167] [main] [Epoch : 2]  [Training accuracy = 0.86%] [Validation accuracy = 0.76%] [Best = 0.76%]  [Training loss = 5.347] [Validation loss = 5.371]\n","[2020-11-13 18:47:44,071] [main] Best model is saved\n","[2020-11-13 18:47:44,141] [main] Last model is saved\n","[2020-11-13 18:47:44,144] [main] [Epoch : 3]  [Training accuracy = 0.76%] [Validation accuracy = 1.12%] [Best = 1.12%]  [Training loss = 4.936] [Validation loss = 4.946]\n","[2020-11-13 18:55:32,014] [main] Last model is saved\n","[2020-11-13 18:55:32,020] [main] [Epoch : 4]  [Training accuracy = 0.91%] [Validation accuracy = 0.91%] [Best = 1.12%]  [Training loss = 4.855] [Validation loss = 4.859]\n","[2020-11-13 19:03:19,927] [main] Last model is saved\n","[2020-11-13 19:03:19,931] [main] [Epoch : 5]  [Training accuracy = 1.06%] [Validation accuracy = 1.06%] [Best = 1.12%]  [Training loss = 4.821] [Validation loss = 4.822]\n","[2020-11-13 19:11:07,682] [main] Last model is saved\n","[2020-11-13 19:11:07,686] [main] [Epoch : 6]  [Training accuracy = 0.98%] [Validation accuracy = 0.94%] [Best = 1.12%]  [Training loss = 4.791] [Validation loss = 4.794]\n","[2020-11-13 19:18:54,672] [main] Last model is saved\n","[2020-11-13 19:18:54,676] [main] [Epoch : 7]  [Training accuracy = 0.98%] [Validation accuracy = 0.97%] [Best = 1.12%]  [Training loss = 4.797] [Validation loss = 4.799]\n","[2020-11-13 19:26:39,805] [main] Best model is saved\n","[2020-11-13 19:26:40,193] [main] Last model is saved\n","[2020-11-13 19:26:40,196] [main] [Epoch : 8]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.785] [Validation loss = 4.787]\n","[2020-11-13 19:34:25,187] [main] Last model is saved\n","[2020-11-13 19:34:25,191] [main] [Epoch : 9]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-13 19:42:10,056] [main] Last model is saved\n","[2020-11-13 19:42:10,060] [main] [Epoch : 10]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-13 19:49:55,414] [main] Last model is saved\n","[2020-11-13 19:49:55,418] [main] [Epoch : 11]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.784]\n","[2020-11-13 19:57:41,029] [main] Best model is saved\n","[2020-11-13 19:57:41,101] [main] Last model is saved\n","[2020-11-13 19:57:41,104] [main] [Epoch : 12]  [Training accuracy = 1.14%] [Validation accuracy = 1.27%] [Best = 1.27%]  [Training loss = 4.782] [Validation loss = 4.785]\n","[2020-11-13 20:05:27,940] [main] Last model is saved\n","[2020-11-13 20:05:27,944] [main] [Epoch : 13]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.782] [Validation loss = 4.784]\n","[2020-11-13 20:13:14,409] [main] Last model is saved\n","[2020-11-13 20:13:14,413] [main] [Epoch : 14]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.782] [Validation loss = 4.784]\n","[2020-11-13 20:21:02,265] [main] Last model is saved\n","[2020-11-13 20:21:02,267] [main] [Epoch : 15]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.782] [Validation loss = 4.783]\n","[2020-11-13 20:28:49,601] [main] Last model is saved\n","[2020-11-13 20:28:49,605] [main] [Epoch : 16]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.782] [Validation loss = 4.783]\n","[2020-11-13 20:36:36,199] [main] Last model is saved\n","[2020-11-13 20:36:36,203] [main] [Epoch : 17]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.781] [Validation loss = 4.783]\n","[2020-11-13 20:44:21,288] [main] Last model is saved\n","[2020-11-13 20:44:21,292] [main] [Epoch : 18]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.781] [Validation loss = 4.783]\n","[2020-11-13 20:52:06,068] [main] Last model is saved\n","[2020-11-13 20:52:06,072] [main] [Epoch : 19]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.781] [Validation loss = 4.782]\n","[2020-11-13 20:59:53,064] [main] Last model is saved\n","[2020-11-13 20:59:53,068] [main] [Epoch : 20]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.781] [Validation loss = 4.782]\n","[2020-11-13 21:07:40,346] [main] Last model is saved\n","[2020-11-13 21:07:40,350] [main] [Epoch : 21]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.780] [Validation loss = 4.782]\n","[2020-11-13 21:15:27,469] [main] Last model is saved\n","[2020-11-13 21:15:27,473] [main] [Epoch : 22]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.780] [Validation loss = 4.782]\n","[2020-11-13 21:23:15,430] [main] Last model is saved\n","[2020-11-13 21:23:15,435] [main] [Epoch : 23]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.780] [Validation loss = 4.782]\n","[2020-11-13 21:31:03,036] [main] Last model is saved\n","[2020-11-13 21:31:03,040] [main] [Epoch : 24]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.780] [Validation loss = 4.781]\n","[2020-11-13 21:38:50,222] [main] Last model is saved\n","[2020-11-13 21:38:50,226] [main] [Epoch : 25]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.780] [Validation loss = 4.781]\n","[2020-11-13 21:46:36,971] [main] Last model is saved\n","[2020-11-13 21:46:36,975] [main] [Epoch : 26]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.779] [Validation loss = 4.781]\n","[2020-11-13 21:54:22,622] [main] Last model is saved\n","[2020-11-13 21:54:22,626] [main] [Epoch : 27]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.779] [Validation loss = 4.781]\n","[2020-11-13 22:02:08,351] [main] Last model is saved\n","[2020-11-13 22:02:08,354] [main] [Epoch : 28]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.779] [Validation loss = 4.781]\n","[2020-11-13 22:09:52,756] [main] Last model is saved\n","[2020-11-13 22:09:52,761] [main] [Epoch : 29]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.779] [Validation loss = 4.781]\n","[2020-11-13 22:17:37,215] [main] Last model is saved\n","[2020-11-13 22:17:37,218] [main] [Epoch : 30]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.779] [Validation loss = 4.780]\n","[2020-11-13 22:25:21,037] [main] Last model is saved\n","[2020-11-13 22:25:21,040] [main] [Epoch : 31]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.779] [Validation loss = 4.780]\n","[2020-11-13 22:33:04,383] [main] Last model is saved\n","[2020-11-13 22:33:04,387] [main] [Epoch : 32]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.27%]  [Training loss = 4.779] [Validation loss = 4.780]\n","[2020-11-13 22:33:04,396] [main] Training stopped by early_stop\n","[2020-11-13 22:33:04,398] [main] Training is done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hkyokgIWaTQ9"},"source":["La performance est moins bonne avec la méthode l2t-ww depuis EfficientNetB4, qu'avec une optimisation de base avec Adam."]},{"cell_type":"markdown","metadata":{"id":"b1cYwTo4GZ_k"},"source":["Je fais un autre test en chargeant le modèle cible pré-entraîné."]},{"cell_type":"markdown","metadata":{"id":"Gp4bOAc5Hbji"},"source":["### 2.2. Deuxième essai : le modèle cible est pré-entraîné"]},{"cell_type":"code","metadata":{"id":"5Eq480ixZs4Z"},"source":["source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_target.mycnn3(num_classes=120, pretrained=True,\n","                                url_pretrained=\"models/baseline_cnn.pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u5PgfRHOZs4i"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUYFm1LWZs4n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605320041028,"user_tz":-60,"elapsed":12985502,"user":{"displayName":"S FRIOT","photoUrl":"","userId":"08174580811350672782"}},"outputId":"eeeff796-9fc8-4757-b242-13c3b2b45ec1"},"source":["l2t_model.train(IMAGES_DRIVE, epochs=200, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_mycnn_pretrained_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-13 22:37:39,390] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-aae3090b-91c1-4814-b659-ecfe8712cb56.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-13 22:45:23,572] [main] Best model is saved\n","[2020-11-13 22:45:23,651] [main] Last model is saved\n","[2020-11-13 22:45:23,652] [main] [Epoch : 1]  [Training accuracy = 0.91%] [Validation accuracy = 0.79%] [Best = 0.79%]  [Training loss = 5.398] [Validation loss = 5.433]\n","[2020-11-13 22:53:07,311] [main] Best model is saved\n","[2020-11-13 22:53:07,382] [main] Last model is saved\n","[2020-11-13 22:53:07,385] [main] [Epoch : 2]  [Training accuracy = 1.14%] [Validation accuracy = 1.12%] [Best = 1.12%]  [Training loss = 4.970] [Validation loss = 4.980]\n","[2020-11-13 23:00:50,840] [main] Last model is saved\n","[2020-11-13 23:00:50,844] [main] [Epoch : 3]  [Training accuracy = 0.91%] [Validation accuracy = 0.79%] [Best = 1.12%]  [Training loss = 4.905] [Validation loss = 4.914]\n","[2020-11-13 23:08:34,608] [main] Last model is saved\n","[2020-11-13 23:08:34,612] [main] [Epoch : 4]  [Training accuracy = 0.91%] [Validation accuracy = 0.94%] [Best = 1.12%]  [Training loss = 4.805] [Validation loss = 4.816]\n","[2020-11-13 23:16:18,037] [main] Last model is saved\n","[2020-11-13 23:16:18,040] [main] [Epoch : 5]  [Training accuracy = 1.06%] [Validation accuracy = 0.64%] [Best = 1.12%]  [Training loss = 4.790] [Validation loss = 4.792]\n","[2020-11-13 23:24:01,414] [main] Last model is saved\n","[2020-11-13 23:24:01,417] [main] [Epoch : 6]  [Training accuracy = 1.06%] [Validation accuracy = 1.06%] [Best = 1.12%]  [Training loss = 4.785] [Validation loss = 4.786]\n","[2020-11-13 23:31:44,885] [main] Last model is saved\n","[2020-11-13 23:31:44,888] [main] [Epoch : 7]  [Training accuracy = 1.06%] [Validation accuracy = 1.06%] [Best = 1.12%]  [Training loss = 4.785] [Validation loss = 4.786]\n","[2020-11-13 23:39:28,726] [main] Best model is saved\n","[2020-11-13 23:39:28,793] [main] Last model is saved\n","[2020-11-13 23:39:28,795] [main] [Epoch : 8]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.784] [Validation loss = 4.785]\n","[2020-11-13 23:47:11,728] [main] Last model is saved\n","[2020-11-13 23:47:11,732] [main] [Epoch : 9]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.784] [Validation loss = 4.785]\n","[2020-11-13 23:54:55,807] [main] Last model is saved\n","[2020-11-13 23:54:55,811] [main] [Epoch : 10]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.784] [Validation loss = 4.786]\n","[2020-11-14 00:02:39,134] [main] Last model is saved\n","[2020-11-14 00:02:39,138] [main] [Epoch : 11]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.784] [Validation loss = 4.785]\n","[2020-11-14 00:10:23,195] [main] Last model is saved\n","[2020-11-14 00:10:23,199] [main] [Epoch : 12]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.793] [Validation loss = 4.794]\n","[2020-11-14 00:18:06,267] [main] Last model is saved\n","[2020-11-14 00:18:06,270] [main] [Epoch : 13]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.784] [Validation loss = 4.785]\n","[2020-11-14 00:25:49,763] [main] Last model is saved\n","[2020-11-14 00:25:49,765] [main] [Epoch : 14]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.784] [Validation loss = 4.785]\n","[2020-11-14 00:33:33,207] [main] Last model is saved\n","[2020-11-14 00:33:33,211] [main] [Epoch : 15]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-14 00:41:17,021] [main] Last model is saved\n","[2020-11-14 00:41:17,024] [main] [Epoch : 16]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.788] [Validation loss = 4.790]\n","[2020-11-14 00:49:00,109] [main] Last model is saved\n","[2020-11-14 00:49:00,113] [main] [Epoch : 17]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.784] [Validation loss = 4.785]\n","[2020-11-14 00:56:44,011] [main] Last model is saved\n","[2020-11-14 00:56:44,017] [main] [Epoch : 18]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-14 01:04:27,704] [main] Last model is saved\n","[2020-11-14 01:04:27,707] [main] [Epoch : 19]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.793] [Validation loss = 4.796]\n","[2020-11-14 01:12:11,680] [main] Last model is saved\n","[2020-11-14 01:12:11,683] [main] [Epoch : 20]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.784] [Validation loss = 4.785]\n","[2020-11-14 01:19:54,910] [main] Last model is saved\n","[2020-11-14 01:19:54,913] [main] [Epoch : 21]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-14 01:27:38,193] [main] Last model is saved\n","[2020-11-14 01:27:38,197] [main] [Epoch : 22]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-14 01:35:21,570] [main] Last model is saved\n","[2020-11-14 01:35:21,572] [main] [Epoch : 23]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-14 01:43:05,187] [main] Last model is saved\n","[2020-11-14 01:43:05,191] [main] [Epoch : 24]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-14 01:50:48,514] [main] Last model is saved\n","[2020-11-14 01:50:48,517] [main] [Epoch : 25]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-14 01:58:32,047] [main] Last model is saved\n","[2020-11-14 01:58:32,051] [main] [Epoch : 26]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-14 02:06:15,637] [main] Last model is saved\n","[2020-11-14 02:06:15,640] [main] [Epoch : 27]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-14 02:13:59,977] [main] Last model is saved\n","[2020-11-14 02:13:59,980] [main] [Epoch : 28]  [Training accuracy = 1.21%] [Validation accuracy = 1.21%] [Best = 1.21%]  [Training loss = 4.783] [Validation loss = 4.785]\n","[2020-11-14 02:13:59,990] [main] Training stopped by early_stop\n","[2020-11-14 02:13:59,992] [main] Training is done\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Yeaiu3m5GioK"},"source":["La performance ne s'améliore pas en basant l'entraînement sur le modèle pré-entraîné.  \n","Le modèle cible est trop simple pour apprendre correctement du transfert de connaissance."]},{"cell_type":"markdown","metadata":{"id":"1dxHw2EI9jDA"},"source":["---\n","## 3\\. Transfert d'EfficientNetB4 vers VGG16"]},{"cell_type":"markdown","metadata":{"id":"2IDJyTXyGq3P"},"source":["J'essaie désormais de voir l'efficacité de la méthode l2t-ww avec comme réseau cible VGG16 et comme réseau source EfficientNetB4."]},{"cell_type":"markdown","metadata":{"id":"b03ybE1HHphB"},"source":["### 3.1. Premier essai : VGG16 n'est pas pré-entraîné"]},{"cell_type":"code","metadata":{"id":"zM5dshwB9jU0"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ufumn27o9jcT"},"source":["source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16(num_classes=120, original_classifier=False,\n","                            pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Louamleu9jsC"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtQnlh0j9vwk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cfd0dfe8-b478-419c-c36d-2c97de74b881"},"source":["l2t_model.train(IMAGES_DRIVE, epochs=200, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vgg_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-14 09:02:50,788] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-be98f530-0030-4bbd-ba03-9efb33eacb40.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-14 09:58:07,520] [main] Best model is saved\n","[2020-11-14 09:58:09,175] [main] Last model is saved\n","[2020-11-14 09:58:09,178] [main] [Epoch : 1]  [Training accuracy = 0.76%] [Validation accuracy = 0.73%] [Best = 0.73%]  [Training loss = nan] [Validation loss = nan]\n","[2020-11-14 10:20:44,457] [main] Last model is saved\n","[2020-11-14 10:20:44,459] [main] [Epoch : 2]  [Training accuracy = 0.76%] [Validation accuracy = 0.73%] [Best = 0.73%]  [Training loss = nan] [Validation loss = nan]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-X2OR9L0G9FZ"},"source":["Je constate une explosion du gradient dès la première époque. J'exécute un nouvel essai avec un réseau cible pré-entraîné afin de voir si cela permet de limiter l'instabilité du gradient."]},{"cell_type":"markdown","metadata":{"id":"b_B9cqg-Hxsa"},"source":["### 3.2. Deuxième essai : VGG16 est pré-entraîné"]},{"cell_type":"code","metadata":{"id":"p3D85Ah3ZtiZ"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWi58zj6Ztiz","colab":{"base_uri":"https://localhost:8080/","height":103,"referenced_widgets":["10143c7b8f244cf1864ee86925fb238e","d84d6e7f76a2482198a26c4424cb8ebd","6da24aeee76d4b85b3b93e9a07616094","cfe07a21dcd340bdb19a65f8401a90f9","6ed5c00ca3694905b2b2bc29ba5b8940","8caca4a95da94cba92d66b7e42709459","c5f04a04e2834917829e34b57039f266","4d03977cd553460f91c208490c73c647"]},"executionInfo":{"status":"ok","timestamp":1605352299237,"user_tz":-60,"elapsed":9728,"user":{"displayName":"S FRIOT","photoUrl":"","userId":"08174580811350672782"}},"outputId":"f49ec83c-3ae6-4e41-c093-a2d5e8546304"},"source":["source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16(num_classes=120, original_classifier=False,\n","                            pretrained=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10143c7b8f244cf1864ee86925fb238e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fVkgHHzQZti4"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DwFqUIQnZti9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"407e72a7-416d-42f7-db15-b968f3b31a08"},"source":["l2t_model.train(IMAGES_DRIVE, epochs=200, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vgg_pretrained_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-14 11:12:05,532] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-549bc2b4-c269-4194-a2d6-7ea68dc978db.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-14 12:05:39,138] [main] Best model is saved\n","[2020-11-14 12:05:39,812] [main] Last model is saved\n","[2020-11-14 12:05:39,814] [main] [Epoch : 1]  [Training accuracy = 0.76%] [Validation accuracy = 0.73%] [Best = 0.73%]  [Training loss = nan] [Validation loss = nan]\n","[2020-11-14 12:18:09,408] [main] Last model is saved\n","[2020-11-14 12:18:09,412] [main] [Epoch : 2]  [Training accuracy = 0.76%] [Validation accuracy = 0.73%] [Best = 0.73%]  [Training loss = nan] [Validation loss = nan]\n","[2020-11-14 12:30:38,652] [main] Last model is saved\n","[2020-11-14 12:30:38,655] [main] [Epoch : 3]  [Training accuracy = 0.76%] [Validation accuracy = 0.73%] [Best = 0.73%]  [Training loss = nan] [Validation loss = nan]\n","[2020-11-14 12:43:07,598] [main] Last model is saved\n","[2020-11-14 12:43:07,602] [main] [Epoch : 4]  [Training accuracy = 0.76%] [Validation accuracy = 0.73%] [Best = 0.73%]  [Training loss = nan] [Validation loss = nan]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VAu0l3PzH8Bn"},"source":["Je constate une nouvelle fois une explosion du gradient. Je dois utiliser VGG16 avec Batch Normalization si je veux pouvoir tester la méthode l2t-ww."]},{"cell_type":"markdown","metadata":{"id":"GuxCr3iXG76k"},"source":["---\n","## 4\\. Transfert d'EfficientNetB4 vers VGG16 avec Batch Normalization"]},{"cell_type":"markdown","metadata":{"id":"yv8JH18pIqfE"},"source":["### 4.1. Pré-entraînement de VGG16 avec Batch Normalization"]},{"cell_type":"markdown","metadata":{"id":"nlF-x2qjIzfw"},"source":["J'utilise VGG16 avec Batch Normalization avec une sortie en Global Average Pooling et une classification avec une couche dense composée de 120 sorties.  \n","J'optimise ce modèle sur les données du Stanford Dogs Dataset en comparant la performance des algorithmes Adam et SGD-Nesterov."]},{"cell_type":"code","metadata":{"id":"3RHSpWS4G7PH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605515302130,"user_tz":-60,"elapsed":1807,"user":{"displayName":"S FRIOT","photoUrl":"","userId":"08174580811350672782"}},"outputId":"79d0a760-a57e-4a94-9584-2d9e0ad9b03a"},"source":["model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                       pretrained=True)\n","model.freeze_layers(last_layer=-1)\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), eps=1e-7)\n","# note : eps=1e-7 to get the same epsilon than Tensorflow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 : features\n","freezed\n","1 : avgpool\n","freezed\n","2 : classifier\n","unfreezed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kn01MwnpHicH"},"source":["loaders = sf_load.get_dataset(IMAGES_DRIVE, model, mini_data=0.1, stratify=True,\n","                              batch_size=64, with_data_augmentation=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"epB0NA57HuPl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605519476013,"user_tz":-60,"elapsed":4154729,"user":{"displayName":"S FRIOT","photoUrl":"","userId":"08174580811350672782"}},"outputId":"dea8ce6b-012d-4cf6-8196-86041ff51395"},"source":["transferlearning_on_targettask(model, criterion, optimizer, loaders, \"vgg16bn_120_adam\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Epoch : 0]  [Training accuracy = 1.79%] [Validation accuracy = 8.03%] [Best = 8.03%]  [Training loss = 4.742] [Validation loss = 4.604]\n","[Epoch : 1]  [Training accuracy = 22.39%] [Validation accuracy = 25.42%] [Best = 25.42%]  [Training loss = 4.484] [Validation loss = 4.431]\n","[Epoch : 2]  [Training accuracy = 43.71%] [Validation accuracy = 34.46%] [Best = 34.46%]  [Training loss = 4.276] [Validation loss = 4.266]\n","[Epoch : 3]  [Training accuracy = 57.16%] [Validation accuracy = 41.46%] [Best = 41.46%]  [Training loss = 4.078] [Validation loss = 4.107]\n","[Epoch : 4]  [Training accuracy = 67.18%] [Validation accuracy = 45.68%] [Best = 45.68%]  [Training loss = 3.887] [Validation loss = 3.955]\n","[Epoch : 5]  [Training accuracy = 74.77%] [Validation accuracy = 49.03%] [Best = 49.03%]  [Training loss = 3.704] [Validation loss = 3.812]\n","[Epoch : 6]  [Training accuracy = 78.54%] [Validation accuracy = 51.66%] [Best = 51.66%]  [Training loss = 3.529] [Validation loss = 3.676]\n","[Epoch : 7]  [Training accuracy = 81.45%] [Validation accuracy = 53.59%] [Best = 53.59%]  [Training loss = 3.362] [Validation loss = 3.547]\n","[Epoch : 8]  [Training accuracy = 84.12%] [Validation accuracy = 55.10%] [Best = 55.10%]  [Training loss = 3.203] [Validation loss = 3.426]\n","[Epoch : 9]  [Training accuracy = 85.76%] [Validation accuracy = 56.61%] [Best = 56.61%]  [Training loss = 3.052] [Validation loss = 3.311]\n","[Epoch : 10]  [Training accuracy = 87.25%] [Validation accuracy = 57.61%] [Best = 57.61%]  [Training loss = 2.909] [Validation loss = 3.204]\n","[Epoch : 11]  [Training accuracy = 88.34%] [Validation accuracy = 58.45%] [Best = 58.45%]  [Training loss = 2.773] [Validation loss = 3.103]\n","[Epoch : 12]  [Training accuracy = 89.53%] [Validation accuracy = 59.39%] [Best = 59.39%]  [Training loss = 2.645] [Validation loss = 3.007]\n","[Epoch : 13]  [Training accuracy = 90.48%] [Validation accuracy = 60.44%] [Best = 60.44%]  [Training loss = 2.523] [Validation loss = 2.918]\n","[Epoch : 14]  [Training accuracy = 91.00%] [Validation accuracy = 61.22%] [Best = 61.22%]  [Training loss = 2.408] [Validation loss = 2.835]\n","[Epoch : 15]  [Training accuracy = 91.74%] [Validation accuracy = 61.94%] [Best = 61.94%]  [Training loss = 2.300] [Validation loss = 2.756]\n","[Epoch : 16]  [Training accuracy = 92.19%] [Validation accuracy = 62.55%] [Best = 62.55%]  [Training loss = 2.198] [Validation loss = 2.682]\n","[Epoch : 17]  [Training accuracy = 92.63%] [Validation accuracy = 63.03%] [Best = 63.03%]  [Training loss = 2.102] [Validation loss = 2.613]\n","[Epoch : 18]  [Training accuracy = 92.86%] [Validation accuracy = 63.27%] [Best = 63.27%]  [Training loss = 2.011] [Validation loss = 2.549]\n","[Epoch : 19]  [Training accuracy = 93.15%] [Validation accuracy = 63.66%] [Best = 63.66%]  [Training loss = 1.926] [Validation loss = 2.488]\n","[Epoch : 20]  [Training accuracy = 93.90%] [Validation accuracy = 63.90%] [Best = 63.90%]  [Training loss = 1.845] [Validation loss = 2.431]\n","[Epoch : 21]  [Training accuracy = 94.12%] [Validation accuracy = 64.14%] [Best = 64.14%]  [Training loss = 1.770] [Validation loss = 2.378]\n","[Epoch : 22]  [Training accuracy = 94.64%] [Validation accuracy = 64.35%] [Best = 64.35%]  [Training loss = 1.698] [Validation loss = 2.327]\n","[Epoch : 23]  [Training accuracy = 95.01%] [Validation accuracy = 64.47%] [Best = 64.47%]  [Training loss = 1.631] [Validation loss = 2.280]\n","[Epoch : 24]  [Training accuracy = 95.68%] [Validation accuracy = 64.50%] [Best = 64.50%]  [Training loss = 1.567] [Validation loss = 2.236]\n","[Epoch : 25]  [Training accuracy = 96.06%] [Validation accuracy = 64.50%] [Best = 64.50%]  [Training loss = 1.507] [Validation loss = 2.194]\n","[Epoch : 26]  [Training accuracy = 96.21%] [Validation accuracy = 64.74%] [Best = 64.74%]  [Training loss = 1.450] [Validation loss = 2.154]\n","[Epoch : 27]  [Training accuracy = 96.43%] [Validation accuracy = 64.98%] [Best = 64.98%]  [Training loss = 1.396] [Validation loss = 2.117]\n","[Epoch : 28]  [Training accuracy = 96.65%] [Validation accuracy = 65.07%] [Best = 65.07%]  [Training loss = 1.345] [Validation loss = 2.082]\n","[Epoch : 29]  [Training accuracy = 96.73%] [Validation accuracy = 65.34%] [Best = 65.34%]  [Training loss = 1.297] [Validation loss = 2.049]\n","[Epoch : 30]  [Training accuracy = 96.80%] [Validation accuracy = 65.34%] [Best = 65.34%]  [Training loss = 1.251] [Validation loss = 2.017]\n","[Epoch : 31]  [Training accuracy = 96.95%] [Validation accuracy = 65.40%] [Best = 65.40%]  [Training loss = 1.207] [Validation loss = 1.988]\n","[Epoch : 32]  [Training accuracy = 97.17%] [Validation accuracy = 65.52%] [Best = 65.52%]  [Training loss = 1.166] [Validation loss = 1.960]\n","[Epoch : 33]  [Training accuracy = 97.32%] [Validation accuracy = 65.67%] [Best = 65.67%]  [Training loss = 1.127] [Validation loss = 1.933]\n","[Epoch : 34]  [Training accuracy = 97.54%] [Validation accuracy = 65.82%] [Best = 65.82%]  [Training loss = 1.090] [Validation loss = 1.908]\n","[Epoch : 35]  [Training accuracy = 97.69%] [Validation accuracy = 65.85%] [Best = 65.85%]  [Training loss = 1.054] [Validation loss = 1.884]\n","[Epoch : 36]  [Training accuracy = 97.77%] [Validation accuracy = 65.94%] [Best = 65.94%]  [Training loss = 1.020] [Validation loss = 1.861]\n","[Epoch : 37]  [Training accuracy = 97.92%] [Validation accuracy = 66.18%] [Best = 66.18%]  [Training loss = 0.988] [Validation loss = 1.839]\n","[Epoch : 38]  [Training accuracy = 97.92%] [Validation accuracy = 66.09%] [Best = 66.18%]  [Training loss = 0.957] [Validation loss = 1.818]\n","[Epoch : 39]  [Training accuracy = 98.14%] [Validation accuracy = 66.03%] [Best = 66.18%]  [Training loss = 0.927] [Validation loss = 1.798]\n","[Epoch : 40]  [Training accuracy = 98.14%] [Validation accuracy = 65.93%] [Best = 66.18%]  [Training loss = 0.899] [Validation loss = 1.780]\n","[Epoch : 41]  [Training accuracy = 98.51%] [Validation accuracy = 65.96%] [Best = 66.18%]  [Training loss = 0.872] [Validation loss = 1.762]\n","[Epoch : 42]  [Training accuracy = 98.66%] [Validation accuracy = 65.93%] [Best = 66.18%]  [Training loss = 0.847] [Validation loss = 1.744]\n","[Epoch : 43]  [Training accuracy = 98.74%] [Validation accuracy = 66.12%] [Best = 66.18%]  [Training loss = 0.822] [Validation loss = 1.728]\n","[Epoch : 44]  [Training accuracy = 98.88%] [Validation accuracy = 66.06%] [Best = 66.18%]  [Training loss = 0.798] [Validation loss = 1.712]\n","[Epoch : 45]  [Training accuracy = 98.96%] [Validation accuracy = 66.03%] [Best = 66.18%]  [Training loss = 0.775] [Validation loss = 1.697]\n","[Epoch : 46]  [Training accuracy = 98.96%] [Validation accuracy = 66.12%] [Best = 66.18%]  [Training loss = 0.753] [Validation loss = 1.683]\n","[Epoch : 47]  [Training accuracy = 98.96%] [Validation accuracy = 66.03%] [Best = 66.18%]  [Training loss = 0.732] [Validation loss = 1.669]\n","[Epoch : 48]  [Training accuracy = 99.03%] [Validation accuracy = 66.03%] [Best = 66.18%]  [Training loss = 0.712] [Validation loss = 1.656]\n","[Epoch : 49]  [Training accuracy = 99.03%] [Validation accuracy = 66.09%] [Best = 66.18%]  [Training loss = 0.693] [Validation loss = 1.643]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZE6bJFh3a5A2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605522613950,"user_tz":-60,"elapsed":2608,"user":{"displayName":"S FRIOT","photoUrl":"","userId":"08174580811350672782"}},"outputId":"7a9f9a7c-29c1-4a34-8123-4275ad625a8f"},"source":["model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                       pretrained=True)\n","model.freeze_layers(last_layer=-1)\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 : features\n","freezed\n","1 : avgpool\n","freezed\n","2 : classifier\n","unfreezed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6L3evb-Ra5A-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605532948589,"user_tz":-60,"elapsed":10333855,"user":{"displayName":"S FRIOT","photoUrl":"","userId":"08174580811350672782"}},"outputId":"287750ad-5bf7-42cd-a9d9-17c1a2797ec2"},"source":["transferlearning_on_targettask(model, criterion, optimizer, loaders,\n","                               \"vgg16bn_120_sgd\", nb_epochs=200, patience=20)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Epoch : 0]  [Training accuracy = 1.91%] [Validation accuracy = 5.61%] [Best = 5.61%]  [Training loss = 4.781] [Validation loss = 4.755]\n","[Epoch : 1]  [Training accuracy = 9.66%] [Validation accuracy = 13.49%] [Best = 13.49%]  [Training loss = 4.729] [Validation loss = 4.707]\n","[Epoch : 2]  [Training accuracy = 17.82%] [Validation accuracy = 17.90%] [Best = 17.90%]  [Training loss = 4.673] [Validation loss = 4.659]\n","[Epoch : 3]  [Training accuracy = 23.18%] [Validation accuracy = 20.34%] [Best = 20.34%]  [Training loss = 4.617] [Validation loss = 4.612]\n","[Epoch : 4]  [Training accuracy = 27.98%] [Validation accuracy = 22.63%] [Best = 22.63%]  [Training loss = 4.562] [Validation loss = 4.566]\n","[Epoch : 5]  [Training accuracy = 30.80%] [Validation accuracy = 24.89%] [Best = 24.89%]  [Training loss = 4.509] [Validation loss = 4.521]\n","[Epoch : 6]  [Training accuracy = 34.15%] [Validation accuracy = 26.58%] [Best = 26.58%]  [Training loss = 4.456] [Validation loss = 4.476]\n","[Epoch : 7]  [Training accuracy = 35.74%] [Validation accuracy = 28.19%] [Best = 28.19%]  [Training loss = 4.404] [Validation loss = 4.432]\n","[Epoch : 8]  [Training accuracy = 37.95%] [Validation accuracy = 29.46%] [Best = 29.46%]  [Training loss = 4.353] [Validation loss = 4.389]\n","[Epoch : 9]  [Training accuracy = 39.29%] [Validation accuracy = 30.66%] [Best = 30.66%]  [Training loss = 4.302] [Validation loss = 4.346]\n","[Epoch : 10]  [Training accuracy = 41.45%] [Validation accuracy = 32.07%] [Best = 32.07%]  [Training loss = 4.252] [Validation loss = 4.303]\n","[Epoch : 11]  [Training accuracy = 43.06%] [Validation accuracy = 32.85%] [Best = 32.85%]  [Training loss = 4.203] [Validation loss = 4.262]\n","[Epoch : 12]  [Training accuracy = 44.88%] [Validation accuracy = 34.17%] [Best = 34.17%]  [Training loss = 4.154] [Validation loss = 4.220]\n","[Epoch : 13]  [Training accuracy = 46.14%] [Validation accuracy = 35.32%] [Best = 35.32%]  [Training loss = 4.106] [Validation loss = 4.180]\n","[Epoch : 14]  [Training accuracy = 48.08%] [Validation accuracy = 36.10%] [Best = 36.10%]  [Training loss = 4.058] [Validation loss = 4.139]\n","[Epoch : 15]  [Training accuracy = 49.42%] [Validation accuracy = 37.11%] [Best = 37.11%]  [Training loss = 4.011] [Validation loss = 4.099]\n","[Epoch : 16]  [Training accuracy = 51.25%] [Validation accuracy = 37.71%] [Best = 37.71%]  [Training loss = 3.964] [Validation loss = 4.060]\n","[Epoch : 17]  [Training accuracy = 52.72%] [Validation accuracy = 38.73%] [Best = 38.73%]  [Training loss = 3.918] [Validation loss = 4.021]\n","[Epoch : 18]  [Training accuracy = 53.91%] [Validation accuracy = 39.39%] [Best = 39.39%]  [Training loss = 3.872] [Validation loss = 3.983]\n","[Epoch : 19]  [Training accuracy = 55.99%] [Validation accuracy = 40.38%] [Best = 40.38%]  [Training loss = 3.827] [Validation loss = 3.945]\n","[Epoch : 20]  [Training accuracy = 57.26%] [Validation accuracy = 41.34%] [Best = 41.34%]  [Training loss = 3.783] [Validation loss = 3.908]\n","[Epoch : 21]  [Training accuracy = 59.09%] [Validation accuracy = 41.92%] [Best = 41.92%]  [Training loss = 3.739] [Validation loss = 3.871]\n","[Epoch : 22]  [Training accuracy = 60.51%] [Validation accuracy = 42.58%] [Best = 42.58%]  [Training loss = 3.695] [Validation loss = 3.835]\n","[Epoch : 23]  [Training accuracy = 61.47%] [Validation accuracy = 43.24%] [Best = 43.24%]  [Training loss = 3.653] [Validation loss = 3.799]\n","[Epoch : 24]  [Training accuracy = 62.64%] [Validation accuracy = 44.11%] [Best = 44.11%]  [Training loss = 3.610] [Validation loss = 3.764]\n","[Epoch : 25]  [Training accuracy = 63.68%] [Validation accuracy = 44.66%] [Best = 44.66%]  [Training loss = 3.569] [Validation loss = 3.729]\n","[Epoch : 26]  [Training accuracy = 64.55%] [Validation accuracy = 45.30%] [Best = 45.30%]  [Training loss = 3.527] [Validation loss = 3.695]\n","[Epoch : 27]  [Training accuracy = 65.44%] [Validation accuracy = 45.93%] [Best = 45.93%]  [Training loss = 3.487] [Validation loss = 3.662]\n","[Epoch : 28]  [Training accuracy = 65.97%] [Validation accuracy = 46.41%] [Best = 46.41%]  [Training loss = 3.447] [Validation loss = 3.628]\n","[Epoch : 29]  [Training accuracy = 66.64%] [Validation accuracy = 46.89%] [Best = 46.89%]  [Training loss = 3.407] [Validation loss = 3.596]\n","[Epoch : 30]  [Training accuracy = 67.90%] [Validation accuracy = 47.52%] [Best = 47.52%]  [Training loss = 3.368] [Validation loss = 3.563]\n","[Epoch : 31]  [Training accuracy = 68.72%] [Validation accuracy = 47.91%] [Best = 47.91%]  [Training loss = 3.330] [Validation loss = 3.532]\n","[Epoch : 32]  [Training accuracy = 69.61%] [Validation accuracy = 48.55%] [Best = 48.55%]  [Training loss = 3.292] [Validation loss = 3.501]\n","[Epoch : 33]  [Training accuracy = 70.88%] [Validation accuracy = 48.92%] [Best = 48.92%]  [Training loss = 3.255] [Validation loss = 3.470]\n","[Epoch : 34]  [Training accuracy = 71.62%] [Validation accuracy = 49.07%] [Best = 49.07%]  [Training loss = 3.218] [Validation loss = 3.440]\n","[Epoch : 35]  [Training accuracy = 72.12%] [Validation accuracy = 49.52%] [Best = 49.52%]  [Training loss = 3.181] [Validation loss = 3.410]\n","[Epoch : 36]  [Training accuracy = 73.01%] [Validation accuracy = 50.00%] [Best = 50.00%]  [Training loss = 3.146] [Validation loss = 3.381]\n","[Epoch : 37]  [Training accuracy = 73.16%] [Validation accuracy = 50.69%] [Best = 50.69%]  [Training loss = 3.110] [Validation loss = 3.352]\n","[Epoch : 38]  [Training accuracy = 73.73%] [Validation accuracy = 51.14%] [Best = 51.14%]  [Training loss = 3.076] [Validation loss = 3.323]\n","[Epoch : 39]  [Training accuracy = 74.53%] [Validation accuracy = 51.50%] [Best = 51.50%]  [Training loss = 3.042] [Validation loss = 3.295]\n","[Epoch : 40]  [Training accuracy = 75.27%] [Validation accuracy = 51.95%] [Best = 51.95%]  [Training loss = 3.008] [Validation loss = 3.268]\n","[Epoch : 41]  [Training accuracy = 75.49%] [Validation accuracy = 52.31%] [Best = 52.31%]  [Training loss = 2.975] [Validation loss = 3.241]\n","[Epoch : 42]  [Training accuracy = 76.01%] [Validation accuracy = 52.73%] [Best = 52.73%]  [Training loss = 2.942] [Validation loss = 3.214]\n","[Epoch : 43]  [Training accuracy = 76.54%] [Validation accuracy = 53.31%] [Best = 53.31%]  [Training loss = 2.910] [Validation loss = 3.188]\n","[Epoch : 44]  [Training accuracy = 77.13%] [Validation accuracy = 53.79%] [Best = 53.79%]  [Training loss = 2.878] [Validation loss = 3.163]\n","[Epoch : 45]  [Training accuracy = 77.43%] [Validation accuracy = 54.22%] [Best = 54.22%]  [Training loss = 2.847] [Validation loss = 3.137]\n","[Epoch : 46]  [Training accuracy = 78.02%] [Validation accuracy = 54.56%] [Best = 54.56%]  [Training loss = 2.816] [Validation loss = 3.112]\n","[Epoch : 47]  [Training accuracy = 78.62%] [Validation accuracy = 55.07%] [Best = 55.07%]  [Training loss = 2.786] [Validation loss = 3.088]\n","[Epoch : 48]  [Training accuracy = 78.99%] [Validation accuracy = 55.31%] [Best = 55.31%]  [Training loss = 2.756] [Validation loss = 3.064]\n","[Epoch : 49]  [Training accuracy = 79.14%] [Validation accuracy = 55.70%] [Best = 55.70%]  [Training loss = 2.727] [Validation loss = 3.040]\n","[Epoch : 50]  [Training accuracy = 79.66%] [Validation accuracy = 55.95%] [Best = 55.95%]  [Training loss = 2.698] [Validation loss = 3.017]\n","[Epoch : 51]  [Training accuracy = 80.11%] [Validation accuracy = 56.49%] [Best = 56.49%]  [Training loss = 2.669] [Validation loss = 2.994]\n","[Epoch : 52]  [Training accuracy = 80.55%] [Validation accuracy = 56.98%] [Best = 56.98%]  [Training loss = 2.641] [Validation loss = 2.972]\n","[Epoch : 53]  [Training accuracy = 80.92%] [Validation accuracy = 57.22%] [Best = 57.22%]  [Training loss = 2.614] [Validation loss = 2.949]\n","[Epoch : 54]  [Training accuracy = 81.52%] [Validation accuracy = 57.25%] [Best = 57.25%]  [Training loss = 2.587] [Validation loss = 2.928]\n","[Epoch : 55]  [Training accuracy = 82.19%] [Validation accuracy = 57.46%] [Best = 57.46%]  [Training loss = 2.560] [Validation loss = 2.906]\n","[Epoch : 56]  [Training accuracy = 82.34%] [Validation accuracy = 58.04%] [Best = 58.04%]  [Training loss = 2.534] [Validation loss = 2.885]\n","[Epoch : 57]  [Training accuracy = 82.56%] [Validation accuracy = 58.43%] [Best = 58.43%]  [Training loss = 2.508] [Validation loss = 2.865]\n","[Epoch : 58]  [Training accuracy = 82.71%] [Validation accuracy = 58.52%] [Best = 58.52%]  [Training loss = 2.482] [Validation loss = 2.844]\n","[Epoch : 59]  [Training accuracy = 83.38%] [Validation accuracy = 58.67%] [Best = 58.67%]  [Training loss = 2.457] [Validation loss = 2.824]\n","[Epoch : 60]  [Training accuracy = 83.68%] [Validation accuracy = 58.82%] [Best = 58.82%]  [Training loss = 2.432] [Validation loss = 2.805]\n","[Epoch : 61]  [Training accuracy = 83.98%] [Validation accuracy = 59.06%] [Best = 59.06%]  [Training loss = 2.408] [Validation loss = 2.785]\n","[Epoch : 62]  [Training accuracy = 84.12%] [Validation accuracy = 59.06%] [Best = 59.06%]  [Training loss = 2.384] [Validation loss = 2.766]\n","[Epoch : 63]  [Training accuracy = 84.42%] [Validation accuracy = 59.30%] [Best = 59.30%]  [Training loss = 2.360] [Validation loss = 2.748]\n","[Epoch : 64]  [Training accuracy = 84.72%] [Validation accuracy = 59.39%] [Best = 59.39%]  [Training loss = 2.337] [Validation loss = 2.729]\n","[Epoch : 65]  [Training accuracy = 85.02%] [Validation accuracy = 59.75%] [Best = 59.75%]  [Training loss = 2.314] [Validation loss = 2.711]\n","[Epoch : 66]  [Training accuracy = 85.46%] [Validation accuracy = 60.05%] [Best = 60.05%]  [Training loss = 2.292] [Validation loss = 2.693]\n","[Epoch : 67]  [Training accuracy = 85.61%] [Validation accuracy = 60.20%] [Best = 60.20%]  [Training loss = 2.270] [Validation loss = 2.676]\n","[Epoch : 68]  [Training accuracy = 85.84%] [Validation accuracy = 60.29%] [Best = 60.29%]  [Training loss = 2.248] [Validation loss = 2.659]\n","[Epoch : 69]  [Training accuracy = 86.06%] [Validation accuracy = 60.38%] [Best = 60.38%]  [Training loss = 2.226] [Validation loss = 2.642]\n","[Epoch : 70]  [Training accuracy = 86.28%] [Validation accuracy = 60.44%] [Best = 60.44%]  [Training loss = 2.205] [Validation loss = 2.625]\n","[Epoch : 71]  [Training accuracy = 86.36%] [Validation accuracy = 60.59%] [Best = 60.59%]  [Training loss = 2.184] [Validation loss = 2.609]\n","[Epoch : 72]  [Training accuracy = 86.65%] [Validation accuracy = 60.59%] [Best = 60.59%]  [Training loss = 2.164] [Validation loss = 2.593]\n","[Epoch : 73]  [Training accuracy = 86.88%] [Validation accuracy = 60.80%] [Best = 60.80%]  [Training loss = 2.143] [Validation loss = 2.577]\n","[Epoch : 74]  [Training accuracy = 86.95%] [Validation accuracy = 60.95%] [Best = 60.95%]  [Training loss = 2.123] [Validation loss = 2.561]\n","[Epoch : 75]  [Training accuracy = 86.88%] [Validation accuracy = 61.13%] [Best = 61.13%]  [Training loss = 2.104] [Validation loss = 2.546]\n","[Epoch : 76]  [Training accuracy = 86.95%] [Validation accuracy = 61.34%] [Best = 61.34%]  [Training loss = 2.084] [Validation loss = 2.531]\n","[Epoch : 77]  [Training accuracy = 87.32%] [Validation accuracy = 61.49%] [Best = 61.49%]  [Training loss = 2.065] [Validation loss = 2.516]\n","[Epoch : 78]  [Training accuracy = 87.67%] [Validation accuracy = 61.52%] [Best = 61.52%]  [Training loss = 2.047] [Validation loss = 2.501]\n","[Epoch : 79]  [Training accuracy = 87.82%] [Validation accuracy = 61.70%] [Best = 61.70%]  [Training loss = 2.028] [Validation loss = 2.487]\n","[Epoch : 80]  [Training accuracy = 88.19%] [Validation accuracy = 61.83%] [Best = 61.83%]  [Training loss = 2.010] [Validation loss = 2.473]\n","[Epoch : 81]  [Training accuracy = 88.42%] [Validation accuracy = 61.89%] [Best = 61.89%]  [Training loss = 1.992] [Validation loss = 2.459]\n","[Epoch : 82]  [Training accuracy = 88.57%] [Validation accuracy = 62.01%] [Best = 62.01%]  [Training loss = 1.974] [Validation loss = 2.445]\n","[Epoch : 83]  [Training accuracy = 88.64%] [Validation accuracy = 62.19%] [Best = 62.19%]  [Training loss = 1.957] [Validation loss = 2.432]\n","[Epoch : 84]  [Training accuracy = 88.86%] [Validation accuracy = 62.34%] [Best = 62.34%]  [Training loss = 1.940] [Validation loss = 2.418]\n","[Epoch : 85]  [Training accuracy = 89.01%] [Validation accuracy = 62.40%] [Best = 62.40%]  [Training loss = 1.923] [Validation loss = 2.405]\n","[Epoch : 86]  [Training accuracy = 89.23%] [Validation accuracy = 62.49%] [Best = 62.49%]  [Training loss = 1.906] [Validation loss = 2.393]\n","[Epoch : 87]  [Training accuracy = 89.66%] [Validation accuracy = 62.70%] [Best = 62.70%]  [Training loss = 1.890] [Validation loss = 2.380]\n","[Epoch : 88]  [Training accuracy = 89.73%] [Validation accuracy = 62.82%] [Best = 62.82%]  [Training loss = 1.874] [Validation loss = 2.368]\n","[Epoch : 89]  [Training accuracy = 89.73%] [Validation accuracy = 62.85%] [Best = 62.85%]  [Training loss = 1.858] [Validation loss = 2.355]\n","[Epoch : 90]  [Training accuracy = 89.96%] [Validation accuracy = 62.97%] [Best = 62.97%]  [Training loss = 1.842] [Validation loss = 2.343]\n","[Epoch : 91]  [Training accuracy = 90.10%] [Validation accuracy = 63.06%] [Best = 63.06%]  [Training loss = 1.827] [Validation loss = 2.331]\n","[Epoch : 92]  [Training accuracy = 90.25%] [Validation accuracy = 63.18%] [Best = 63.18%]  [Training loss = 1.811] [Validation loss = 2.320]\n","[Epoch : 93]  [Training accuracy = 90.40%] [Validation accuracy = 63.18%] [Best = 63.18%]  [Training loss = 1.796] [Validation loss = 2.308]\n","[Epoch : 94]  [Training accuracy = 90.40%] [Validation accuracy = 63.24%] [Best = 63.24%]  [Training loss = 1.781] [Validation loss = 2.297]\n","[Epoch : 95]  [Training accuracy = 90.48%] [Validation accuracy = 63.27%] [Best = 63.27%]  [Training loss = 1.767] [Validation loss = 2.286]\n","[Epoch : 96]  [Training accuracy = 90.48%] [Validation accuracy = 63.30%] [Best = 63.30%]  [Training loss = 1.752] [Validation loss = 2.275]\n","[Epoch : 97]  [Training accuracy = 90.55%] [Validation accuracy = 63.45%] [Best = 63.45%]  [Training loss = 1.738] [Validation loss = 2.264]\n","[Epoch : 98]  [Training accuracy = 90.62%] [Validation accuracy = 63.63%] [Best = 63.63%]  [Training loss = 1.724] [Validation loss = 2.253]\n","[Epoch : 99]  [Training accuracy = 90.77%] [Validation accuracy = 63.84%] [Best = 63.84%]  [Training loss = 1.710] [Validation loss = 2.243]\n","[Epoch : 100]  [Training accuracy = 90.85%] [Validation accuracy = 64.08%] [Best = 64.08%]  [Training loss = 1.697] [Validation loss = 2.232]\n","[Epoch : 101]  [Training accuracy = 90.92%] [Validation accuracy = 64.20%] [Best = 64.20%]  [Training loss = 1.683] [Validation loss = 2.222]\n","[Epoch : 102]  [Training accuracy = 91.00%] [Validation accuracy = 64.35%] [Best = 64.35%]  [Training loss = 1.670] [Validation loss = 2.212]\n","[Epoch : 103]  [Training accuracy = 91.22%] [Validation accuracy = 64.35%] [Best = 64.35%]  [Training loss = 1.657] [Validation loss = 2.202]\n","[Epoch : 104]  [Training accuracy = 91.44%] [Validation accuracy = 64.32%] [Best = 64.35%]  [Training loss = 1.644] [Validation loss = 2.193]\n","[Epoch : 105]  [Training accuracy = 91.59%] [Validation accuracy = 64.47%] [Best = 64.47%]  [Training loss = 1.631] [Validation loss = 2.183]\n","[Epoch : 106]  [Training accuracy = 91.96%] [Validation accuracy = 64.56%] [Best = 64.56%]  [Training loss = 1.619] [Validation loss = 2.174]\n","[Epoch : 107]  [Training accuracy = 92.11%] [Validation accuracy = 64.71%] [Best = 64.71%]  [Training loss = 1.606] [Validation loss = 2.164]\n","[Epoch : 108]  [Training accuracy = 92.34%] [Validation accuracy = 64.80%] [Best = 64.80%]  [Training loss = 1.594] [Validation loss = 2.155]\n","[Epoch : 109]  [Training accuracy = 92.34%] [Validation accuracy = 64.71%] [Best = 64.80%]  [Training loss = 1.582] [Validation loss = 2.146]\n","[Epoch : 110]  [Training accuracy = 92.41%] [Validation accuracy = 64.77%] [Best = 64.80%]  [Training loss = 1.570] [Validation loss = 2.137]\n","[Epoch : 111]  [Training accuracy = 92.49%] [Validation accuracy = 64.86%] [Best = 64.86%]  [Training loss = 1.559] [Validation loss = 2.128]\n","[Epoch : 112]  [Training accuracy = 92.71%] [Validation accuracy = 64.86%] [Best = 64.86%]  [Training loss = 1.547] [Validation loss = 2.120]\n","[Epoch : 113]  [Training accuracy = 92.71%] [Validation accuracy = 64.89%] [Best = 64.89%]  [Training loss = 1.536] [Validation loss = 2.111]\n","[Epoch : 114]  [Training accuracy = 92.78%] [Validation accuracy = 65.01%] [Best = 65.01%]  [Training loss = 1.524] [Validation loss = 2.103]\n","[Epoch : 115]  [Training accuracy = 92.78%] [Validation accuracy = 65.04%] [Best = 65.04%]  [Training loss = 1.513] [Validation loss = 2.094]\n","[Epoch : 116]  [Training accuracy = 92.86%] [Validation accuracy = 65.07%] [Best = 65.07%]  [Training loss = 1.502] [Validation loss = 2.086]\n","[Epoch : 117]  [Training accuracy = 92.93%] [Validation accuracy = 65.01%] [Best = 65.07%]  [Training loss = 1.491] [Validation loss = 2.078]\n","[Epoch : 118]  [Training accuracy = 92.93%] [Validation accuracy = 65.10%] [Best = 65.10%]  [Training loss = 1.481] [Validation loss = 2.070]\n","[Epoch : 119]  [Training accuracy = 93.01%] [Validation accuracy = 65.16%] [Best = 65.16%]  [Training loss = 1.470] [Validation loss = 2.062]\n","[Epoch : 120]  [Training accuracy = 93.01%] [Validation accuracy = 65.16%] [Best = 65.16%]  [Training loss = 1.460] [Validation loss = 2.055]\n","[Epoch : 121]  [Training accuracy = 93.08%] [Validation accuracy = 65.19%] [Best = 65.19%]  [Training loss = 1.449] [Validation loss = 2.047]\n","[Epoch : 122]  [Training accuracy = 93.23%] [Validation accuracy = 65.16%] [Best = 65.19%]  [Training loss = 1.439] [Validation loss = 2.039]\n","[Epoch : 123]  [Training accuracy = 93.30%] [Validation accuracy = 65.16%] [Best = 65.19%]  [Training loss = 1.429] [Validation loss = 2.032]\n","[Epoch : 124]  [Training accuracy = 93.30%] [Validation accuracy = 65.31%] [Best = 65.31%]  [Training loss = 1.419] [Validation loss = 2.025]\n","[Epoch : 125]  [Training accuracy = 93.45%] [Validation accuracy = 65.31%] [Best = 65.31%]  [Training loss = 1.409] [Validation loss = 2.017]\n","[Epoch : 126]  [Training accuracy = 93.53%] [Validation accuracy = 65.40%] [Best = 65.40%]  [Training loss = 1.400] [Validation loss = 2.010]\n","[Epoch : 127]  [Training accuracy = 93.60%] [Validation accuracy = 65.40%] [Best = 65.40%]  [Training loss = 1.390] [Validation loss = 2.003]\n","[Epoch : 128]  [Training accuracy = 93.68%] [Validation accuracy = 65.52%] [Best = 65.52%]  [Training loss = 1.381] [Validation loss = 1.996]\n","[Epoch : 129]  [Training accuracy = 93.82%] [Validation accuracy = 65.55%] [Best = 65.55%]  [Training loss = 1.371] [Validation loss = 1.989]\n","[Epoch : 130]  [Training accuracy = 93.82%] [Validation accuracy = 65.55%] [Best = 65.55%]  [Training loss = 1.362] [Validation loss = 1.983]\n","[Epoch : 131]  [Training accuracy = 93.90%] [Validation accuracy = 65.55%] [Best = 65.55%]  [Training loss = 1.353] [Validation loss = 1.976]\n","[Epoch : 132]  [Training accuracy = 93.97%] [Validation accuracy = 65.57%] [Best = 65.57%]  [Training loss = 1.344] [Validation loss = 1.969]\n","[Epoch : 133]  [Training accuracy = 93.97%] [Validation accuracy = 65.48%] [Best = 65.57%]  [Training loss = 1.335] [Validation loss = 1.963]\n","[Epoch : 134]  [Training accuracy = 94.05%] [Validation accuracy = 65.48%] [Best = 65.57%]  [Training loss = 1.326] [Validation loss = 1.957]\n","[Epoch : 135]  [Training accuracy = 94.12%] [Validation accuracy = 65.54%] [Best = 65.57%]  [Training loss = 1.318] [Validation loss = 1.950]\n","[Epoch : 136]  [Training accuracy = 94.12%] [Validation accuracy = 65.60%] [Best = 65.60%]  [Training loss = 1.309] [Validation loss = 1.944]\n","[Epoch : 137]  [Training accuracy = 94.20%] [Validation accuracy = 65.60%] [Best = 65.60%]  [Training loss = 1.301] [Validation loss = 1.938]\n","[Epoch : 138]  [Training accuracy = 94.20%] [Validation accuracy = 65.60%] [Best = 65.60%]  [Training loss = 1.292] [Validation loss = 1.932]\n","[Epoch : 139]  [Training accuracy = 94.27%] [Validation accuracy = 65.69%] [Best = 65.69%]  [Training loss = 1.284] [Validation loss = 1.926]\n","[Epoch : 140]  [Training accuracy = 94.42%] [Validation accuracy = 65.72%] [Best = 65.72%]  [Training loss = 1.276] [Validation loss = 1.920]\n","[Epoch : 141]  [Training accuracy = 94.49%] [Validation accuracy = 65.72%] [Best = 65.72%]  [Training loss = 1.268] [Validation loss = 1.914]\n","[Epoch : 142]  [Training accuracy = 94.57%] [Validation accuracy = 65.72%] [Best = 65.72%]  [Training loss = 1.260] [Validation loss = 1.908]\n","[Epoch : 143]  [Training accuracy = 94.57%] [Validation accuracy = 65.75%] [Best = 65.75%]  [Training loss = 1.252] [Validation loss = 1.902]\n","[Epoch : 144]  [Training accuracy = 94.57%] [Validation accuracy = 65.81%] [Best = 65.81%]  [Training loss = 1.244] [Validation loss = 1.897]\n","[Epoch : 145]  [Training accuracy = 94.64%] [Validation accuracy = 65.87%] [Best = 65.87%]  [Training loss = 1.236] [Validation loss = 1.891]\n","[Epoch : 146]  [Training accuracy = 94.72%] [Validation accuracy = 65.87%] [Best = 65.87%]  [Training loss = 1.229] [Validation loss = 1.886]\n","[Epoch : 147]  [Training accuracy = 94.79%] [Validation accuracy = 65.87%] [Best = 65.87%]  [Training loss = 1.221] [Validation loss = 1.880]\n","[Epoch : 148]  [Training accuracy = 95.01%] [Validation accuracy = 65.93%] [Best = 65.93%]  [Training loss = 1.214] [Validation loss = 1.875]\n","[Epoch : 149]  [Training accuracy = 95.01%] [Validation accuracy = 65.99%] [Best = 65.99%]  [Training loss = 1.206] [Validation loss = 1.870]\n","[Epoch : 150]  [Training accuracy = 95.09%] [Validation accuracy = 65.96%] [Best = 65.99%]  [Training loss = 1.199] [Validation loss = 1.864]\n","[Epoch : 151]  [Training accuracy = 95.09%] [Validation accuracy = 65.99%] [Best = 65.99%]  [Training loss = 1.192] [Validation loss = 1.859]\n","[Epoch : 152]  [Training accuracy = 95.09%] [Validation accuracy = 65.99%] [Best = 65.99%]  [Training loss = 1.185] [Validation loss = 1.854]\n","[Epoch : 153]  [Training accuracy = 95.09%] [Validation accuracy = 65.99%] [Best = 65.99%]  [Training loss = 1.178] [Validation loss = 1.849]\n","[Epoch : 154]  [Training accuracy = 95.24%] [Validation accuracy = 66.05%] [Best = 66.05%]  [Training loss = 1.171] [Validation loss = 1.844]\n","[Epoch : 155]  [Training accuracy = 95.24%] [Validation accuracy = 66.11%] [Best = 66.11%]  [Training loss = 1.164] [Validation loss = 1.839]\n","[Epoch : 156]  [Training accuracy = 95.31%] [Validation accuracy = 66.05%] [Best = 66.11%]  [Training loss = 1.157] [Validation loss = 1.834]\n","[Epoch : 157]  [Training accuracy = 95.31%] [Validation accuracy = 66.02%] [Best = 66.11%]  [Training loss = 1.150] [Validation loss = 1.829]\n","[Epoch : 158]  [Training accuracy = 95.46%] [Validation accuracy = 65.99%] [Best = 66.11%]  [Training loss = 1.143] [Validation loss = 1.825]\n","[Epoch : 159]  [Training accuracy = 95.46%] [Validation accuracy = 65.99%] [Best = 66.11%]  [Training loss = 1.137] [Validation loss = 1.820]\n","[Epoch : 160]  [Training accuracy = 95.61%] [Validation accuracy = 65.96%] [Best = 66.11%]  [Training loss = 1.130] [Validation loss = 1.815]\n","[Epoch : 161]  [Training accuracy = 95.68%] [Validation accuracy = 65.93%] [Best = 66.11%]  [Training loss = 1.124] [Validation loss = 1.811]\n","[Epoch : 162]  [Training accuracy = 95.68%] [Validation accuracy = 65.99%] [Best = 66.11%]  [Training loss = 1.117] [Validation loss = 1.806]\n","[Epoch : 163]  [Training accuracy = 95.83%] [Validation accuracy = 65.99%] [Best = 66.11%]  [Training loss = 1.111] [Validation loss = 1.802]\n","[Epoch : 164]  [Training accuracy = 95.91%] [Validation accuracy = 66.08%] [Best = 66.11%]  [Training loss = 1.105] [Validation loss = 1.797]\n","[Epoch : 165]  [Training accuracy = 95.91%] [Validation accuracy = 66.11%] [Best = 66.11%]  [Training loss = 1.098] [Validation loss = 1.793]\n","[Epoch : 166]  [Training accuracy = 96.06%] [Validation accuracy = 66.17%] [Best = 66.17%]  [Training loss = 1.092] [Validation loss = 1.788]\n","[Epoch : 167]  [Training accuracy = 96.06%] [Validation accuracy = 66.14%] [Best = 66.17%]  [Training loss = 1.086] [Validation loss = 1.784]\n","[Epoch : 168]  [Training accuracy = 96.13%] [Validation accuracy = 66.20%] [Best = 66.20%]  [Training loss = 1.080] [Validation loss = 1.780]\n","[Epoch : 169]  [Training accuracy = 96.13%] [Validation accuracy = 66.29%] [Best = 66.29%]  [Training loss = 1.074] [Validation loss = 1.776]\n","[Epoch : 170]  [Training accuracy = 96.13%] [Validation accuracy = 66.29%] [Best = 66.29%]  [Training loss = 1.068] [Validation loss = 1.772]\n","[Epoch : 171]  [Training accuracy = 96.13%] [Validation accuracy = 66.26%] [Best = 66.29%]  [Training loss = 1.062] [Validation loss = 1.767]\n","[Epoch : 172]  [Training accuracy = 96.13%] [Validation accuracy = 66.29%] [Best = 66.29%]  [Training loss = 1.056] [Validation loss = 1.763]\n","[Epoch : 173]  [Training accuracy = 96.13%] [Validation accuracy = 66.35%] [Best = 66.35%]  [Training loss = 1.051] [Validation loss = 1.759]\n","[Epoch : 174]  [Training accuracy = 96.21%] [Validation accuracy = 66.38%] [Best = 66.38%]  [Training loss = 1.045] [Validation loss = 1.755]\n","[Epoch : 175]  [Training accuracy = 96.21%] [Validation accuracy = 66.41%] [Best = 66.41%]  [Training loss = 1.039] [Validation loss = 1.751]\n","[Epoch : 176]  [Training accuracy = 96.21%] [Validation accuracy = 66.44%] [Best = 66.44%]  [Training loss = 1.034] [Validation loss = 1.748]\n","[Epoch : 177]  [Training accuracy = 96.28%] [Validation accuracy = 66.50%] [Best = 66.50%]  [Training loss = 1.028] [Validation loss = 1.744]\n","[Epoch : 178]  [Training accuracy = 96.28%] [Validation accuracy = 66.53%] [Best = 66.53%]  [Training loss = 1.023] [Validation loss = 1.740]\n","[Epoch : 179]  [Training accuracy = 96.28%] [Validation accuracy = 66.53%] [Best = 66.53%]  [Training loss = 1.017] [Validation loss = 1.736]\n","[Epoch : 180]  [Training accuracy = 96.43%] [Validation accuracy = 66.56%] [Best = 66.56%]  [Training loss = 1.012] [Validation loss = 1.732]\n","[Epoch : 181]  [Training accuracy = 96.43%] [Validation accuracy = 66.56%] [Best = 66.56%]  [Training loss = 1.007] [Validation loss = 1.729]\n","[Epoch : 182]  [Training accuracy = 96.43%] [Validation accuracy = 66.59%] [Best = 66.59%]  [Training loss = 1.001] [Validation loss = 1.725]\n","[Epoch : 183]  [Training accuracy = 96.50%] [Validation accuracy = 66.62%] [Best = 66.62%]  [Training loss = 0.996] [Validation loss = 1.721]\n","[Epoch : 184]  [Training accuracy = 96.50%] [Validation accuracy = 66.65%] [Best = 66.65%]  [Training loss = 0.991] [Validation loss = 1.718]\n","[Epoch : 185]  [Training accuracy = 96.50%] [Validation accuracy = 66.71%] [Best = 66.71%]  [Training loss = 0.986] [Validation loss = 1.714]\n","[Epoch : 186]  [Training accuracy = 96.73%] [Validation accuracy = 66.74%] [Best = 66.74%]  [Training loss = 0.981] [Validation loss = 1.711]\n","[Epoch : 187]  [Training accuracy = 96.73%] [Validation accuracy = 66.77%] [Best = 66.77%]  [Training loss = 0.976] [Validation loss = 1.707]\n","[Epoch : 188]  [Training accuracy = 96.73%] [Validation accuracy = 66.83%] [Best = 66.83%]  [Training loss = 0.971] [Validation loss = 1.704]\n","[Epoch : 189]  [Training accuracy = 96.73%] [Validation accuracy = 66.80%] [Best = 66.83%]  [Training loss = 0.966] [Validation loss = 1.701]\n","[Epoch : 190]  [Training accuracy = 96.73%] [Validation accuracy = 66.80%] [Best = 66.83%]  [Training loss = 0.961] [Validation loss = 1.697]\n","[Epoch : 191]  [Training accuracy = 96.80%] [Validation accuracy = 66.77%] [Best = 66.83%]  [Training loss = 0.956] [Validation loss = 1.694]\n","[Epoch : 192]  [Training accuracy = 96.80%] [Validation accuracy = 66.68%] [Best = 66.83%]  [Training loss = 0.951] [Validation loss = 1.691]\n","[Epoch : 193]  [Training accuracy = 96.80%] [Validation accuracy = 66.77%] [Best = 66.83%]  [Training loss = 0.947] [Validation loss = 1.687]\n","[Epoch : 194]  [Training accuracy = 96.80%] [Validation accuracy = 66.84%] [Best = 66.84%]  [Training loss = 0.942] [Validation loss = 1.684]\n","[Epoch : 195]  [Training accuracy = 96.80%] [Validation accuracy = 66.84%] [Best = 66.84%]  [Training loss = 0.937] [Validation loss = 1.681]\n","[Epoch : 196]  [Training accuracy = 96.95%] [Validation accuracy = 66.84%] [Best = 66.84%]  [Training loss = 0.933] [Validation loss = 1.678]\n","[Epoch : 197]  [Training accuracy = 96.95%] [Validation accuracy = 66.87%] [Best = 66.87%]  [Training loss = 0.928] [Validation loss = 1.675]\n","[Epoch : 198]  [Training accuracy = 96.95%] [Validation accuracy = 66.93%] [Best = 66.93%]  [Training loss = 0.923] [Validation loss = 1.672]\n","[Epoch : 199]  [Training accuracy = 97.02%] [Validation accuracy = 66.93%] [Best = 66.93%]  [Training loss = 0.919] [Validation loss = 1.669]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8UOnYmTMJc9c"},"source":["La meilleure performance est obtenue avec le SGD-Nesterov, qui semble de plus avoir encore un potentiel d'amélioration. Cette base est suffisante pour le pré-entraînement du modèle cible, qui sera de toute façon impactée par le transfert de connaissance."]},{"cell_type":"markdown","metadata":{"id":"YugtogbOJxgi"},"source":["### 4.2. Premier essai : VGG16bn n'est pas pré-entraîné"]},{"cell_type":"code","metadata":{"id":"XU2M4U8VHzEC"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XgtbX4_eHzEJ"},"source":["source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                              pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7jKUIL2HzEM"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOCfQm8cHzEP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b29fd95d-524f-45e3-d4d4-b3b2634777a3"},"source":["l2t_model.train(IMAGES_DRIVE, epochs=200, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vggbn_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-16 13:26:44,443] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-41a777f9-369d-49e1-879a-db699b2f6ff7.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-16 14:13:08,001] [main] Best model is saved\n","[2020-11-16 14:13:08,693] [main] Last model is saved\n","[2020-11-16 14:13:08,695] [main] [Epoch : 1]  [Training accuracy = 1.89%] [Validation accuracy = 1.24%] [Best = 1.24%]  [Training loss = 4.949] [Validation loss = 5.065]\n","[2020-11-16 14:41:06,249] [main] Last model is saved\n","[2020-11-16 14:41:06,252] [main] [Epoch : 2]  [Training accuracy = 1.59%] [Validation accuracy = 0.82%] [Best = 1.24%]  [Training loss = 5.361] [Validation loss = 5.621]\n","[2020-11-16 15:08:59,899] [main] Last model is saved\n","[2020-11-16 15:08:59,902] [main] [Epoch : 3]  [Training accuracy = 1.52%] [Validation accuracy = 1.03%] [Best = 1.24%]  [Training loss = 5.605] [Validation loss = 6.068]\n","[2020-11-16 15:36:51,556] [main] Last model is saved\n","[2020-11-16 15:36:51,559] [main] [Epoch : 4]  [Training accuracy = 2.98%] [Validation accuracy = 1.24%] [Best = 1.24%]  [Training loss = 5.494] [Validation loss = 6.114]\n","[2020-11-16 16:04:35,022] [main] Best model is saved\n","[2020-11-16 16:04:35,690] [main] Last model is saved\n","[2020-11-16 16:04:35,693] [main] [Epoch : 5]  [Training accuracy = 3.94%] [Validation accuracy = 1.30%] [Best = 1.30%]  [Training loss = 5.303] [Validation loss = 6.079]\n","[2020-11-16 16:32:16,703] [main] Best model is saved\n","[2020-11-16 16:32:17,438] [main] Last model is saved\n","[2020-11-16 16:32:17,440] [main] [Epoch : 6]  [Training accuracy = 3.79%] [Validation accuracy = 1.33%] [Best = 1.33%]  [Training loss = 5.067] [Validation loss = 6.028]\n","[2020-11-16 16:59:57,549] [main] Best model is saved\n","[2020-11-16 16:59:58,166] [main] Last model is saved\n","[2020-11-16 16:59:58,171] [main] [Epoch : 7]  [Training accuracy = 5.76%] [Validation accuracy = 2.00%] [Best = 2.00%]  [Training loss = 4.837] [Validation loss = 6.073]\n","[2020-11-16 17:27:37,106] [main] Best model is saved\n","[2020-11-16 17:27:38,532] [main] Last model is saved\n","[2020-11-16 17:27:38,534] [main] [Epoch : 8]  [Training accuracy = 8.51%] [Validation accuracy = 2.03%] [Best = 2.03%]  [Training loss = 4.651] [Validation loss = 6.152]\n","[2020-11-16 17:55:15,236] [main] Best model is saved\n","[2020-11-16 17:55:15,854] [main] Last model is saved\n","[2020-11-16 17:55:15,856] [main] [Epoch : 9]  [Training accuracy = 11.04%] [Validation accuracy = 3.16%] [Best = 3.16%]  [Training loss = 4.487] [Validation loss = 6.235]\n","[2020-11-16 18:22:38,012] [main] Best model is saved\n","[2020-11-16 18:22:38,677] [main] Last model is saved\n","[2020-11-16 18:22:38,680] [main] [Epoch : 10]  [Training accuracy = 13.51%] [Validation accuracy = 3.64%] [Best = 3.64%]  [Training loss = 4.204] [Validation loss = 6.269]\n","[2020-11-16 18:50:00,848] [main] Last model is saved\n","[2020-11-16 18:50:00,851] [main] [Epoch : 11]  [Training accuracy = 9.70%] [Validation accuracy = 2.25%] [Best = 3.64%]  [Training loss = 5.179] [Validation loss = 7.584]\n","[2020-11-16 19:17:24,950] [main] Last model is saved\n","[2020-11-16 19:17:24,953] [main] [Epoch : 12]  [Training accuracy = 16.14%] [Validation accuracy = 3.06%] [Best = 3.64%]  [Training loss = 4.259] [Validation loss = 7.095]\n","[2020-11-16 19:44:54,918] [main] Last model is saved\n","[2020-11-16 19:44:54,920] [main] [Epoch : 13]  [Training accuracy = 13.66%] [Validation accuracy = 2.88%] [Best = 3.64%]  [Training loss = 5.353] [Validation loss = 8.833]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e3gMPpn3J7Z6"},"source":["L'apprentissage démarre assez lentement. Je regarde si le démarrage est plus rapide est prometteur avec le modèle pré-entraîné, car chaque époque est très longue, même en utilisant seulement 10% des données d'entraînement."]},{"cell_type":"markdown","metadata":{"id":"xJMg-1t2KhWp"},"source":["### 4.3. Deuxième essai : VGG16bn est pré-entraîné"]},{"cell_type":"code","metadata":{"id":"llz2JHxgvHzu"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"poSwShD-vEz2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605559870400,"user_tz":-60,"elapsed":16951,"user":{"displayName":"Sylvain Friot","photoUrl":"","userId":"08300853576559974108"}},"outputId":"2837f89b-9a97-4915-cfdf-17f7718e00fb"},"source":["source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                              pretrained=False)\n","target_model.load_state_dict(torch.load(\"models/vgg16bn_120_sgd.pth\"))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"a3ZQVr4cvE0F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605561197818,"user_tz":-60,"elapsed":1317380,"user":{"displayName":"Sylvain Friot","photoUrl":"","userId":"08300853576559974108"}},"outputId":"a8b5547b-4755-4515-ba2d-7152363d6062"},"source":["loaders = sf_load.get_dataset(IMAGES_DRIVE, target_model, mini_data=0.1, stratify=True,\n","                              batch_size=64, with_data_augmentation=False)\n","model = target_model.to(device)\n","get_validation(model, loaders[2])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(1.6716, device='cuda:0'), 0.6692994505494506)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"7YvSu9H6vE0L"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"umZer5LBvE0Q","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6b4d72c-0905-4426-9056-71a1e2e9d783"},"source":["l2t_model.train(IMAGES_DRIVE, epochs=200, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vggbn_trained_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-16 21:13:17,437] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-f77f78c4-7212-41a4-a1c9-eebb4f6b3447.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-16 21:47:46,159] [main] Best model is saved\n","[2020-11-16 21:47:46,812] [main] Last model is saved\n","[2020-11-16 21:47:46,817] [main] [Epoch : 1]  [Training accuracy = 2.50%] [Validation accuracy = 1.64%] [Best = 1.64%]  [Training loss = 5.775] [Validation loss = 6.389]\n","[2020-11-16 22:13:04,974] [main] Best model is saved\n","[2020-11-16 22:13:05,659] [main] Last model is saved\n","[2020-11-16 22:13:05,663] [main] [Epoch : 2]  [Training accuracy = 6.29%] [Validation accuracy = 2.28%] [Best = 2.28%]  [Training loss = 4.984] [Validation loss = 6.011]\n","[2020-11-16 22:38:22,646] [main] Best model is saved\n","[2020-11-16 22:38:23,279] [main] Last model is saved\n","[2020-11-16 22:38:23,286] [main] [Epoch : 3]  [Training accuracy = 9.82%] [Validation accuracy = 3.40%] [Best = 3.40%]  [Training loss = 4.571] [Validation loss = 6.129]\n","[2020-11-16 23:03:38,437] [main] Last model is saved\n","[2020-11-16 23:03:38,440] [main] [Epoch : 4]  [Training accuracy = 13.66%] [Validation accuracy = 3.06%] [Best = 3.40%]  [Training loss = 4.249] [Validation loss = 6.457]\n","[2020-11-16 23:28:51,954] [main] Best model is saved\n","[2020-11-16 23:28:52,631] [main] Last model is saved\n","[2020-11-16 23:28:52,634] [main] [Epoch : 5]  [Training accuracy = 17.65%] [Validation accuracy = 4.40%] [Best = 4.40%]  [Training loss = 4.292] [Validation loss = 7.475]\n","[2020-11-16 23:54:02,363] [main] Last model is saved\n","[2020-11-16 23:54:02,372] [main] [Epoch : 6]  [Training accuracy = 22.30%] [Validation accuracy = 4.19%] [Best = 4.40%]  [Training loss = 4.287] [Validation loss = 8.138]\n","[2020-11-17 00:19:10,808] [main] Best model is saved\n","[2020-11-17 00:19:11,493] [main] Last model is saved\n","[2020-11-17 00:19:11,496] [main] [Epoch : 7]  [Training accuracy = 23.54%] [Validation accuracy = 5.25%] [Best = 5.25%]  [Training loss = 4.519] [Validation loss = 9.187]\n","[2020-11-17 00:44:22,027] [main] Last model is saved\n","[2020-11-17 00:44:22,028] [main] [Epoch : 8]  [Training accuracy = 27.78%] [Validation accuracy = 4.19%] [Best = 5.25%]  [Training loss = 4.571] [Validation loss = 9.648]\n","[2020-11-17 01:09:29,650] [main] Last model is saved\n","[2020-11-17 01:09:29,652] [main] [Epoch : 9]  [Training accuracy = 24.29%] [Validation accuracy = 4.37%] [Best = 5.25%]  [Training loss = 5.719] [Validation loss = 11.881]\n","[2020-11-17 01:34:37,712] [main] Last model is saved\n","[2020-11-17 01:34:37,714] [main] [Epoch : 10]  [Training accuracy = 29.44%] [Validation accuracy = 4.40%] [Best = 5.25%]  [Training loss = 4.686] [Validation loss = 10.661]\n","[2020-11-17 01:59:45,263] [main] Last model is saved\n","[2020-11-17 01:59:45,265] [main] [Epoch : 11]  [Training accuracy = 27.10%] [Validation accuracy = 4.43%] [Best = 5.25%]  [Training loss = 6.257] [Validation loss = 14.281]\n","[2020-11-17 02:25:07,229] [main] Last model is saved\n","[2020-11-17 02:25:07,232] [main] [Epoch : 12]  [Training accuracy = 31.77%] [Validation accuracy = 4.73%] [Best = 5.25%]  [Training loss = 5.449] [Validation loss = 13.538]\n","[2020-11-17 02:50:43,058] [main] Best model is saved\n","[2020-11-17 02:50:43,736] [main] Last model is saved\n","[2020-11-17 02:50:43,738] [main] [Epoch : 13]  [Training accuracy = 42.78%] [Validation accuracy = 6.25%] [Best = 6.25%]  [Training loss = 3.736] [Validation loss = 12.046]\n","[2020-11-17 03:16:22,351] [main] Best model is saved\n","[2020-11-17 03:16:23,076] [main] Last model is saved\n","[2020-11-17 03:16:23,080] [main] [Epoch : 14]  [Training accuracy = 53.23%] [Validation accuracy = 6.77%] [Best = 6.77%]  [Training loss = 2.399] [Validation loss = 10.590]\n","[2020-11-17 03:42:00,210] [main] Best model is saved\n","[2020-11-17 03:42:00,904] [main] Last model is saved\n","[2020-11-17 03:42:00,908] [main] [Epoch : 15]  [Training accuracy = 51.89%] [Validation accuracy = 7.34%] [Best = 7.34%]  [Training loss = 2.909] [Validation loss = 11.491]\n","[2020-11-17 04:07:39,097] [main] Best model is saved\n","[2020-11-17 04:07:40,144] [main] Last model is saved\n","[2020-11-17 04:07:40,148] [main] [Epoch : 16]  [Training accuracy = 69.29%] [Validation accuracy = 8.13%] [Best = 8.13%]  [Training loss = 1.431] [Validation loss = 10.050]\n","[2020-11-17 04:33:15,929] [main] Best model is saved\n","[2020-11-17 04:33:16,566] [main] Last model is saved\n","[2020-11-17 04:33:16,568] [main] [Epoch : 17]  [Training accuracy = 67.65%] [Validation accuracy = 8.22%] [Best = 8.22%]  [Training loss = 1.510] [Validation loss = 10.482]\n","[2020-11-17 04:58:43,884] [main] Last model is saved\n","[2020-11-17 04:58:43,886] [main] [Epoch : 18]  [Training accuracy = 55.48%] [Validation accuracy = 7.71%] [Best = 8.22%]  [Training loss = 2.328] [Validation loss = 10.722]\n","[2020-11-17 05:24:11,753] [main] Last model is saved\n","[2020-11-17 05:24:11,755] [main] [Epoch : 19]  [Training accuracy = 44.72%] [Validation accuracy = 5.46%] [Best = 8.22%]  [Training loss = 3.412] [Validation loss = 12.298]\n","[2020-11-17 05:49:43,231] [main] Best model is saved\n","[2020-11-17 05:49:43,891] [main] Last model is saved\n","[2020-11-17 05:49:43,894] [main] [Epoch : 20]  [Training accuracy = 63.89%] [Validation accuracy = 8.43%] [Best = 8.43%]  [Training loss = 2.072] [Validation loss = 11.912]\n","[2020-11-17 06:15:13,090] [main] Last model is saved\n","[2020-11-17 06:15:13,093] [main] [Epoch : 21]  [Training accuracy = 56.01%] [Validation accuracy = 6.86%] [Best = 8.43%]  [Training loss = 2.360] [Validation loss = 11.809]\n","[2020-11-17 06:40:45,409] [main] Best model is saved\n","[2020-11-17 06:40:46,020] [main] Last model is saved\n","[2020-11-17 06:40:46,028] [main] [Epoch : 22]  [Training accuracy = 64.55%] [Validation accuracy = 8.68%] [Best = 8.68%]  [Training loss = 1.857] [Validation loss = 11.624]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rCmY-ebvKquw"},"source":["Je continue avec cette base qui commence son apprentissage plus rapidement.  \n","Je dois relancer plusieurs fois l'apprentissage, dû aux limitations en temps de Google Colab."]},{"cell_type":"code","metadata":{"id":"adA_xWmkt7FX"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0gZFhkybt7Fu"},"source":["source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                              pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wf82Jx9Ft7F6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605609334843,"user_tz":-60,"elapsed":14157,"user":{"displayName":"Sylvain Friot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoXMlSuKZ6igNpG8eWztmf3VmOip01BSn5cBTjWg=s64","userId":"16265699099211164232"}},"outputId":"78d7fb43-60c9-4028-83cc-6c5883117532"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)\n","l2t_model.load_parameters(\"ckpt_last_effb4_to_vggbn_trained_mini.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model loaded : best accuracy = 8.68% after 22 epochs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IchPcmQ9t7F9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"927e1546-3b12-4a04-d75b-e9ccfa93ae27"},"source":["l2t_model.train(IMAGES_DRIVE, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vggbn_trained_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-17 10:35:58,805] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-323f1809-fe0c-4e23-a1e2-8a216c12815a.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-17 11:34:46,169] [main] Last model is saved\n","[2020-11-17 11:34:46,174] [main] [Epoch : 23]  [Training accuracy = 71.89%] [Validation accuracy = 8.34%] [Best = 8.68%]  [Training loss = 1.326] [Validation loss = 10.964]\n","[2020-11-17 12:01:36,875] [main] Last model is saved\n","[2020-11-17 12:01:36,878] [main] [Epoch : 24]  [Training accuracy = 63.74%] [Validation accuracy = 7.28%] [Best = 8.68%]  [Training loss = 2.017] [Validation loss = 12.095]\n","[2020-11-17 12:28:26,841] [main] Last model is saved\n","[2020-11-17 12:28:26,844] [main] [Epoch : 25]  [Training accuracy = 64.55%] [Validation accuracy = 7.92%] [Best = 8.68%]  [Training loss = 1.900] [Validation loss = 12.620]\n","[2020-11-17 12:55:15,591] [main] Best model is saved\n","[2020-11-17 12:55:16,299] [main] Last model is saved\n","[2020-11-17 12:55:16,301] [main] [Epoch : 26]  [Training accuracy = 70.86%] [Validation accuracy = 8.71%] [Best = 8.71%]  [Training loss = 1.534] [Validation loss = 11.907]\n","[2020-11-17 13:22:05,304] [main] Last model is saved\n","[2020-11-17 13:22:05,306] [main] [Epoch : 27]  [Training accuracy = 63.59%] [Validation accuracy = 8.59%] [Best = 8.71%]  [Training loss = 2.545] [Validation loss = 13.089]\n","[2020-11-17 13:48:53,477] [main] Last model is saved\n","[2020-11-17 13:48:53,479] [main] [Epoch : 28]  [Training accuracy = 70.45%] [Validation accuracy = 8.10%] [Best = 8.71%]  [Training loss = 1.561] [Validation loss = 11.706]\n","[2020-11-17 14:15:41,896] [main] Last model is saved\n","[2020-11-17 14:15:41,899] [main] [Epoch : 29]  [Training accuracy = 60.51%] [Validation accuracy = 7.07%] [Best = 8.71%]  [Training loss = 2.296] [Validation loss = 13.518]\n","[2020-11-17 14:42:29,931] [main] Last model is saved\n","[2020-11-17 14:42:29,933] [main] [Epoch : 30]  [Training accuracy = 70.98%] [Validation accuracy = 7.43%] [Best = 8.71%]  [Training loss = 1.584] [Validation loss = 11.962]\n","[2020-11-17 15:09:17,053] [main] Best model is saved\n","[2020-11-17 15:09:17,742] [main] Last model is saved\n","[2020-11-17 15:09:17,746] [main] [Epoch : 31]  [Training accuracy = 79.92%] [Validation accuracy = 10.07%] [Best = 10.07%]  [Training loss = 1.013] [Validation loss = 11.273]\n","[2020-11-17 15:36:02,595] [main] Last model is saved\n","[2020-11-17 15:36:02,597] [main] [Epoch : 32]  [Training accuracy = 71.79%] [Validation accuracy = 7.95%] [Best = 10.07%]  [Training loss = 1.807] [Validation loss = 12.957]\n","[2020-11-17 16:02:46,715] [main] Last model is saved\n","[2020-11-17 16:02:46,719] [main] [Epoch : 33]  [Training accuracy = 77.25%] [Validation accuracy = 8.59%] [Best = 10.07%]  [Training loss = 1.069] [Validation loss = 12.544]\n","[2020-11-17 16:29:29,867] [main] Last model is saved\n","[2020-11-17 16:29:29,870] [main] [Epoch : 34]  [Training accuracy = 80.51%] [Validation accuracy = 8.40%] [Best = 10.07%]  [Training loss = 0.831] [Validation loss = 11.717]\n","[2020-11-17 16:56:11,433] [main] Best model is saved\n","[2020-11-17 16:56:12,094] [main] Last model is saved\n","[2020-11-17 16:56:12,097] [main] [Epoch : 35]  [Training accuracy = 89.47%] [Validation accuracy = 11.62%] [Best = 11.62%]  [Training loss = 0.480] [Validation loss = 10.487]\n","[2020-11-17 17:22:53,756] [main] Last model is saved\n","[2020-11-17 17:22:53,760] [main] [Epoch : 36]  [Training accuracy = 84.02%] [Validation accuracy = 9.77%] [Best = 11.62%]  [Training loss = 0.676] [Validation loss = 11.432]\n","[2020-11-17 17:49:35,055] [main] Last model is saved\n","[2020-11-17 17:49:35,057] [main] [Epoch : 37]  [Training accuracy = 88.03%] [Validation accuracy = 8.98%] [Best = 11.62%]  [Training loss = 0.501] [Validation loss = 11.404]\n","[2020-11-17 18:16:16,894] [main] Last model is saved\n","[2020-11-17 18:16:16,896] [main] [Epoch : 38]  [Training accuracy = 81.21%] [Validation accuracy = 9.95%] [Best = 11.62%]  [Training loss = 1.106] [Validation loss = 11.852]\n","[2020-11-17 18:42:57,548] [main] Last model is saved\n","[2020-11-17 18:42:57,550] [main] [Epoch : 39]  [Training accuracy = 68.91%] [Validation accuracy = 6.64%] [Best = 11.62%]  [Training loss = 1.775] [Validation loss = 12.793]\n","[2020-11-17 19:09:38,334] [main] Last model is saved\n","[2020-11-17 19:09:38,337] [main] [Epoch : 40]  [Training accuracy = 71.87%] [Validation accuracy = 8.34%] [Best = 11.62%]  [Training loss = 1.490] [Validation loss = 12.380]\n","[2020-11-17 19:36:18,625] [main] Last model is saved\n","[2020-11-17 19:36:18,628] [main] [Epoch : 41]  [Training accuracy = 70.66%] [Validation accuracy = 6.77%] [Best = 11.62%]  [Training loss = 1.550] [Validation loss = 13.385]\n","[2020-11-17 20:02:57,678] [main] Last model is saved\n","[2020-11-17 20:02:57,680] [main] [Epoch : 42]  [Training accuracy = 85.73%] [Validation accuracy = 9.19%] [Best = 11.62%]  [Training loss = 0.644] [Validation loss = 10.786]\n","[2020-11-17 20:29:38,839] [main] Last model is saved\n","[2020-11-17 20:29:38,841] [main] [Epoch : 43]  [Training accuracy = 85.76%] [Validation accuracy = 8.95%] [Best = 11.62%]  [Training loss = 0.655] [Validation loss = 11.167]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dO5j3YUjhoy-"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvcCpKPnhoy-"},"source":["source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                              pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nijyROu2hoy-","executionInfo":{"status":"ok","timestamp":1605655520294,"user_tz":-60,"elapsed":12645,"user":{"displayName":"Sylvain Friot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoXMlSuKZ6igNpG8eWztmf3VmOip01BSn5cBTjWg=s64","userId":"16265699099211164232"}},"outputId":"67476546-0f73-4105-e1c2-27789eb0a62c"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)\n","l2t_model.load_parameters(\"ckpt_last_effb4_to_vggbn_trained_mini.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model loaded : best accuracy = 11.62% after 43 epochs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3oGGIT6hoy_","outputId":"10dc6cf5-8ff2-4408-b1e8-1346be470e18"},"source":["l2t_model.train(IMAGES_DRIVE, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vggbn_trained_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-17 23:25:21,675] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-9fef629b-5e81-445e-8799-e77b74816e66.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-18 00:22:42,030] [main] Last model is saved\n","[2020-11-18 00:22:42,033] [main] [Epoch : 44]  [Training accuracy = 90.23%] [Validation accuracy = 10.41%] [Best = 11.62%]  [Training loss = 0.396] [Validation loss = 10.876]\n","[2020-11-18 00:49:11,440] [main] Last model is saved\n","[2020-11-18 00:49:11,442] [main] [Epoch : 45]  [Training accuracy = 91.06%] [Validation accuracy = 10.92%] [Best = 11.62%]  [Training loss = 0.396] [Validation loss = 10.470]\n","[2020-11-18 01:15:38,903] [main] Last model is saved\n","[2020-11-18 01:15:38,907] [main] [Epoch : 46]  [Training accuracy = 88.86%] [Validation accuracy = 10.29%] [Best = 11.62%]  [Training loss = 0.465] [Validation loss = 10.904]\n","[2020-11-18 01:42:05,687] [main] Last model is saved\n","[2020-11-18 01:42:05,692] [main] [Epoch : 47]  [Training accuracy = 92.95%] [Validation accuracy = 11.07%] [Best = 11.62%]  [Training loss = 0.292] [Validation loss = 10.025]\n","[2020-11-18 02:08:32,407] [main] Last model is saved\n","[2020-11-18 02:08:32,410] [main] [Epoch : 48]  [Training accuracy = 96.36%] [Validation accuracy = 11.26%] [Best = 11.62%]  [Training loss = 0.116] [Validation loss = 9.681]\n","[2020-11-18 02:34:59,086] [main] Last model is saved\n","[2020-11-18 02:34:59,088] [main] [Epoch : 49]  [Training accuracy = 96.89%] [Validation accuracy = 11.53%] [Best = 11.62%]  [Training loss = 0.106] [Validation loss = 9.488]\n","[2020-11-18 03:01:27,304] [main] Best model is saved\n","[2020-11-18 03:01:27,993] [main] Last model is saved\n","[2020-11-18 03:01:27,995] [main] [Epoch : 50]  [Training accuracy = 97.27%] [Validation accuracy = 12.17%] [Best = 12.17%]  [Training loss = 0.078] [Validation loss = 9.182]\n","[2020-11-18 03:27:53,353] [main] Last model is saved\n","[2020-11-18 03:27:53,355] [main] [Epoch : 51]  [Training accuracy = 97.50%] [Validation accuracy = 11.95%] [Best = 12.17%]  [Training loss = 0.074] [Validation loss = 9.081]\n","[2020-11-18 03:54:19,101] [main] Last model is saved\n","[2020-11-18 03:54:19,103] [main] [Epoch : 52]  [Training accuracy = 97.80%] [Validation accuracy = 12.01%] [Best = 12.17%]  [Training loss = 0.071] [Validation loss = 9.014]\n","[2020-11-18 04:20:50,398] [main] Last model is saved\n","[2020-11-18 04:20:50,400] [main] [Epoch : 53]  [Training accuracy = 97.27%] [Validation accuracy = 11.59%] [Best = 12.17%]  [Training loss = 0.078] [Validation loss = 8.896]\n","[2020-11-18 04:47:18,114] [main] Best model is saved\n","[2020-11-18 04:47:18,855] [main] Last model is saved\n","[2020-11-18 04:47:18,860] [main] [Epoch : 54]  [Training accuracy = 97.73%] [Validation accuracy = 12.26%] [Best = 12.26%]  [Training loss = 0.064] [Validation loss = 8.783]\n","[2020-11-18 05:13:45,932] [main] Last model is saved\n","[2020-11-18 05:13:45,934] [main] [Epoch : 55]  [Training accuracy = 97.12%] [Validation accuracy = 11.83%] [Best = 12.26%]  [Training loss = 0.095] [Validation loss = 8.762]\n","[2020-11-18 05:40:13,572] [main] Last model is saved\n","[2020-11-18 05:40:13,575] [main] [Epoch : 56]  [Training accuracy = 97.42%] [Validation accuracy = 11.92%] [Best = 12.26%]  [Training loss = 0.073] [Validation loss = 8.527]\n","[2020-11-18 06:06:40,492] [main] Last model is saved\n","[2020-11-18 06:06:40,494] [main] [Epoch : 57]  [Training accuracy = 97.12%] [Validation accuracy = 11.56%] [Best = 12.26%]  [Training loss = 0.085] [Validation loss = 8.468]\n","[2020-11-18 06:33:06,928] [main] Last model is saved\n","[2020-11-18 06:33:06,933] [main] [Epoch : 58]  [Training accuracy = 96.82%] [Validation accuracy = 11.44%] [Best = 12.26%]  [Training loss = 0.081] [Validation loss = 8.345]\n","[2020-11-18 06:59:32,586] [main] Last model is saved\n","[2020-11-18 06:59:32,589] [main] [Epoch : 59]  [Training accuracy = 96.44%] [Validation accuracy = 11.23%] [Best = 12.26%]  [Training loss = 0.106] [Validation loss = 8.382]\n","[2020-11-18 07:26:02,544] [main] Last model is saved\n","[2020-11-18 07:26:02,546] [main] [Epoch : 60]  [Training accuracy = 95.61%] [Validation accuracy = 10.98%] [Best = 12.26%]  [Training loss = 0.136] [Validation loss = 8.346]\n","[2020-11-18 07:52:35,670] [main] Last model is saved\n","[2020-11-18 07:52:35,673] [main] [Epoch : 61]  [Training accuracy = 94.77%] [Validation accuracy = 11.13%] [Best = 12.26%]  [Training loss = 0.150] [Validation loss = 8.313]\n","[2020-11-18 08:19:03,040] [main] Last model is saved\n","[2020-11-18 08:19:03,042] [main] [Epoch : 62]  [Training accuracy = 94.77%] [Validation accuracy = 11.23%] [Best = 12.26%]  [Training loss = 0.167] [Validation loss = 8.211]\n","[2020-11-18 08:45:30,140] [main] Last model is saved\n","[2020-11-18 08:45:30,142] [main] [Epoch : 63]  [Training accuracy = 95.68%] [Validation accuracy = 11.35%] [Best = 12.26%]  [Training loss = 0.131] [Validation loss = 7.915]\n","[2020-11-18 09:11:56,046] [main] Last model is saved\n","[2020-11-18 09:11:56,051] [main] [Epoch : 64]  [Training accuracy = 96.44%] [Validation accuracy = 11.17%] [Best = 12.26%]  [Training loss = 0.124] [Validation loss = 7.690]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vKPNKYu9r5z8"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUppqBGYr5z9"},"source":["source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                              pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KBp1mSUr5z9","executionInfo":{"status":"ok","timestamp":1605691846756,"user_tz":-60,"elapsed":14405,"user":{"displayName":"Sylvain Friot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoXMlSuKZ6igNpG8eWztmf3VmOip01BSn5cBTjWg=s64","userId":"16265699099211164232"}},"outputId":"a580ccb4-7b69-4f7b-f78f-c9f8fab2ba22"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)\n","l2t_model.load_parameters(\"ckpt_last_effb4_to_vggbn_trained_mini.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model loaded : best accuracy = 12.26% after 64 epochs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApQaSdsAr5z-","outputId":"5b15944c-42f3-4741-be52-f8529a0a90dd"},"source":["l2t_model.train(IMAGES_DRIVE, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vggbn_trained_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-18 09:31:04,114] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-842d6815-ac90-4974-8d0d-69d946fadbb5.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-18 10:18:38,200] [main] Last model is saved\n","[2020-11-18 10:18:38,202] [main] [Epoch : 65]  [Training accuracy = 96.21%] [Validation accuracy = 11.17%] [Best = 12.26%]  [Training loss = 0.125] [Validation loss = 7.588]\n","[2020-11-18 10:46:56,736] [main] Last model is saved\n","[2020-11-18 10:46:56,738] [main] [Epoch : 66]  [Training accuracy = 97.12%] [Validation accuracy = 11.17%] [Best = 12.26%]  [Training loss = 0.088] [Validation loss = 7.390]\n","[2020-11-18 11:15:32,714] [main] Last model is saved\n","[2020-11-18 11:15:32,717] [main] [Epoch : 67]  [Training accuracy = 97.05%] [Validation accuracy = 11.04%] [Best = 12.26%]  [Training loss = 0.088] [Validation loss = 7.330]\n","[2020-11-18 11:44:09,656] [main] Last model is saved\n","[2020-11-18 11:44:09,659] [main] [Epoch : 68]  [Training accuracy = 96.89%] [Validation accuracy = 11.35%] [Best = 12.26%]  [Training loss = 0.095] [Validation loss = 7.236]\n","[2020-11-18 12:12:46,372] [main] Last model is saved\n","[2020-11-18 12:12:46,374] [main] [Epoch : 69]  [Training accuracy = 96.97%] [Validation accuracy = 10.89%] [Best = 12.26%]  [Training loss = 0.101] [Validation loss = 7.074]\n","[2020-11-18 12:41:22,788] [main] Last model is saved\n","[2020-11-18 12:41:22,791] [main] [Epoch : 70]  [Training accuracy = 97.73%] [Validation accuracy = 10.80%] [Best = 12.26%]  [Training loss = 0.078] [Validation loss = 6.864]\n","[2020-11-18 13:09:57,654] [main] Last model is saved\n","[2020-11-18 13:09:57,657] [main] [Epoch : 71]  [Training accuracy = 98.41%] [Validation accuracy = 12.01%] [Best = 12.26%]  [Training loss = 0.066] [Validation loss = 6.822]\n","[2020-11-18 13:38:33,309] [main] Best model is saved\n","[2020-11-18 13:38:33,948] [main] Last model is saved\n","[2020-11-18 13:38:33,950] [main] [Epoch : 72]  [Training accuracy = 98.79%] [Validation accuracy = 12.38%] [Best = 12.38%]  [Training loss = 0.047] [Validation loss = 6.620]\n","[2020-11-18 14:07:09,482] [main] Best model is saved\n","[2020-11-18 14:07:10,125] [main] Last model is saved\n","[2020-11-18 14:07:10,127] [main] [Epoch : 73]  [Training accuracy = 98.94%] [Validation accuracy = 12.68%] [Best = 12.68%]  [Training loss = 0.039] [Validation loss = 6.459]\n","[2020-11-18 14:35:45,069] [main] Last model is saved\n","[2020-11-18 14:35:45,071] [main] [Epoch : 74]  [Training accuracy = 98.33%] [Validation accuracy = 12.59%] [Best = 12.68%]  [Training loss = 0.055] [Validation loss = 6.441]\n","[2020-11-18 15:04:19,374] [main] Best model is saved\n","[2020-11-18 15:04:20,002] [main] Last model is saved\n","[2020-11-18 15:04:20,005] [main] [Epoch : 75]  [Training accuracy = 98.79%] [Validation accuracy = 12.83%] [Best = 12.83%]  [Training loss = 0.046] [Validation loss = 6.272]\n","[2020-11-18 15:32:55,899] [main] Last model is saved\n","[2020-11-18 15:32:55,901] [main] [Epoch : 76]  [Training accuracy = 98.41%] [Validation accuracy = 12.44%] [Best = 12.83%]  [Training loss = 0.066] [Validation loss = 6.299]\n","[2020-11-18 16:01:32,886] [main] Best model is saved\n","[2020-11-18 16:01:33,535] [main] Last model is saved\n","[2020-11-18 16:01:33,540] [main] [Epoch : 77]  [Training accuracy = 99.17%] [Validation accuracy = 13.23%] [Best = 13.23%]  [Training loss = 0.040] [Validation loss = 6.123]\n","[2020-11-18 16:30:07,590] [main] Last model is saved\n","[2020-11-18 16:30:07,592] [main] [Epoch : 78]  [Training accuracy = 99.09%] [Validation accuracy = 12.86%] [Best = 13.23%]  [Training loss = 0.050] [Validation loss = 6.112]\n","[2020-11-18 16:58:41,459] [main] Best model is saved\n","[2020-11-18 16:58:42,083] [main] Last model is saved\n","[2020-11-18 16:58:42,086] [main] [Epoch : 79]  [Training accuracy = 99.62%] [Validation accuracy = 13.41%] [Best = 13.41%]  [Training loss = 0.031] [Validation loss = 5.903]\n","[2020-11-18 17:27:16,594] [main] Best model is saved\n","[2020-11-18 17:27:17,217] [main] Last model is saved\n","[2020-11-18 17:27:17,224] [main] [Epoch : 80]  [Training accuracy = 99.55%] [Validation accuracy = 13.56%] [Best = 13.56%]  [Training loss = 0.031] [Validation loss = 5.914]\n","[2020-11-18 17:55:50,846] [main] Last model is saved\n","[2020-11-18 17:55:50,848] [main] [Epoch : 81]  [Training accuracy = 99.70%] [Validation accuracy = 13.56%] [Best = 13.56%]  [Training loss = 0.028] [Validation loss = 5.773]\n","[2020-11-18 18:24:23,864] [main] Last model is saved\n","[2020-11-18 18:24:23,867] [main] [Epoch : 82]  [Training accuracy = 99.55%] [Validation accuracy = 13.32%] [Best = 13.56%]  [Training loss = 0.027] [Validation loss = 5.667]\n","[2020-11-18 18:52:58,763] [main] Last model is saved\n","[2020-11-18 18:52:58,765] [main] [Epoch : 83]  [Training accuracy = 99.55%] [Validation accuracy = 13.47%] [Best = 13.56%]  [Training loss = 0.027] [Validation loss = 5.583]\n","[2020-11-18 19:21:37,999] [main] Last model is saved\n","[2020-11-18 19:21:38,001] [main] [Epoch : 84]  [Training accuracy = 99.55%] [Validation accuracy = 13.41%] [Best = 13.56%]  [Training loss = 0.028] [Validation loss = 5.523]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LbYnZvN9OiJs"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\"\n","source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                              pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jaFDno1-OiJs","executionInfo":{"status":"ok","timestamp":1605734507615,"user_tz":-60,"elapsed":12108,"user":{"displayName":"Sylvain Friot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoXMlSuKZ6igNpG8eWztmf3VmOip01BSn5cBTjWg=s64","userId":"16265699099211164232"}},"outputId":"00c18fdf-1209-4d21-c3c7-adae70babec0"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)\n","l2t_model.load_parameters(\"ckpt_last_effb4_to_vggbn_trained_mini.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model loaded : best accuracy = 13.56% after 84 epochs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iHC49wPROiJt","outputId":"8b025b0c-ef52-4f31-8ea8-1f7b4a3ba5ad"},"source":["l2t_model.train(IMAGES_DRIVE, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vggbn_trained_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-18 21:21:50,708] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-7a8c89c0-11a6-424c-aa0a-6d6d0c3cfe8a.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-18 22:21:09,394] [main] Last model is saved\n","[2020-11-18 22:21:09,398] [main] [Epoch : 85]  [Training accuracy = 99.62%] [Validation accuracy = 13.50%] [Best = 13.56%]  [Training loss = 0.026] [Validation loss = 5.434]\n","[2020-11-18 22:48:33,795] [main] Best model is saved\n","[2020-11-18 22:48:34,423] [main] Last model is saved\n","[2020-11-18 22:48:34,427] [main] [Epoch : 86]  [Training accuracy = 99.70%] [Validation accuracy = 14.05%] [Best = 14.05%]  [Training loss = 0.023] [Validation loss = 5.360]\n","[2020-11-18 23:15:55,217] [main] Last model is saved\n","[2020-11-18 23:15:55,219] [main] [Epoch : 87]  [Training accuracy = 99.62%] [Validation accuracy = 13.83%] [Best = 14.05%]  [Training loss = 0.024] [Validation loss = 5.310]\n","[2020-11-18 23:43:14,938] [main] Last model is saved\n","[2020-11-18 23:43:14,941] [main] [Epoch : 88]  [Training accuracy = 99.62%] [Validation accuracy = 13.77%] [Best = 14.05%]  [Training loss = 0.025] [Validation loss = 5.263]\n","[2020-11-19 00:10:35,384] [main] Last model is saved\n","[2020-11-19 00:10:35,386] [main] [Epoch : 89]  [Training accuracy = 99.62%] [Validation accuracy = 13.71%] [Best = 14.05%]  [Training loss = 0.025] [Validation loss = 5.216]\n","[2020-11-19 00:37:55,555] [main] Last model is saved\n","[2020-11-19 00:37:55,557] [main] [Epoch : 90]  [Training accuracy = 99.55%] [Validation accuracy = 13.65%] [Best = 14.05%]  [Training loss = 0.025] [Validation loss = 5.178]\n","[2020-11-19 01:05:15,988] [main] Last model is saved\n","[2020-11-19 01:05:15,990] [main] [Epoch : 91]  [Training accuracy = 99.47%] [Validation accuracy = 13.83%] [Best = 14.05%]  [Training loss = 0.026] [Validation loss = 5.138]\n","[2020-11-19 01:32:34,437] [main] Last model is saved\n","[2020-11-19 01:32:34,439] [main] [Epoch : 92]  [Training accuracy = 99.47%] [Validation accuracy = 13.80%] [Best = 14.05%]  [Training loss = 0.027] [Validation loss = 5.126]\n","[2020-11-19 01:59:55,731] [main] Last model is saved\n","[2020-11-19 01:59:55,734] [main] [Epoch : 93]  [Training accuracy = 99.47%] [Validation accuracy = 13.71%] [Best = 14.05%]  [Training loss = 0.026] [Validation loss = 5.077]\n","[2020-11-19 02:27:19,370] [main] Last model is saved\n","[2020-11-19 02:27:19,373] [main] [Epoch : 94]  [Training accuracy = 99.62%] [Validation accuracy = 13.99%] [Best = 14.05%]  [Training loss = 0.023] [Validation loss = 5.035]\n","[2020-11-19 02:54:41,818] [main] Last model is saved\n","[2020-11-19 02:54:41,821] [main] [Epoch : 95]  [Training accuracy = 99.62%] [Validation accuracy = 14.05%] [Best = 14.05%]  [Training loss = 0.023] [Validation loss = 5.013]\n","[2020-11-19 03:22:05,877] [main] Last model is saved\n","[2020-11-19 03:22:05,880] [main] [Epoch : 96]  [Training accuracy = 99.55%] [Validation accuracy = 13.90%] [Best = 14.05%]  [Training loss = 0.023] [Validation loss = 4.994]\n","[2020-11-19 03:49:31,322] [main] Last model is saved\n","[2020-11-19 03:49:31,324] [main] [Epoch : 97]  [Training accuracy = 99.55%] [Validation accuracy = 14.05%] [Best = 14.05%]  [Training loss = 0.024] [Validation loss = 4.968]\n","[2020-11-19 04:16:53,414] [main] Best model is saved\n","[2020-11-19 04:16:54,176] [main] Last model is saved\n","[2020-11-19 04:16:54,180] [main] [Epoch : 98]  [Training accuracy = 99.55%] [Validation accuracy = 14.29%] [Best = 14.29%]  [Training loss = 0.024] [Validation loss = 4.940]\n","[2020-11-19 04:44:15,088] [main] Last model is saved\n","[2020-11-19 04:44:15,091] [main] [Epoch : 99]  [Training accuracy = 99.55%] [Validation accuracy = 14.23%] [Best = 14.29%]  [Training loss = 0.025] [Validation loss = 4.926]\n","[2020-11-19 05:11:34,116] [main] Best model is saved\n","[2020-11-19 05:11:34,826] [main] Last model is saved\n","[2020-11-19 05:11:34,832] [main] [Epoch : 100]  [Training accuracy = 99.55%] [Validation accuracy = 14.32%] [Best = 14.32%]  [Training loss = 0.025] [Validation loss = 4.905]\n","[2020-11-19 05:38:50,634] [main] Best model is saved\n","[2020-11-19 05:38:51,352] [main] Last model is saved\n","[2020-11-19 05:38:51,356] [main] [Epoch : 101]  [Training accuracy = 99.55%] [Validation accuracy = 14.44%] [Best = 14.44%]  [Training loss = 0.023] [Validation loss = 4.855]\n","[2020-11-19 06:06:07,814] [main] Best model is saved\n","[2020-11-19 06:06:08,499] [main] Last model is saved\n","[2020-11-19 06:06:08,502] [main] [Epoch : 102]  [Training accuracy = 99.77%] [Validation accuracy = 14.50%] [Best = 14.50%]  [Training loss = 0.024] [Validation loss = 4.836]\n","[2020-11-19 06:33:21,818] [main] Best model is saved\n","[2020-11-19 06:33:22,527] [main] Last model is saved\n","[2020-11-19 06:33:22,531] [main] [Epoch : 103]  [Training accuracy = 99.77%] [Validation accuracy = 14.71%] [Best = 14.71%]  [Training loss = 0.023] [Validation loss = 4.804]\n","[2020-11-19 07:00:37,535] [main] Last model is saved\n","[2020-11-19 07:00:37,538] [main] [Epoch : 104]  [Training accuracy = 99.77%] [Validation accuracy = 14.50%] [Best = 14.71%]  [Training loss = 0.023] [Validation loss = 4.788]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oNnQNDKjmRQS"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\"\n","source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                              pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHuCaRrhmRQS","executionInfo":{"status":"ok","timestamp":1605774222049,"user_tz":-60,"elapsed":15529,"user":{"displayName":"Sylvain Friot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoXMlSuKZ6igNpG8eWztmf3VmOip01BSn5cBTjWg=s64","userId":"16265699099211164232"}},"outputId":"707ddca3-0a9f-4ac3-8c63-6060e6c149b2"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)\n","l2t_model.load_parameters(\"ckpt_last_effb4_to_vggbn_trained_mini.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model loaded : best accuracy = 14.71% after 104 epochs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kW9HoPcFmRQV","outputId":"66066e60-c7dd-46a2-f994-4ad0d95411b9"},"source":["l2t_model.train(IMAGES_DRIVE, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vggbn_trained_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-19 08:23:42,791] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-9960d625-40bd-4b45-b248-3a6af69735b6.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-19 09:22:18,631] [main] Best model is saved\n","[2020-11-19 09:22:19,303] [main] Last model is saved\n","[2020-11-19 09:22:19,307] [main] [Epoch : 105]  [Training accuracy = 99.70%] [Validation accuracy = 14.78%] [Best = 14.78%]  [Training loss = 0.024] [Validation loss = 4.770]\n","[2020-11-19 09:48:36,432] [main] Best model is saved\n","[2020-11-19 09:48:37,125] [main] Last model is saved\n","[2020-11-19 09:48:37,127] [main] [Epoch : 106]  [Training accuracy = 99.70%] [Validation accuracy = 14.81%] [Best = 14.81%]  [Training loss = 0.024] [Validation loss = 4.752]\n","[2020-11-19 10:14:54,784] [main] Last model is saved\n","[2020-11-19 10:14:54,787] [main] [Epoch : 107]  [Training accuracy = 99.70%] [Validation accuracy = 14.68%] [Best = 14.81%]  [Training loss = 0.024] [Validation loss = 4.739]\n","[2020-11-19 10:41:11,801] [main] Last model is saved\n","[2020-11-19 10:41:11,803] [main] [Epoch : 108]  [Training accuracy = 99.70%] [Validation accuracy = 14.81%] [Best = 14.81%]  [Training loss = 0.023] [Validation loss = 4.728]\n","[2020-11-19 11:07:23,038] [main] Last model is saved\n","[2020-11-19 11:07:23,040] [main] [Epoch : 109]  [Training accuracy = 99.77%] [Validation accuracy = 14.81%] [Best = 14.81%]  [Training loss = 0.022] [Validation loss = 4.707]\n","[2020-11-19 11:33:33,273] [main] Last model is saved\n","[2020-11-19 11:33:33,277] [main] [Epoch : 110]  [Training accuracy = 99.85%] [Validation accuracy = 14.59%] [Best = 14.81%]  [Training loss = 0.022] [Validation loss = 4.686]\n","[2020-11-19 11:59:37,993] [main] Best model is saved\n","[2020-11-19 11:59:38,606] [main] Last model is saved\n","[2020-11-19 11:59:38,614] [main] [Epoch : 111]  [Training accuracy = 99.70%] [Validation accuracy = 15.05%] [Best = 15.05%]  [Training loss = 0.025] [Validation loss = 4.666]\n","[2020-11-19 12:25:41,582] [main] Best model is saved\n","[2020-11-19 12:25:42,230] [main] Last model is saved\n","[2020-11-19 12:25:42,231] [main] [Epoch : 112]  [Training accuracy = 99.55%] [Validation accuracy = 15.14%] [Best = 15.14%]  [Training loss = 0.025] [Validation loss = 4.667]\n","[2020-11-19 12:51:51,255] [main] Last model is saved\n","[2020-11-19 12:51:51,258] [main] [Epoch : 113]  [Training accuracy = 99.55%] [Validation accuracy = 14.84%] [Best = 15.14%]  [Training loss = 0.023] [Validation loss = 4.644]\n","[2020-11-19 13:17:55,158] [main] Last model is saved\n","[2020-11-19 13:17:55,160] [main] [Epoch : 114]  [Training accuracy = 99.55%] [Validation accuracy = 14.65%] [Best = 15.14%]  [Training loss = 0.023] [Validation loss = 4.628]\n","[2020-11-19 13:43:59,901] [main] Last model is saved\n","[2020-11-19 13:43:59,903] [main] [Epoch : 115]  [Training accuracy = 99.55%] [Validation accuracy = 14.93%] [Best = 15.14%]  [Training loss = 0.023] [Validation loss = 4.623]\n","[2020-11-19 14:10:01,782] [main] Last model is saved\n","[2020-11-19 14:10:01,787] [main] [Epoch : 116]  [Training accuracy = 99.55%] [Validation accuracy = 14.87%] [Best = 15.14%]  [Training loss = 0.023] [Validation loss = 4.606]\n","[2020-11-19 14:36:02,638] [main] Last model is saved\n","[2020-11-19 14:36:02,641] [main] [Epoch : 117]  [Training accuracy = 99.55%] [Validation accuracy = 14.84%] [Best = 15.14%]  [Training loss = 0.023] [Validation loss = 4.596]\n","[2020-11-19 15:02:03,428] [main] Last model is saved\n","[2020-11-19 15:02:03,433] [main] [Epoch : 118]  [Training accuracy = 99.62%] [Validation accuracy = 14.93%] [Best = 15.14%]  [Training loss = 0.023] [Validation loss = 4.583]\n","[2020-11-19 15:28:04,846] [main] Last model is saved\n","[2020-11-19 15:28:04,848] [main] [Epoch : 119]  [Training accuracy = 99.70%] [Validation accuracy = 14.96%] [Best = 15.14%]  [Training loss = 0.023] [Validation loss = 4.569]\n","[2020-11-19 15:53:57,356] [main] Last model is saved\n","[2020-11-19 15:53:57,359] [main] [Epoch : 120]  [Training accuracy = 99.77%] [Validation accuracy = 14.96%] [Best = 15.14%]  [Training loss = 0.023] [Validation loss = 4.558]\n","[2020-11-19 16:19:44,688] [main] Last model is saved\n","[2020-11-19 16:19:44,691] [main] [Epoch : 121]  [Training accuracy = 99.77%] [Validation accuracy = 15.05%] [Best = 15.14%]  [Training loss = 0.022] [Validation loss = 4.545]\n","[2020-11-19 16:45:33,499] [main] Best model is saved\n","[2020-11-19 16:45:34,254] [main] Last model is saved\n","[2020-11-19 16:45:34,259] [main] [Epoch : 122]  [Training accuracy = 99.77%] [Validation accuracy = 15.23%] [Best = 15.23%]  [Training loss = 0.022] [Validation loss = 4.532]\n","[2020-11-19 17:11:23,431] [main] Last model is saved\n","[2020-11-19 17:11:23,434] [main] [Epoch : 123]  [Training accuracy = 99.77%] [Validation accuracy = 15.17%] [Best = 15.23%]  [Training loss = 0.022] [Validation loss = 4.516]\n","[2020-11-19 17:37:13,397] [main] Last model is saved\n","[2020-11-19 17:37:13,400] [main] [Epoch : 124]  [Training accuracy = 99.77%] [Validation accuracy = 15.23%] [Best = 15.23%]  [Training loss = 0.022] [Validation loss = 4.506]\n","[2020-11-19 18:03:04,005] [main] Last model is saved\n","[2020-11-19 18:03:04,009] [main] [Epoch : 125]  [Training accuracy = 99.77%] [Validation accuracy = 15.14%] [Best = 15.23%]  [Training loss = 0.022] [Validation loss = 4.504]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hPZZpWgwM4YZ"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\"\n","source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                              pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_LWtadUM4Ya","executionInfo":{"status":"ok","timestamp":1605817941239,"user_tz":-60,"elapsed":12595,"user":{"displayName":"Sylvain Friot","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgoXMlSuKZ6igNpG8eWztmf3VmOip01BSn5cBTjWg=s64","userId":"16265699099211164232"}},"outputId":"72550f34-5c95-4eee-afd0-ddd09a373e10"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)\n","l2t_model.load_parameters(\"ckpt_last_effb4_to_vggbn_trained_mini.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model loaded : best accuracy = 15.23% after 125 epochs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fW4ucFW1M4Yb","outputId":"9bbb1ea6-09b9-46f5-d61a-69b787ed680f"},"source":["l2t_model.train(IMAGES_DRIVE, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vggbn_trained_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-19 20:32:24,155] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-7b59f465-a852-42bf-ae62-764237908366.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-19 21:27:16,148] [main] Last model is saved\n","[2020-11-19 21:27:16,151] [main] [Epoch : 126]  [Training accuracy = 99.77%] [Validation accuracy = 15.11%] [Best = 15.23%]  [Training loss = 0.022] [Validation loss = 4.496]\n","[2020-11-19 21:53:09,878] [main] Last model is saved\n","[2020-11-19 21:53:09,880] [main] [Epoch : 127]  [Training accuracy = 99.77%] [Validation accuracy = 15.11%] [Best = 15.23%]  [Training loss = 0.022] [Validation loss = 4.487]\n","[2020-11-19 22:19:01,898] [main] Last model is saved\n","[2020-11-19 22:19:01,901] [main] [Epoch : 128]  [Training accuracy = 99.77%] [Validation accuracy = 15.23%] [Best = 15.23%]  [Training loss = 0.022] [Validation loss = 4.477]\n","[2020-11-19 22:44:51,943] [main] Best model is saved\n","[2020-11-19 22:44:52,618] [main] Last model is saved\n","[2020-11-19 22:44:52,622] [main] [Epoch : 129]  [Training accuracy = 99.77%] [Validation accuracy = 15.35%] [Best = 15.35%]  [Training loss = 0.022] [Validation loss = 4.470]\n","[2020-11-19 23:10:42,939] [main] Last model is saved\n","[2020-11-19 23:10:42,941] [main] [Epoch : 130]  [Training accuracy = 99.77%] [Validation accuracy = 15.32%] [Best = 15.35%]  [Training loss = 0.022] [Validation loss = 4.463]\n","[2020-11-19 23:36:35,379] [main] Best model is saved\n","[2020-11-19 23:36:36,010] [main] Last model is saved\n","[2020-11-19 23:36:36,012] [main] [Epoch : 131]  [Training accuracy = 99.77%] [Validation accuracy = 15.44%] [Best = 15.44%]  [Training loss = 0.021] [Validation loss = 4.452]\n","[2020-11-20 00:02:26,779] [main] Last model is saved\n","[2020-11-20 00:02:26,785] [main] [Epoch : 132]  [Training accuracy = 99.77%] [Validation accuracy = 15.41%] [Best = 15.44%]  [Training loss = 0.022] [Validation loss = 4.448]\n","[2020-11-20 00:28:21,875] [main] Best model is saved\n","[2020-11-20 00:28:22,537] [main] Last model is saved\n","[2020-11-20 00:28:22,539] [main] [Epoch : 133]  [Training accuracy = 99.77%] [Validation accuracy = 15.47%] [Best = 15.47%]  [Training loss = 0.021] [Validation loss = 4.439]\n","[2020-11-20 00:54:17,566] [main] Best model is saved\n","[2020-11-20 00:54:18,213] [main] Last model is saved\n","[2020-11-20 00:54:18,215] [main] [Epoch : 134]  [Training accuracy = 99.77%] [Validation accuracy = 15.50%] [Best = 15.50%]  [Training loss = 0.021] [Validation loss = 4.433]\n","[2020-11-20 01:20:11,245] [main] Last model is saved\n","[2020-11-20 01:20:11,247] [main] [Epoch : 135]  [Training accuracy = 99.77%] [Validation accuracy = 15.38%] [Best = 15.50%]  [Training loss = 0.021] [Validation loss = 4.428]\n","[2020-11-20 01:46:04,165] [main] Last model is saved\n","[2020-11-20 01:46:04,168] [main] [Epoch : 136]  [Training accuracy = 99.77%] [Validation accuracy = 15.47%] [Best = 15.50%]  [Training loss = 0.021] [Validation loss = 4.419]\n","[2020-11-20 02:11:55,987] [main] Last model is saved\n","[2020-11-20 02:11:55,990] [main] [Epoch : 137]  [Training accuracy = 99.77%] [Validation accuracy = 15.44%] [Best = 15.50%]  [Training loss = 0.021] [Validation loss = 4.415]\n","[2020-11-20 02:37:51,887] [main] Last model is saved\n","[2020-11-20 02:37:51,890] [main] [Epoch : 138]  [Training accuracy = 99.77%] [Validation accuracy = 15.44%] [Best = 15.50%]  [Training loss = 0.021] [Validation loss = 4.411]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tRn8QLnVsVhT"},"source":["model_efficientnetb4_url = PATH_DRIVE + \"/models/efficientnet-b4-6ed6700e.pth\"\n","source_model = sf_source.efficientnetb4(pretrained=True, max_num_features=512,\n","                                        folder_saves=\"models\",\n","                                        url_pretrained=model_efficientnetb4_url)\n","target_model = sf_vgg.vgg16bn(num_classes=120, original_classifier=False,\n","                              pretrained=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LaaucVX7sVhT","executionInfo":{"status":"ok","timestamp":1605860223116,"user_tz":-60,"elapsed":12459,"user":{"displayName":"CBS Power","photoUrl":"","userId":"13126957910862042425"}},"outputId":"1c20aa7a-29f0-4219-b24a-191667e0e710"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)\n","l2t_model.load_parameters(\"ckpt_last_effb4_to_vggbn_trained_mini.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model loaded : best accuracy = 15.50% after 138 epochs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNIrhjDxsVhU","outputId":"7f20a133-7151-4169-a567-726002679bfc"},"source":["l2t_model.train(IMAGES_DRIVE, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"effb4_to_vggbn_trained_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-20 08:17:11,747] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-51d3c411-fa9b-47fc-a8bb-580976512fb1.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-20 08:59:51,725] [main] Best model is saved\n","[2020-11-20 08:59:52,383] [main] Last model is saved\n","[2020-11-20 08:59:52,388] [main] [Epoch : 139]  [Training accuracy = 99.77%] [Validation accuracy = 15.53%] [Best = 15.53%]  [Training loss = 0.021] [Validation loss = 4.405]\n","[2020-11-20 09:25:48,478] [main] Last model is saved\n","[2020-11-20 09:25:48,481] [main] [Epoch : 140]  [Training accuracy = 99.77%] [Validation accuracy = 15.50%] [Best = 15.53%]  [Training loss = 0.021] [Validation loss = 4.400]\n","[2020-11-20 09:51:45,343] [main] Last model is saved\n","[2020-11-20 09:51:45,346] [main] [Epoch : 141]  [Training accuracy = 99.77%] [Validation accuracy = 15.50%] [Best = 15.53%]  [Training loss = 0.020] [Validation loss = 4.393]\n","[2020-11-20 10:17:39,829] [main] Best model is saved\n","[2020-11-20 10:17:40,507] [main] Last model is saved\n","[2020-11-20 10:17:40,510] [main] [Epoch : 142]  [Training accuracy = 99.77%] [Validation accuracy = 15.59%] [Best = 15.59%]  [Training loss = 0.021] [Validation loss = 4.385]\n","[2020-11-20 10:43:39,225] [main] Last model is saved\n","[2020-11-20 10:43:39,227] [main] [Epoch : 143]  [Training accuracy = 99.77%] [Validation accuracy = 15.59%] [Best = 15.59%]  [Training loss = 0.020] [Validation loss = 4.380]\n","[2020-11-20 11:09:35,517] [main] Best model is saved\n","[2020-11-20 11:09:36,205] [main] Last model is saved\n","[2020-11-20 11:09:36,207] [main] [Epoch : 144]  [Training accuracy = 99.77%] [Validation accuracy = 15.84%] [Best = 15.84%]  [Training loss = 0.020] [Validation loss = 4.375]\n","[2020-11-20 11:35:30,725] [main] Last model is saved\n","[2020-11-20 11:35:30,727] [main] [Epoch : 145]  [Training accuracy = 99.77%] [Validation accuracy = 15.72%] [Best = 15.84%]  [Training loss = 0.020] [Validation loss = 4.371]\n","[2020-11-20 12:01:26,178] [main] Last model is saved\n","[2020-11-20 12:01:26,185] [main] [Epoch : 146]  [Training accuracy = 99.77%] [Validation accuracy = 15.69%] [Best = 15.84%]  [Training loss = 0.020] [Validation loss = 4.364]\n","[2020-11-20 12:27:17,608] [main] Last model is saved\n","[2020-11-20 12:27:17,611] [main] [Epoch : 147]  [Training accuracy = 99.77%] [Validation accuracy = 15.78%] [Best = 15.84%]  [Training loss = 0.020] [Validation loss = 4.360]\n","[2020-11-20 12:53:14,237] [main] Last model is saved\n","[2020-11-20 12:53:14,239] [main] [Epoch : 148]  [Training accuracy = 99.77%] [Validation accuracy = 15.75%] [Best = 15.84%]  [Training loss = 0.020] [Validation loss = 4.355]\n","[2020-11-20 13:19:09,446] [main] Last model is saved\n","[2020-11-20 13:19:09,449] [main] [Epoch : 149]  [Training accuracy = 99.77%] [Validation accuracy = 15.56%] [Best = 15.84%]  [Training loss = 0.020] [Validation loss = 4.349]\n","[2020-11-20 13:45:05,495] [main] Last model is saved\n","[2020-11-20 13:45:05,498] [main] [Epoch : 150]  [Training accuracy = 99.77%] [Validation accuracy = 15.69%] [Best = 15.84%]  [Training loss = 0.020] [Validation loss = 4.347]\n","[2020-11-20 14:11:02,607] [main] Last model is saved\n","[2020-11-20 14:11:02,609] [main] [Epoch : 151]  [Training accuracy = 99.77%] [Validation accuracy = 15.75%] [Best = 15.84%]  [Training loss = 0.020] [Validation loss = 4.343]\n","[2020-11-20 14:36:58,894] [main] Best model is saved\n","[2020-11-20 14:36:59,606] [main] Last model is saved\n","[2020-11-20 14:36:59,608] [main] [Epoch : 152]  [Training accuracy = 99.77%] [Validation accuracy = 15.87%] [Best = 15.87%]  [Training loss = 0.020] [Validation loss = 4.336]\n","[2020-11-20 15:02:49,955] [main] Last model is saved\n","[2020-11-20 15:02:49,957] [main] [Epoch : 153]  [Training accuracy = 99.77%] [Validation accuracy = 15.87%] [Best = 15.87%]  [Training loss = 0.019] [Validation loss = 4.331]\n","[2020-11-20 15:28:40,873] [main] Best model is saved\n","[2020-11-20 15:28:41,475] [main] Last model is saved\n","[2020-11-20 15:28:41,483] [main] [Epoch : 154]  [Training accuracy = 99.85%] [Validation accuracy = 16.02%] [Best = 16.02%]  [Training loss = 0.019] [Validation loss = 4.324]\n","[2020-11-20 15:54:33,174] [main] Last model is saved\n","[2020-11-20 15:54:33,176] [main] [Epoch : 155]  [Training accuracy = 99.77%] [Validation accuracy = 15.99%] [Best = 16.02%]  [Training loss = 0.019] [Validation loss = 4.323]\n","[2020-11-20 16:20:27,069] [main] Last model is saved\n","[2020-11-20 16:20:27,075] [main] [Epoch : 156]  [Training accuracy = 99.85%] [Validation accuracy = 15.96%] [Best = 16.02%]  [Training loss = 0.019] [Validation loss = 4.322]\n","[2020-11-20 16:46:16,620] [main] Best model is saved\n","[2020-11-20 16:46:17,232] [main] Last model is saved\n","[2020-11-20 16:46:17,235] [main] [Epoch : 157]  [Training accuracy = 99.85%] [Validation accuracy = 16.11%] [Best = 16.11%]  [Training loss = 0.019] [Validation loss = 4.318]\n","[2020-11-20 17:12:06,647] [main] Last model is saved\n","[2020-11-20 17:12:06,649] [main] [Epoch : 158]  [Training accuracy = 99.85%] [Validation accuracy = 16.02%] [Best = 16.11%]  [Training loss = 0.019] [Validation loss = 4.315]\n","[2020-11-20 17:37:58,406] [main] Last model is saved\n","[2020-11-20 17:37:58,407] [main] [Epoch : 159]  [Training accuracy = 99.85%] [Validation accuracy = 15.96%] [Best = 16.11%]  [Training loss = 0.019] [Validation loss = 4.314]\n","[2020-11-20 18:03:49,279] [main] Last model is saved\n","[2020-11-20 18:03:49,281] [main] [Epoch : 160]  [Training accuracy = 99.85%] [Validation accuracy = 16.05%] [Best = 16.11%]  [Training loss = 0.019] [Validation loss = 4.311]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Sa1jgD-0LLcA"},"source":["Après 5 jours d'entraînement, je mets un terme à cette optimisation :\n","- elle est trop gourmande en ressources par rapport à mes moyens ;\n","- elle est trop gourmande en temps par rapport à mes objectifs ;\n","- elle ne semble pas disposer d'un potentiel de performance suffisant (training loss très faible alors que la validation accuracy est encore très insuffisante)."]},{"cell_type":"code","metadata":{"id":"9hWigPFShxtF"},"source":[""],"execution_count":null,"outputs":[]}]}