{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML07_02_Improving_EfficientNetB0.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1IuDnV7wBCdC"},"source":["<font size=6>Développer une preuve de concept</font>  \n","<font size=5>Classification d'image avec le papier Learning What and Where to Transfer  \n","Partie 1 : Améliorer les performances d'EfficientNetB0 grâce à EfficientNetB7</font>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"u_rEOyNPBCdD"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"GF2mrZJkBCdE"},"source":["**Vérification de l'environnement**"]},{"cell_type":"code","metadata":{"id":"tUgNLOrZ5zyy"},"source":["import sys\n","IN_COLAB = \"google.colab\" in sys.modules\n","# PATH_DRIVE : to change according to your Google Drive folders\n","PATH_DRIVE = \"/content/drive/My Drive/MachineLearning/ML07\"\n","# IMAGES_DRIVE : to get access to previously loaded images\n","IMAGES_DRIVE = \"/content/drive/My Drive/MachineLearning/ML06/Images\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ay0Ybm0I500n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605605638776,"user_tz":-60,"elapsed":1005,"user":{"displayName":"SF Futures","photoUrl":"","userId":"02252129064136863627"}},"outputId":"c7374623-69ff-4547-eb18-508df3c9b85c"},"source":["if IN_COLAB:\n","    print(\"Le notebook est exécuté sur Google Colab\")\n","else:\n","    print(\"Le notebook est exécuté en local\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Le notebook est exécuté sur Google Colab\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CCi_1tXv505N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605605638778,"user_tz":-60,"elapsed":997,"user":{"displayName":"SF Futures","photoUrl":"","userId":"02252129064136863627"}},"outputId":"38ba3217-87cd-4791-8575-12ad84a43d52"},"source":["if IN_COLAB:\n","    from google.colab import drive, files\n","    drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6ay6qcCIBCdQ"},"source":["---\n","## <font color=blue>Notebook set-up</font>"]},{"cell_type":"markdown","metadata":{"id":"uSAAMADMBCdR"},"source":["**Importation des librairies**"]},{"cell_type":"code","metadata":{"id":"Sqiejm5glRVD"},"source":["import os\n","#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"79hrYgCN5y49"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import re\n","import datetime\n","import random as python_random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqmb_7nXmC2M"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQuRhGr6TYB2"},"source":["import csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z1ZnXqIM6feY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605605641180,"user_tz":-60,"elapsed":3362,"user":{"displayName":"SF Futures","photoUrl":"","userId":"02252129064136863627"}},"outputId":"6beeb2dc-3da3-4788-a115-9ad092dc70eb"},"source":["if IN_COLAB:\n","    sys.path.append(PATH_DRIVE)\n","    os.chdir(PATH_DRIVE)\n","    import sf_graphiques as sfg\n","    import sf_efficientnet_b4 as sf_efn\n","    import sf_pytorch_loaders as sf_load\n","    import sf_meta_optimizers as sf_optim\n","    import sf_l2t_ww as sf_l2t\n","else:\n","    import modules_perso.sf_graphiques as sfg\n","    import modules_perso.sf_efficientnet_b4 as sf_efn\n","    import modules_perso.sf_pytorch_loaders as sf_load\n","    import modules_perso.sf_meta_optimizers as sf_optim\n","    import modules_perso.sf_l2t_ww as sf_l2t"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"viCeZ9D2BCde"},"source":["**Notebook set-up**"]},{"cell_type":"code","metadata":{"id":"5wZeyN8chxvE"},"source":["def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n","    path = fig_id + \".\" + fig_extension\n","    if IN_COLAB:\n","        path = PATH_DRIVE + \"/\" + path\n","    #print(\"Saving figure\", fig_id)\n","    if tight_layout:\n","        plt.tight_layout()\n","    plt.savefig(path, dpi=resolution)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0g-vuB7KQdJt"},"source":["RANDOM_SEED = 42\n","BATCH_SIZE = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HS2qTQ43S93Z"},"source":["def reset_random_seeds():\n","    np.random.seed(RANDOM_SEED)\n","    python_random.seed(RANDOM_SEED)\n","    torch.manual_seed(40)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGbHCe6mWd_8"},"source":["reset_random_seeds()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k7ekka88FQSp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605605641541,"user_tz":-60,"elapsed":3688,"user":{"displayName":"SF Futures","photoUrl":"","userId":"02252129064136863627"}},"outputId":"66cd5483-5dab-4e78-f5a9-6ffc64776b53"},"source":["if torch.cuda.device_count() >= 1:\n","    print(torch.cuda.get_device_name(0))\n","else:\n","    print(\"No Cuda Device\")\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r6gbizCTLhHj"},"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNE6rZ1bLi80"},"source":["def accuracy_topk(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(1.0 / batch_size))\n","    return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oPmX-QbVqg_S"},"source":["def accuracy_top1(outputs_data, labels):\n","    _, pred = torch.max(outputs_data, 1)\n","    correct = (pred == labels).sum().item()\n","    return correct / labels.size(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLSBB1tCNx7m"},"source":["def get_validation(model, loader):\n","    acc = AverageMeter()\n","    loss = AverageMeter()\n","    model.eval()\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(device), y.to(device)\n","            y_pred = model.forward(x)\n","            loss.update(F.cross_entropy(y_pred, y))\n","            acc.update(accuracy_top1(y_pred.data, y))\n","    return loss.avg, acc.avg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZgebVWTfJaNU"},"source":["def transferlearning_on_targettask(mymodel, mycriterion, myoptimizer, myloaders,\n","                                   mysave_name, nb_epochs=50, patience=0):\n","    csv_filename = os.path.join(PATH_DRIVE, \"logs/{}.csv\".format(mysave_name))\n","    csv_memory = open(csv_filename, \"w\")  # Write the headers to the file\n","    writer = csv.writer(csv_memory)\n","    writer.writerow([\"epoch\", \"validation_loss\", \"training_loss\",\n","                      \"validation_accuracy\", \"training_accuracy\"])\n","    csv_memory.close()\n","\n","    best_acc = 0.0\n","    lag_best = 0\n","    for epoch in range(nb_epochs):\n","        mymodel.train()\n","        epoch_acc = AverageMeter()\n","        epoch_loss = AverageMeter()\n","        for x, y in myloaders[0]:\n","            x, y = x.to(device), y.to(device)\n","            myoptimizer.zero_grad()\n","            y_pred = mymodel.forward(x)\n","            loss = mycriterion(y_pred, y)\n","            loss.backward()\n","            myoptimizer.step()\n","            epoch_loss.update(loss.item())\n","            epoch_acc.update(accuracy_top1(y_pred.data, y))\n","        training_loss = epoch_loss.avg\n","        training_accuracy = epoch_acc.avg\n","        \n","        validation_loss, validation_accuracy = get_validation(mymodel, myloaders[2])\n","        if validation_accuracy > best_acc:\n","            best_acc = validation_accuracy\n","            lag_best = 0\n","            torch.save(mymodel.state_dict(), \"models/{}.pth\".format(mysave_name))\n","        else:\n","            lag_best += 1\n","\n","        print(\"[Epoch : {}]  [Training accuracy = {:.2%}] [Validation accuracy = {:.2%}] [Best = {:.2%}]  [Training loss = {:.3f}] [Validation loss = {:.3f}]\"\\\n","              .format(epoch, training_accuracy, validation_accuracy, best_acc, training_loss, validation_loss))\n","        csv_memory = open(csv_filename, \"a\")  # Write the results to the file\n","        writer = csv.writer(csv_memory)\n","        writer.writerow([epoch, validation_loss, training_loss,\n","                        validation_accuracy, training_accuracy])\n","        csv_memory.close()\n","\n","        if (patience > 0) & (lag_best > patience):\n","            print(\"Learning ended by early-stop\")\n","            break\n","        # next epoch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GuxCr3iXG76k"},"source":["---\n","## 1\\. Performance de base d'EfficientNetB0"]},{"cell_type":"markdown","metadata":{"id":"jeu1MUV8xXc8"},"source":["### 1.1. Optimisation avec l'algorithme Adam"]},{"cell_type":"code","metadata":{"id":"3RHSpWS4G7PH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605605645116,"user_tz":-60,"elapsed":7219,"user":{"displayName":"SF Futures","photoUrl":"","userId":"02252129064136863627"}},"outputId":"40df43db-5caf-4b6c-985f-97406592467d"},"source":["model = sf_efn.efficientnetb0(num_classes=120, pretrained=True,\n","                              url_pretrained=\"models/efficientnet-b0-355c32eb.pth\")\n","model.freeze_layers(last_layer=-2)\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), eps=1e-7)\n","# note : eps=1e-7 to get the same epsilon than Tensorflow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 : _conv_stem\n","freezed\n","1 : _bn0\n","freezed\n","2 : _blocks\n","freezed\n","3 : _conv_head\n","freezed\n","4 : _bn1\n","freezed\n","5 : _avg_pooling\n","freezed\n","6 : _dropout\n","freezed\n","7 : _fc\n","unfreezed\n","8 : _swish\n","unfreezed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kn01MwnpHicH"},"source":["loaders = sf_load.get_dataset(IMAGES_DRIVE, model, mini_data=0.1, stratify=True,\n","                              batch_size=64, with_data_augmentation=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"epB0NA57HuPl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605610479299,"user_tz":-60,"elapsed":4841387,"user":{"displayName":"SF Futures","photoUrl":"","userId":"02252129064136863627"}},"outputId":"8a80a67c-f2b5-4085-9801-8506cec1aa0c"},"source":["transferlearning_on_targettask(model, criterion, optimizer, loaders, \"efnb0_120_adam\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Epoch : 0]  [Training accuracy = 7.77%] [Validation accuracy = 34.74%] [Best = 34.74%]  [Training loss = 4.615] [Validation loss = 4.108]\n","[Epoch : 1]  [Training accuracy = 61.97%] [Validation accuracy = 50.29%] [Best = 50.29%]  [Training loss = 3.638] [Validation loss = 3.446]\n","[Epoch : 2]  [Training accuracy = 83.78%] [Validation accuracy = 54.29%] [Best = 54.29%]  [Training loss = 2.901] [Validation loss = 2.918]\n","[Epoch : 3]  [Training accuracy = 91.17%] [Validation accuracy = 56.78%] [Best = 56.78%]  [Training loss = 2.303] [Validation loss = 2.527]\n","[Epoch : 4]  [Training accuracy = 93.97%] [Validation accuracy = 57.89%] [Best = 57.89%]  [Training loss = 1.826] [Validation loss = 2.260]\n","[Epoch : 5]  [Training accuracy = 96.65%] [Validation accuracy = 57.88%] [Best = 57.89%]  [Training loss = 1.477] [Validation loss = 2.087]\n","[Epoch : 6]  [Training accuracy = 97.84%] [Validation accuracy = 57.51%] [Best = 57.89%]  [Training loss = 1.191] [Validation loss = 1.981]\n","[Epoch : 7]  [Training accuracy = 98.44%] [Validation accuracy = 56.71%] [Best = 57.89%]  [Training loss = 0.977] [Validation loss = 1.918]\n","[Epoch : 8]  [Training accuracy = 98.74%] [Validation accuracy = 55.87%] [Best = 57.89%]  [Training loss = 0.812] [Validation loss = 1.880]\n","[Epoch : 9]  [Training accuracy = 99.11%] [Validation accuracy = 55.42%] [Best = 57.89%]  [Training loss = 0.687] [Validation loss = 1.860]\n","[Epoch : 10]  [Training accuracy = 99.48%] [Validation accuracy = 54.48%] [Best = 57.89%]  [Training loss = 0.582] [Validation loss = 1.849]\n","[Epoch : 11]  [Training accuracy = 99.63%] [Validation accuracy = 54.27%] [Best = 57.89%]  [Training loss = 0.501] [Validation loss = 1.844]\n","[Epoch : 12]  [Training accuracy = 99.70%] [Validation accuracy = 53.88%] [Best = 57.89%]  [Training loss = 0.445] [Validation loss = 1.842]\n","[Epoch : 13]  [Training accuracy = 99.78%] [Validation accuracy = 53.40%] [Best = 57.89%]  [Training loss = 0.381] [Validation loss = 1.840]\n","[Epoch : 14]  [Training accuracy = 99.78%] [Validation accuracy = 52.97%] [Best = 57.89%]  [Training loss = 0.339] [Validation loss = 1.838]\n","[Epoch : 15]  [Training accuracy = 99.85%] [Validation accuracy = 52.91%] [Best = 57.89%]  [Training loss = 0.300] [Validation loss = 1.836]\n","[Epoch : 16]  [Training accuracy = 99.78%] [Validation accuracy = 52.85%] [Best = 57.89%]  [Training loss = 0.266] [Validation loss = 1.835]\n","[Epoch : 17]  [Training accuracy = 99.85%] [Validation accuracy = 52.52%] [Best = 57.89%]  [Training loss = 0.243] [Validation loss = 1.833]\n","[Epoch : 18]  [Training accuracy = 99.93%] [Validation accuracy = 52.70%] [Best = 57.89%]  [Training loss = 0.219] [Validation loss = 1.831]\n","[Epoch : 19]  [Training accuracy = 99.93%] [Validation accuracy = 52.49%] [Best = 57.89%]  [Training loss = 0.200] [Validation loss = 1.829]\n","[Epoch : 20]  [Training accuracy = 99.85%] [Validation accuracy = 52.49%] [Best = 57.89%]  [Training loss = 0.190] [Validation loss = 1.825]\n","[Epoch : 21]  [Training accuracy = 99.85%] [Validation accuracy = 52.49%] [Best = 57.89%]  [Training loss = 0.169] [Validation loss = 1.822]\n","[Epoch : 22]  [Training accuracy = 99.78%] [Validation accuracy = 52.52%] [Best = 57.89%]  [Training loss = 0.163] [Validation loss = 1.819]\n","[Epoch : 23]  [Training accuracy = 99.93%] [Validation accuracy = 52.40%] [Best = 57.89%]  [Training loss = 0.145] [Validation loss = 1.815]\n","[Epoch : 24]  [Training accuracy = 100.00%] [Validation accuracy = 52.34%] [Best = 57.89%]  [Training loss = 0.132] [Validation loss = 1.812]\n","[Epoch : 25]  [Training accuracy = 99.93%] [Validation accuracy = 51.94%] [Best = 57.89%]  [Training loss = 0.130] [Validation loss = 1.809]\n","[Epoch : 26]  [Training accuracy = 100.00%] [Validation accuracy = 52.07%] [Best = 57.89%]  [Training loss = 0.119] [Validation loss = 1.807]\n","[Epoch : 27]  [Training accuracy = 100.00%] [Validation accuracy = 52.19%] [Best = 57.89%]  [Training loss = 0.109] [Validation loss = 1.804]\n","[Epoch : 28]  [Training accuracy = 99.93%] [Validation accuracy = 52.28%] [Best = 57.89%]  [Training loss = 0.108] [Validation loss = 1.802]\n","[Epoch : 29]  [Training accuracy = 100.00%] [Validation accuracy = 52.28%] [Best = 57.89%]  [Training loss = 0.098] [Validation loss = 1.798]\n","[Epoch : 30]  [Training accuracy = 99.85%] [Validation accuracy = 52.16%] [Best = 57.89%]  [Training loss = 0.097] [Validation loss = 1.794]\n","[Epoch : 31]  [Training accuracy = 100.00%] [Validation accuracy = 51.98%] [Best = 57.89%]  [Training loss = 0.086] [Validation loss = 1.792]\n","[Epoch : 32]  [Training accuracy = 99.93%] [Validation accuracy = 51.86%] [Best = 57.89%]  [Training loss = 0.085] [Validation loss = 1.791]\n","[Epoch : 33]  [Training accuracy = 100.00%] [Validation accuracy = 51.89%] [Best = 57.89%]  [Training loss = 0.081] [Validation loss = 1.788]\n","[Epoch : 34]  [Training accuracy = 100.00%] [Validation accuracy = 52.04%] [Best = 57.89%]  [Training loss = 0.076] [Validation loss = 1.786]\n","[Epoch : 35]  [Training accuracy = 99.93%] [Validation accuracy = 51.92%] [Best = 57.89%]  [Training loss = 0.072] [Validation loss = 1.784]\n","[Epoch : 36]  [Training accuracy = 100.00%] [Validation accuracy = 51.95%] [Best = 57.89%]  [Training loss = 0.068] [Validation loss = 1.782]\n","[Epoch : 37]  [Training accuracy = 99.93%] [Validation accuracy = 52.10%] [Best = 57.89%]  [Training loss = 0.066] [Validation loss = 1.781]\n","[Epoch : 38]  [Training accuracy = 99.93%] [Validation accuracy = 52.28%] [Best = 57.89%]  [Training loss = 0.067] [Validation loss = 1.778]\n","[Epoch : 39]  [Training accuracy = 100.00%] [Validation accuracy = 51.89%] [Best = 57.89%]  [Training loss = 0.061] [Validation loss = 1.777]\n","[Epoch : 40]  [Training accuracy = 99.93%] [Validation accuracy = 52.19%] [Best = 57.89%]  [Training loss = 0.059] [Validation loss = 1.776]\n","[Epoch : 41]  [Training accuracy = 99.93%] [Validation accuracy = 52.10%] [Best = 57.89%]  [Training loss = 0.058] [Validation loss = 1.774]\n","[Epoch : 42]  [Training accuracy = 100.00%] [Validation accuracy = 52.13%] [Best = 57.89%]  [Training loss = 0.055] [Validation loss = 1.773]\n","[Epoch : 43]  [Training accuracy = 99.93%] [Validation accuracy = 52.10%] [Best = 57.89%]  [Training loss = 0.052] [Validation loss = 1.771]\n","[Epoch : 44]  [Training accuracy = 100.00%] [Validation accuracy = 51.92%] [Best = 57.89%]  [Training loss = 0.052] [Validation loss = 1.769]\n","[Epoch : 45]  [Training accuracy = 100.00%] [Validation accuracy = 52.25%] [Best = 57.89%]  [Training loss = 0.048] [Validation loss = 1.768]\n","[Epoch : 46]  [Training accuracy = 100.00%] [Validation accuracy = 52.19%] [Best = 57.89%]  [Training loss = 0.047] [Validation loss = 1.768]\n","[Epoch : 47]  [Training accuracy = 99.93%] [Validation accuracy = 52.43%] [Best = 57.89%]  [Training loss = 0.046] [Validation loss = 1.766]\n","[Epoch : 48]  [Training accuracy = 100.00%] [Validation accuracy = 52.25%] [Best = 57.89%]  [Training loss = 0.044] [Validation loss = 1.767]\n","[Epoch : 49]  [Training accuracy = 100.00%] [Validation accuracy = 52.22%] [Best = 57.89%]  [Training loss = 0.043] [Validation loss = 1.766]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T232zvTHxhz0"},"source":["### 1.2. Optimisation avec l'algorithme SGD-Nesterov"]},{"cell_type":"code","metadata":{"id":"zCi_kgjw3Rnk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605610950671,"user_tz":-60,"elapsed":1222,"user":{"displayName":"SF Futures","photoUrl":"","userId":"02252129064136863627"}},"outputId":"dce35dd3-a7ee-4083-cd64-a71704857aed"},"source":["model = sf_efn.efficientnetb0(num_classes=120, pretrained=True,\n","                              url_pretrained=\"models/efficientnet-b0-355c32eb.pth\")\n","model.freeze_layers(last_layer=-2)\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 : _conv_stem\n","freezed\n","1 : _bn0\n","freezed\n","2 : _blocks\n","freezed\n","3 : _conv_head\n","freezed\n","4 : _bn1\n","freezed\n","5 : _avg_pooling\n","freezed\n","6 : _dropout\n","freezed\n","7 : _fc\n","unfreezed\n","8 : _swish\n","unfreezed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"knDiBxaQ3RoH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605615039763,"user_tz":-60,"elapsed":4078951,"user":{"displayName":"SF Futures","photoUrl":"","userId":"02252129064136863627"}},"outputId":"6ac249e8-8996-4468-e07a-1b93e19bf46d"},"source":["transferlearning_on_targettask(model, criterion, optimizer, loaders,\n","                               \"efnb0_120_sgd\", nb_epochs=200, patience=20)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Epoch : 0]  [Training accuracy = 1.86%] [Validation accuracy = 10.30%] [Best = 10.30%]  [Training loss = 4.748] [Validation loss = 4.594]\n","[Epoch : 1]  [Training accuracy = 19.54%] [Validation accuracy = 32.77%] [Best = 32.77%]  [Training loss = 4.435] [Validation loss = 4.289]\n","[Epoch : 2]  [Training accuracy = 44.72%] [Validation accuracy = 41.46%] [Best = 41.46%]  [Training loss = 4.097] [Validation loss = 3.993]\n","[Epoch : 3]  [Training accuracy = 59.12%] [Validation accuracy = 45.35%] [Best = 45.35%]  [Training loss = 3.767] [Validation loss = 3.723]\n","[Epoch : 4]  [Training accuracy = 67.65%] [Validation accuracy = 47.00%] [Best = 47.00%]  [Training loss = 3.456] [Validation loss = 3.486]\n","[Epoch : 5]  [Training accuracy = 71.65%] [Validation accuracy = 48.75%] [Best = 48.75%]  [Training loss = 3.191] [Validation loss = 3.283]\n","[Epoch : 6]  [Training accuracy = 77.80%] [Validation accuracy = 49.11%] [Best = 49.11%]  [Training loss = 2.928] [Validation loss = 3.114]\n","[Epoch : 7]  [Training accuracy = 81.52%] [Validation accuracy = 50.22%] [Best = 50.22%]  [Training loss = 2.688] [Validation loss = 2.974]\n","[Epoch : 8]  [Training accuracy = 85.66%] [Validation accuracy = 51.12%] [Best = 51.12%]  [Training loss = 2.478] [Validation loss = 2.858]\n","[Epoch : 9]  [Training accuracy = 87.67%] [Validation accuracy = 51.76%] [Best = 51.76%]  [Training loss = 2.291] [Validation loss = 2.761]\n","[Epoch : 10]  [Training accuracy = 90.05%] [Validation accuracy = 51.81%] [Best = 51.81%]  [Training loss = 2.118] [Validation loss = 2.679]\n","[Epoch : 11]  [Training accuracy = 91.44%] [Validation accuracy = 51.94%] [Best = 51.94%]  [Training loss = 1.954] [Validation loss = 2.610]\n","[Epoch : 12]  [Training accuracy = 93.33%] [Validation accuracy = 51.96%] [Best = 51.96%]  [Training loss = 1.816] [Validation loss = 2.548]\n","[Epoch : 13]  [Training accuracy = 93.68%] [Validation accuracy = 52.35%] [Best = 52.35%]  [Training loss = 1.701] [Validation loss = 2.493]\n","[Epoch : 14]  [Training accuracy = 94.94%] [Validation accuracy = 52.37%] [Best = 52.37%]  [Training loss = 1.571] [Validation loss = 2.446]\n","[Epoch : 15]  [Training accuracy = 95.68%] [Validation accuracy = 52.43%] [Best = 52.43%]  [Training loss = 1.477] [Validation loss = 2.403]\n","[Epoch : 16]  [Training accuracy = 96.08%] [Validation accuracy = 52.27%] [Best = 52.43%]  [Training loss = 1.366] [Validation loss = 2.364]\n","[Epoch : 17]  [Training accuracy = 96.21%] [Validation accuracy = 52.00%] [Best = 52.43%]  [Training loss = 1.291] [Validation loss = 2.327]\n","[Epoch : 18]  [Training accuracy = 96.58%] [Validation accuracy = 52.15%] [Best = 52.43%]  [Training loss = 1.229] [Validation loss = 2.293]\n","[Epoch : 19]  [Training accuracy = 97.02%] [Validation accuracy = 52.03%] [Best = 52.43%]  [Training loss = 1.137] [Validation loss = 2.264]\n","[Epoch : 20]  [Training accuracy = 97.40%] [Validation accuracy = 52.15%] [Best = 52.43%]  [Training loss = 1.069] [Validation loss = 2.235]\n","[Epoch : 21]  [Training accuracy = 97.25%] [Validation accuracy = 52.15%] [Best = 52.43%]  [Training loss = 1.023] [Validation loss = 2.209]\n","[Epoch : 22]  [Training accuracy = 98.14%] [Validation accuracy = 52.25%] [Best = 52.43%]  [Training loss = 0.965] [Validation loss = 2.187]\n","[Epoch : 23]  [Training accuracy = 97.77%] [Validation accuracy = 52.31%] [Best = 52.43%]  [Training loss = 0.917] [Validation loss = 2.165]\n","[Epoch : 24]  [Training accuracy = 98.51%] [Validation accuracy = 52.58%] [Best = 52.58%]  [Training loss = 0.875] [Validation loss = 2.144]\n","[Epoch : 25]  [Training accuracy = 98.81%] [Validation accuracy = 52.52%] [Best = 52.58%]  [Training loss = 0.832] [Validation loss = 2.125]\n","[Epoch : 26]  [Training accuracy = 98.88%] [Validation accuracy = 52.25%] [Best = 52.58%]  [Training loss = 0.790] [Validation loss = 2.107]\n","[Epoch : 27]  [Training accuracy = 99.18%] [Validation accuracy = 52.49%] [Best = 52.58%]  [Training loss = 0.761] [Validation loss = 2.089]\n","[Epoch : 28]  [Training accuracy = 98.59%] [Validation accuracy = 52.49%] [Best = 52.58%]  [Training loss = 0.721] [Validation loss = 2.073]\n","[Epoch : 29]  [Training accuracy = 99.18%] [Validation accuracy = 52.52%] [Best = 52.58%]  [Training loss = 0.678] [Validation loss = 2.057]\n","[Epoch : 30]  [Training accuracy = 99.11%] [Validation accuracy = 52.58%] [Best = 52.58%]  [Training loss = 0.656] [Validation loss = 2.043]\n","[Epoch : 31]  [Training accuracy = 99.40%] [Validation accuracy = 52.52%] [Best = 52.58%]  [Training loss = 0.631] [Validation loss = 2.029]\n","[Epoch : 32]  [Training accuracy = 99.70%] [Validation accuracy = 52.31%] [Best = 52.58%]  [Training loss = 0.610] [Validation loss = 2.015]\n","[Epoch : 33]  [Training accuracy = 99.48%] [Validation accuracy = 52.37%] [Best = 52.58%]  [Training loss = 0.570] [Validation loss = 2.004]\n","[Epoch : 34]  [Training accuracy = 99.40%] [Validation accuracy = 52.34%] [Best = 52.58%]  [Training loss = 0.554] [Validation loss = 1.994]\n","[Epoch : 35]  [Training accuracy = 99.55%] [Validation accuracy = 52.49%] [Best = 52.58%]  [Training loss = 0.533] [Validation loss = 1.983]\n","[Epoch : 36]  [Training accuracy = 99.70%] [Validation accuracy = 52.46%] [Best = 52.58%]  [Training loss = 0.520] [Validation loss = 1.972]\n","[Epoch : 37]  [Training accuracy = 99.33%] [Validation accuracy = 52.25%] [Best = 52.58%]  [Training loss = 0.499] [Validation loss = 1.962]\n","[Epoch : 38]  [Training accuracy = 99.78%] [Validation accuracy = 52.43%] [Best = 52.58%]  [Training loss = 0.475] [Validation loss = 1.954]\n","[Epoch : 39]  [Training accuracy = 99.63%] [Validation accuracy = 52.34%] [Best = 52.58%]  [Training loss = 0.459] [Validation loss = 1.946]\n","[Epoch : 40]  [Training accuracy = 99.78%] [Validation accuracy = 52.40%] [Best = 52.58%]  [Training loss = 0.443] [Validation loss = 1.938]\n","[Epoch : 41]  [Training accuracy = 99.63%] [Validation accuracy = 52.43%] [Best = 52.58%]  [Training loss = 0.435] [Validation loss = 1.931]\n","[Epoch : 42]  [Training accuracy = 99.40%] [Validation accuracy = 52.55%] [Best = 52.58%]  [Training loss = 0.421] [Validation loss = 1.924]\n","[Epoch : 43]  [Training accuracy = 99.63%] [Validation accuracy = 52.55%] [Best = 52.58%]  [Training loss = 0.404] [Validation loss = 1.918]\n","[Epoch : 44]  [Training accuracy = 99.78%] [Validation accuracy = 52.79%] [Best = 52.79%]  [Training loss = 0.390] [Validation loss = 1.911]\n","[Epoch : 45]  [Training accuracy = 99.78%] [Validation accuracy = 52.55%] [Best = 52.79%]  [Training loss = 0.384] [Validation loss = 1.905]\n","[Epoch : 46]  [Training accuracy = 99.93%] [Validation accuracy = 52.64%] [Best = 52.79%]  [Training loss = 0.370] [Validation loss = 1.899]\n","[Epoch : 47]  [Training accuracy = 99.70%] [Validation accuracy = 52.67%] [Best = 52.79%]  [Training loss = 0.367] [Validation loss = 1.894]\n","[Epoch : 48]  [Training accuracy = 99.70%] [Validation accuracy = 52.70%] [Best = 52.79%]  [Training loss = 0.360] [Validation loss = 1.888]\n","[Epoch : 49]  [Training accuracy = 99.93%] [Validation accuracy = 52.58%] [Best = 52.79%]  [Training loss = 0.343] [Validation loss = 1.883]\n","[Epoch : 50]  [Training accuracy = 99.93%] [Validation accuracy = 52.55%] [Best = 52.79%]  [Training loss = 0.333] [Validation loss = 1.879]\n","[Epoch : 51]  [Training accuracy = 99.70%] [Validation accuracy = 52.61%] [Best = 52.79%]  [Training loss = 0.323] [Validation loss = 1.873]\n","[Epoch : 52]  [Training accuracy = 99.85%] [Validation accuracy = 52.67%] [Best = 52.79%]  [Training loss = 0.317] [Validation loss = 1.869]\n","[Epoch : 53]  [Training accuracy = 99.93%] [Validation accuracy = 52.46%] [Best = 52.79%]  [Training loss = 0.308] [Validation loss = 1.865]\n","[Epoch : 54]  [Training accuracy = 99.85%] [Validation accuracy = 52.55%] [Best = 52.79%]  [Training loss = 0.304] [Validation loss = 1.861]\n","[Epoch : 55]  [Training accuracy = 99.85%] [Validation accuracy = 52.73%] [Best = 52.79%]  [Training loss = 0.295] [Validation loss = 1.857]\n","[Epoch : 56]  [Training accuracy = 99.85%] [Validation accuracy = 52.67%] [Best = 52.79%]  [Training loss = 0.282] [Validation loss = 1.854]\n","[Epoch : 57]  [Training accuracy = 99.78%] [Validation accuracy = 52.61%] [Best = 52.79%]  [Training loss = 0.271] [Validation loss = 1.851]\n","[Epoch : 58]  [Training accuracy = 99.93%] [Validation accuracy = 52.61%] [Best = 52.79%]  [Training loss = 0.268] [Validation loss = 1.847]\n","[Epoch : 59]  [Training accuracy = 99.78%] [Validation accuracy = 52.76%] [Best = 52.79%]  [Training loss = 0.263] [Validation loss = 1.843]\n","[Epoch : 60]  [Training accuracy = 99.85%] [Validation accuracy = 52.82%] [Best = 52.82%]  [Training loss = 0.263] [Validation loss = 1.841]\n","[Epoch : 61]  [Training accuracy = 99.85%] [Validation accuracy = 52.79%] [Best = 52.82%]  [Training loss = 0.249] [Validation loss = 1.838]\n","[Epoch : 62]  [Training accuracy = 99.85%] [Validation accuracy = 52.82%] [Best = 52.82%]  [Training loss = 0.249] [Validation loss = 1.834]\n","[Epoch : 63]  [Training accuracy = 99.73%] [Validation accuracy = 52.73%] [Best = 52.82%]  [Training loss = 0.243] [Validation loss = 1.830]\n","[Epoch : 64]  [Training accuracy = 99.78%] [Validation accuracy = 52.88%] [Best = 52.88%]  [Training loss = 0.239] [Validation loss = 1.828]\n","[Epoch : 65]  [Training accuracy = 99.93%] [Validation accuracy = 52.73%] [Best = 52.88%]  [Training loss = 0.237] [Validation loss = 1.824]\n","[Epoch : 66]  [Training accuracy = 100.00%] [Validation accuracy = 52.73%] [Best = 52.88%]  [Training loss = 0.225] [Validation loss = 1.822]\n","[Epoch : 67]  [Training accuracy = 99.78%] [Validation accuracy = 52.70%] [Best = 52.88%]  [Training loss = 0.228] [Validation loss = 1.820]\n","[Epoch : 68]  [Training accuracy = 99.78%] [Validation accuracy = 52.73%] [Best = 52.88%]  [Training loss = 0.216] [Validation loss = 1.819]\n","[Epoch : 69]  [Training accuracy = 99.70%] [Validation accuracy = 52.82%] [Best = 52.88%]  [Training loss = 0.217] [Validation loss = 1.816]\n","[Epoch : 70]  [Training accuracy = 99.78%] [Validation accuracy = 52.97%] [Best = 52.97%]  [Training loss = 0.208] [Validation loss = 1.814]\n","[Epoch : 71]  [Training accuracy = 99.93%] [Validation accuracy = 52.91%] [Best = 52.97%]  [Training loss = 0.209] [Validation loss = 1.812]\n","[Epoch : 72]  [Training accuracy = 100.00%] [Validation accuracy = 52.94%] [Best = 52.97%]  [Training loss = 0.203] [Validation loss = 1.809]\n","[Epoch : 73]  [Training accuracy = 99.85%] [Validation accuracy = 52.97%] [Best = 52.97%]  [Training loss = 0.198] [Validation loss = 1.807]\n","[Epoch : 74]  [Training accuracy = 99.93%] [Validation accuracy = 52.85%] [Best = 52.97%]  [Training loss = 0.193] [Validation loss = 1.806]\n","[Epoch : 75]  [Training accuracy = 100.00%] [Validation accuracy = 52.85%] [Best = 52.97%]  [Training loss = 0.194] [Validation loss = 1.804]\n","[Epoch : 76]  [Training accuracy = 99.93%] [Validation accuracy = 52.85%] [Best = 52.97%]  [Training loss = 0.188] [Validation loss = 1.803]\n","[Epoch : 77]  [Training accuracy = 99.93%] [Validation accuracy = 52.97%] [Best = 52.97%]  [Training loss = 0.185] [Validation loss = 1.802]\n","[Epoch : 78]  [Training accuracy = 99.85%] [Validation accuracy = 52.88%] [Best = 52.97%]  [Training loss = 0.180] [Validation loss = 1.800]\n","[Epoch : 79]  [Training accuracy = 99.78%] [Validation accuracy = 52.88%] [Best = 52.97%]  [Training loss = 0.183] [Validation loss = 1.799]\n","[Epoch : 80]  [Training accuracy = 100.00%] [Validation accuracy = 52.88%] [Best = 52.97%]  [Training loss = 0.176] [Validation loss = 1.797]\n","[Epoch : 81]  [Training accuracy = 99.85%] [Validation accuracy = 52.73%] [Best = 52.97%]  [Training loss = 0.182] [Validation loss = 1.795]\n","[Epoch : 82]  [Training accuracy = 99.93%] [Validation accuracy = 52.82%] [Best = 52.97%]  [Training loss = 0.170] [Validation loss = 1.794]\n","[Epoch : 83]  [Training accuracy = 100.00%] [Validation accuracy = 52.88%] [Best = 52.97%]  [Training loss = 0.168] [Validation loss = 1.791]\n","[Epoch : 84]  [Training accuracy = 99.78%] [Validation accuracy = 52.82%] [Best = 52.97%]  [Training loss = 0.172] [Validation loss = 1.790]\n","[Epoch : 85]  [Training accuracy = 99.93%] [Validation accuracy = 52.85%] [Best = 52.97%]  [Training loss = 0.160] [Validation loss = 1.790]\n","[Epoch : 86]  [Training accuracy = 99.85%] [Validation accuracy = 52.91%] [Best = 52.97%]  [Training loss = 0.163] [Validation loss = 1.787]\n","[Epoch : 87]  [Training accuracy = 99.63%] [Validation accuracy = 52.70%] [Best = 52.97%]  [Training loss = 0.162] [Validation loss = 1.786]\n","[Epoch : 88]  [Training accuracy = 99.93%] [Validation accuracy = 52.76%] [Best = 52.97%]  [Training loss = 0.157] [Validation loss = 1.785]\n","[Epoch : 89]  [Training accuracy = 99.78%] [Validation accuracy = 52.58%] [Best = 52.97%]  [Training loss = 0.153] [Validation loss = 1.784]\n","[Epoch : 90]  [Training accuracy = 99.85%] [Validation accuracy = 52.91%] [Best = 52.97%]  [Training loss = 0.159] [Validation loss = 1.783]\n","[Epoch : 91]  [Training accuracy = 99.85%] [Validation accuracy = 53.00%] [Best = 53.00%]  [Training loss = 0.157] [Validation loss = 1.781]\n","[Epoch : 92]  [Training accuracy = 99.85%] [Validation accuracy = 52.94%] [Best = 53.00%]  [Training loss = 0.153] [Validation loss = 1.779]\n","[Epoch : 93]  [Training accuracy = 99.93%] [Validation accuracy = 52.94%] [Best = 53.00%]  [Training loss = 0.147] [Validation loss = 1.779]\n","[Epoch : 94]  [Training accuracy = 100.00%] [Validation accuracy = 52.64%] [Best = 53.00%]  [Training loss = 0.147] [Validation loss = 1.777]\n","[Epoch : 95]  [Training accuracy = 99.78%] [Validation accuracy = 52.64%] [Best = 53.00%]  [Training loss = 0.143] [Validation loss = 1.775]\n","[Epoch : 96]  [Training accuracy = 99.85%] [Validation accuracy = 52.58%] [Best = 53.00%]  [Training loss = 0.142] [Validation loss = 1.775]\n","[Epoch : 97]  [Training accuracy = 99.93%] [Validation accuracy = 52.61%] [Best = 53.00%]  [Training loss = 0.136] [Validation loss = 1.774]\n","[Epoch : 98]  [Training accuracy = 99.93%] [Validation accuracy = 52.73%] [Best = 53.00%]  [Training loss = 0.139] [Validation loss = 1.771]\n","[Epoch : 99]  [Training accuracy = 99.93%] [Validation accuracy = 52.76%] [Best = 53.00%]  [Training loss = 0.136] [Validation loss = 1.770]\n","[Epoch : 100]  [Training accuracy = 99.93%] [Validation accuracy = 52.82%] [Best = 53.00%]  [Training loss = 0.137] [Validation loss = 1.769]\n","[Epoch : 101]  [Training accuracy = 100.00%] [Validation accuracy = 52.94%] [Best = 53.00%]  [Training loss = 0.132] [Validation loss = 1.768]\n","[Epoch : 102]  [Training accuracy = 99.93%] [Validation accuracy = 52.73%] [Best = 53.00%]  [Training loss = 0.129] [Validation loss = 1.768]\n","[Epoch : 103]  [Training accuracy = 99.85%] [Validation accuracy = 52.76%] [Best = 53.00%]  [Training loss = 0.131] [Validation loss = 1.766]\n","[Epoch : 104]  [Training accuracy = 99.78%] [Validation accuracy = 52.91%] [Best = 53.00%]  [Training loss = 0.125] [Validation loss = 1.766]\n","[Epoch : 105]  [Training accuracy = 99.93%] [Validation accuracy = 52.91%] [Best = 53.00%]  [Training loss = 0.125] [Validation loss = 1.765]\n","[Epoch : 106]  [Training accuracy = 99.93%] [Validation accuracy = 52.79%] [Best = 53.00%]  [Training loss = 0.126] [Validation loss = 1.765]\n","[Epoch : 107]  [Training accuracy = 99.93%] [Validation accuracy = 52.79%] [Best = 53.00%]  [Training loss = 0.123] [Validation loss = 1.765]\n","[Epoch : 108]  [Training accuracy = 99.93%] [Validation accuracy = 52.67%] [Best = 53.00%]  [Training loss = 0.131] [Validation loss = 1.764]\n","[Epoch : 109]  [Training accuracy = 99.93%] [Validation accuracy = 52.55%] [Best = 53.00%]  [Training loss = 0.125] [Validation loss = 1.762]\n","[Epoch : 110]  [Training accuracy = 100.00%] [Validation accuracy = 52.55%] [Best = 53.00%]  [Training loss = 0.120] [Validation loss = 1.761]\n","[Epoch : 111]  [Training accuracy = 99.93%] [Validation accuracy = 52.49%] [Best = 53.00%]  [Training loss = 0.123] [Validation loss = 1.760]\n","[Epoch : 112]  [Training accuracy = 100.00%] [Validation accuracy = 52.64%] [Best = 53.00%]  [Training loss = 0.117] [Validation loss = 1.759]\n","Learning ended by early-stop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QatfL6bnvDBq"},"source":["---\n","## 2\\. Transfert de connaissance d'EfficientNetB7 vers EfficientNetB0"]},{"cell_type":"code","metadata":{"id":"XU2M4U8VHzEC"},"source":["model_efficientnetb7_url = PATH_DRIVE + \"/models/efficientnet-b7-dcc49843.pth\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XgtbX4_eHzEJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605615713715,"user_tz":-60,"elapsed":7767,"user":{"displayName":"SF Futures","photoUrl":"","userId":"02252129064136863627"}},"outputId":"a0c4215e-2963-4c8a-bc83-bc37384a41e8"},"source":["source_model = sf_efn.efficientnetb7(pretrained=True, max_num_features=512,\n","                                     folder_saves=\"models\",\n","                                     url_pretrained=model_efficientnetb7_url)\n","target_model = sf_efn.efficientnetb0(num_classes=120, pretrained=False)\n","target_model.load_state_dict(torch.load(\"models/efnb0_120_adam.pth\"))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"a3ZQVr4cvE0F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605615763233,"user_tz":-60,"elapsed":25606,"user":{"displayName":"SF Futures","photoUrl":"","userId":"02252129064136863627"}},"outputId":"c179f88a-214d-40c5-8e1c-48809a991989"},"source":["loaders = sf_load.get_dataset(IMAGES_DRIVE, target_model, mini_data=0.1, stratify=True,\n","                              batch_size=64, with_data_augmentation=False)\n","model = target_model.to(device)\n","get_validation(model, loaders[2])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(2.2600, device='cuda:0'), 0.5788976648351649)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"b7jKUIL2HzEM"},"source":["l2t_model = sf_l2t.WhatWhere(source_model, target_model, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOCfQm8cHzEP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c07d022-d937-4848-f413-956ec5798338"},"source":["l2t_model.train(IMAGES_DRIVE, epochs=200, batch_size=8,\n","                mini_data=0.1, with_data_augmentation=False,\n","                early_stop=True, save_name=\"efnb7_to_efnb0_mini\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2020-11-17 12:28:52,155] [main] /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-7cfdf943-b60f-4a16-aee8-db472feec61a.json\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"],"name":"stderr"},{"output_type":"stream","text":["[2020-11-17 12:50:40,277] [main] Best model is saved\n","[2020-11-17 12:50:40,608] [main] Last model is saved\n","[2020-11-17 12:50:40,610] [main] [Epoch : 1]  [Training accuracy = 0.76%] [Validation accuracy = 0.73%] [Best = 0.73%]  [Training loss = nan] [Validation loss = nan]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"easwPeOUxyO8"},"source":["La méthode retourne une loss (la cross-entropy) égale à NA. Cela est dû à l'instabilité des gradients qui fait que la perte explose et n'est plus calculable.  \n","Cela remet en cause la possibilité d'utiliser cette méthode sur toutes sortes de réseaux, même lorsque ceux-ci utilisent des couches de Batch Normalization."]},{"cell_type":"code","metadata":{"id":"O-r0K8rNHuSy"},"source":[""],"execution_count":null,"outputs":[]}]}